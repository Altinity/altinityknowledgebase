<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.96.0" /><link rel="canonical" type="text/html" href="http://kb.altinity.com/altinity-kb-integrations/">
<META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
<link rel="shortcut icon" href="/favicons/favicon.ico" >
<link rel="icon" href="/favicons/favicon.ico" >
<title>Integrations | Altinity Knowledge Base</title>
<meta name="description" content="Altinity Knowledge Base"><meta property="og:title" content="Integrations" />
<meta property="og:description" content="Learn how you can integrate cloud services, BI tools, kafka, MySQL, Spark, MindsDB, and more with ClickHouse.
" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://kb.altinity.com/altinity-kb-integrations/" /><meta property="og:site_name" content="Altinity Knowledge Base" />

<meta itemprop="name" content="Integrations">
<meta itemprop="description" content="Learn how you can integrate cloud services, BI tools, kafka, MySQL, Spark, MindsDB, and more with ClickHouse.
"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Integrations"/>
<meta name="twitter:description" content="Learn how you can integrate cloud services, BI tools, kafka, MySQL, Spark, MindsDB, and more with ClickHouse.
"/>




<link rel="preload" href="/scss/main.min.ec0d259783afc2c6841272db4924ae5f6ab47953b32356793cb392fb1f3c3e5d.css" as="style">
<link href="/scss/main.min.ec0d259783afc2c6841272db4924ae5f6ab47953b32356793cb392fb1f3c3e5d.css" rel="stylesheet" integrity="">


<script
  src="https://code.jquery.com/jquery-3.5.1.min.js"
  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
  crossorigin="anonymous"></script>

<script
  src="https://unpkg.com/lunr@2.3.8/lunr.min.js"
  integrity="sha384-vRQ9bDyE0Wnu+lMfm57BlYLO0/XauFuKpVsZPs7KEDwYKktWi5+Kz3MP8++DFlRY"
  crossorigin="anonymous"></script>



<link rel="stylesheet" href="/css/prism.css"/>

<meta name="keywords" content="clickhouse integration, clickhouse bi, clickhouse kafka">




  </head>
  <body class="td-section">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
        <a class="navbar-brand" href="/">
		<span class="navbar-logo"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 97.68 112.95"><defs><linearGradient id="linear-gradient" x1="49.43" y1="564.05" x2="21.19" y2="486.25" gradientTransform="matrix(1, 0, 0, -1, 0, 550.11)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#009cd0"/><stop offset=".16" stop-color="#02a0d4"/><stop offset=".33" stop-color="#08acdf"/><stop offset=".49" stop-color="#12c0f1"/><stop offset=".66" stop-color="#10bced"/><stop offset=".83" stop-color="#0ab0e2"/><stop offset="1" stop-color="#009cd0"/></linearGradient><linearGradient id="linear-gradient-2" x1="0" y1="472.36" x2="48.75" y2="472.36" xlink:href="#linear-gradient"/><linearGradient id="linear-gradient-3" x1=".05" y1="493.62" x2="24.5" y2="493.62" gradientTransform="matrix(1, 0, 0, -1, 0, 550.11)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#fff"/><stop offset=".03" stop-color="#f2f7fb"/><stop offset=".19" stop-color="#b3d2e7"/><stop offset=".34" stop-color="#7cb2d5"/><stop offset=".5" stop-color="#5097c7"/><stop offset=".64" stop-color="#2d83bc"/><stop offset=".78" stop-color="#1474b4"/><stop offset=".9" stop-color="#056bb0"/><stop offset="1" stop-color="#0068ae"/></linearGradient><linearGradient id="linear-gradient-4" x1="73.23" y1="507.9" x2="97.68" y2="507.9" gradientTransform="matrix(1, 0, 0, -1, 0, 550.11)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#0068ae"/><stop offset=".12" stop-color="#046aaf"/><stop offset=".25" stop-color="#1072b3"/><stop offset=".38" stop-color="#257eba"/><stop offset=".5" stop-color="#418fc3"/><stop offset=".63" stop-color="#66a4ce"/><stop offset=".76" stop-color="#93bfdd"/><stop offset=".88" stop-color="#c7deed"/><stop offset="1" stop-color="#fff"/></linearGradient><linearGradient id="linear-gradient-5" x1="50.7" y1="522" x2="74.92" y2="522" gradientTransform="matrix(1, 0, 0, -1, 0, 550.11)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#0068ae"/><stop offset=".09" stop-color="#096eb1"/><stop offset=".23" stop-color="#237db9"/><stop offset=".41" stop-color="#4d95c6"/><stop offset=".62" stop-color="#86b8d9"/><stop offset=".86" stop-color="#cfe3f0"/><stop offset="1" stop-color="#fff"/></linearGradient></defs><title>logo_1</title><g style="isolation:isolate"><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><path d="M97.68 56.29h0L73.23 42.21V98.58L97.68 112.7V56.29z" style="fill:#009cd0"/><path d="M73.23 42.21 97.68 56.32V28.09z" style="fill:#009cd0"/><path d="M73.25 42.2 97.68 28.09 73.25 14h0L48.79 28.08 73.23 42.19v0h0z" style="fill:#009cd0"/><path d="M73.34 14.12 48.89.0V0L24.45 14.18h0L.1 28.23h0L0 28.29l.09.05V56.46L24.45 42.4h0 .1.0L49.4 27.94 73.34 14.12z" style="fill:url(#linear-gradient)"/><path d="M48.75 84.87 24.45 70.52v-28L.21 56.53l-.12-.07v.14L0 56.66l.09.05V84.65L0 84.7l.09.06V113L24.3 99v0L48.75 84.87z" style="fill:url(#linear-gradient-2)"/><path d="M.05 56.44 24.5 70.55V42.32z" style="fill:#009cd0"/><path d="M.05 56.49 24.5 70.6V42.37z" style="mix-blend-mode:multiply;fill:url(#linear-gradient-3)"/><path d="M73.23 42.21 97.68 56.32V28.09z" style="mix-blend-mode:multiply;fill:url(#linear-gradient-4)"/><path d="M97.68 28.09 73.23 14v0L48.79 28.13 73.25 42.25v0z" style="mix-blend-mode:multiply;fill:url(#linear-gradient-5)"/></g></g></g></svg></span><span class="text-uppercase font-weight-bold">Altinity Knowledge Base</span>
	</a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		<ul class="navbar-nav mt-2 mt-lg-0">
			
			
			
			
		</ul>
	</div>
	<div class="navbar-nav d-none d-lg-block">



<input
  type="search"
  class="form-control td-search-input"
  placeholder="&#xf002; Search this site…"
  aria-label="Search this site…"
  autocomplete="off"
  
  data-offline-search-index-json-src="/offline-search-index.9f88c2900b11dcd5146da70a8cc84431.json"
  data-offline-search-base-href="/"
  data-offline-search-max-results="10"
>

</div>
</nav>

    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
          </div>
          <div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
          </div>
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            




<div class="td-content">
<div class="pageinfo pageinfo-primary d-print-none">
<p>
This the multi-page printable view of this section.
<a href="#" onclick="print();return false;">Click here to print</a>.
</p><p>
<a href="/altinity-kb-integrations/">Return to the regular view of this page</a>.
</p>
</div>



<h1 class="title">Integrations</h1>
<div class="lead">Learn how you can integrate cloud services, BI tools, kafka, MySQL, Spark, MindsDB, and more with ClickHouse.</div>




    <ul>
    
  
  
  
  

  
    
    
	
<li>1: <a href="#pg-1df7bcbc597684541fc9783932543752">Cloud Services</a></li>


    
    <ul>
        
  
  
  
  

  
    
    
	
<li>1.1: <a href="#pg-7d14c198d6e6d9a182e49215d0b0efa9">Altinity Cloud Access Management</a></li>


    
  

    </ul>
    
  
    
    
	
<li>2: <a href="#pg-0f98d3cb672b7952fbdcbdf0b4f456a8">MySQL</a></li>


    
  
    
    
	
<li>3: <a href="#pg-eb3d7cbed2a5c568b2bb9a98bbc492ee">ODBC Driver for ClickHouse</a></li>


    
  
    
    
	
<li>4: <a href="#pg-d2afec8f52450d3642df08e91fab21b4">ClickHouse &#43; Spark</a></li>


    
  
    
    
	
<li>5: <a href="#pg-490f1eab7bb37421ddd14a8d6c58e9ab">BI Tools</a></li>


    
  
    
    
	
<li>6: <a href="#pg-7a1dc52ba21a64be26ec5780459eb575">CatBoost / MindsDB /  Fast.ai</a></li>


    
  
    
    
	
<li>7: <a href="#pg-902c0f257a8ddd6f658f1246ef020032">Google S3 (GCS)</a></li>


    
  
    
    
	
<li>8: <a href="#pg-baebc0ff2257ac7906ebf1b6671d8990">Kafka</a></li>


    
    <ul>
        
  
  
  
  

  
    
    
	
<li>8.1: <a href="#pg-b11bb1875d00a2b0ff0e60950c5360ed">Adjusting librdkafka settings</a></li>


    
  
    
    
	
<li>8.2: <a href="#pg-d58f1474300f709dea11df04812ed578">Error handling</a></li>


    
  
    
    
	
<li>8.3: <a href="#pg-d8f2388a49c064f3f21643937cbfcedc">Exactly once semantics</a></li>


    
  
    
    
	
<li>8.4: <a href="#pg-7b4e8063954e9a7aaa7e048590c82f0d">Kafka main parsing loop</a></li>


    
  
    
    
	
<li>8.5: <a href="#pg-8de9ef71664f1495dde935e5d9c292a4">Kafka parallel consuming</a></li>


    
  
    
    
	
<li>8.6: <a href="#pg-70048b9cd8c627a770ed4410dcd3a6d4">Rewind / fast-forward / replay</a></li>


    
  
    
    
	
<li>8.7: <a href="#pg-8441aefeee7f594b90b90afa09a25289">SELECTs from engine=Kafka</a></li>


    
  

    </ul>
    
  

    </ul>


<div class="content">
      
</div>
</div>


  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-1df7bcbc597684541fc9783932543752">1 - Cloud Services</h1>
    <div class="lead">Tips and tricks for using ClickHouse with different cloud services.</div>
	
</div>



    
      
  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="">
    
	<h1 id="pg-7d14c198d6e6d9a182e49215d0b0efa9">1.1 - Altinity Cloud Access Management</h1>
    <div class="lead">Enabling access_management for Altinity.Cloud databases.</div>
	<p>Organizations that want to enable administrative users in their Altinity.Cloud ClickHouse servers can do so by enabling <code>access_management</code> manually.  This allows for administrative users to be created on the specific ClickHouse Cluster.</p>


<div class="alert alert-warning" role="alert">
<h4 class="alert-heading">WARNING</h4>

    Modifying the ClickHouse cluster settings manually can lead to the cluster not loading or other issues.  Change settings only with full consultation with an Altinity.Cloud support team member, and be ready to remove settings if they cause any disruption of service.

</div>

<p>To add the <code>access_management</code> setting to an Altinity.Cloud ClickHouse Cluster:</p>
<ol>
<li>
<p>Log into your Altinity.Cloud account.</p>
</li>
<li>
<p>For the cluster to modify, select <strong>Configure -&gt; Settings</strong>.</p>

<figure>
    <img src="/assets/altinity-cloud-cluster-settings-configure.png" width="400"/> <figcaption>
            <h4>Cluster setting configure</h4>
        </figcaption>
</figure>

</li>
<li>
<p>From the Settings page, select <strong>+ADD SETTING</strong>.</p>

<figure>
    <img src="/assets/altinity-cloud-cluster-add-setting.png"/> <figcaption>
            <h4>Add cluster setting</h4>
        </figcaption>
</figure>

</li>
<li>
<p>Set the following options:</p>
<ol>
<li>
<p><strong>Setting Type</strong>:  Select <strong>users.d file</strong>.</p>
</li>
<li>
<p><strong>Filename</strong>: <code>access_management.xml</code></p>
</li>
<li>
<p><strong>Contents</strong>:  Enter the following to allow the <code>clickhouse_operator</code> that controls the cluster through the <code>clickhouse-operator</code> the ability to set administrative options:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;yandex&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;users&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;admin&gt;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#204a87;font-weight:bold">&lt;access_management&gt;</span>1<span style="color:#204a87;font-weight:bold">&lt;/access_management&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;/admin&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;clickhouse_operator&gt;</span>
</span></span><span style="display:flex;"><span>            <span style="color:#204a87;font-weight:bold">&lt;access_management&gt;</span>1<span style="color:#204a87;font-weight:bold">&lt;/access_management&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;/clickhouse_operator&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;/users&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;/yandex&gt;</span>
</span></span></code></pre></div></li>
</ol>
<p>access_management=1 means that users <code>admin</code>, <code>clickhouse_operator</code> are able to create users and grant them privileges using SQL.</p>
</li>
<li>
<p>Select <strong>OK</strong>.  The cluster will restart, and users can now be created in the cluster that can be granted administrative access.</p>
</li>
<li>
<p>If you are running ClickHouse 21.9 and above you can enable storing access management in ZooKeeper. in this case it will be automatically propagated to the cluster. This requires yet another configuration file:</p>
<ol>
<li>
<p><strong>Setting Type</strong>: Select <strong>config.d file</strong></p>
</li>
<li>
<p><strong>Filename</strong>: <code>user_directories.xml</code></p>
</li>
<li>
<p><strong>Contents</strong>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;yandex&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#204a87;font-weight:bold">&lt;user_directories</span> <span style="color:#c4a000">replace=</span><span style="color:#4e9a06">&#34;replace&#34;</span><span style="color:#204a87;font-weight:bold">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;users_xml&gt;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#204a87;font-weight:bold">&lt;path&gt;</span>/etc/clickhouse-server/users.xml<span style="color:#204a87;font-weight:bold">&lt;/path&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;/users_xml&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;replicated&gt;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#204a87;font-weight:bold">&lt;zookeeper_path&gt;</span>/clickhouse/access/<span style="color:#204a87;font-weight:bold">&lt;/zookeeper_path&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;/replicated&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#204a87;font-weight:bold">&lt;/user_directories&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;/yandex&gt;</span>
</span></span></code></pre></div></li>
</ol>
</li>
</ol>

</div>



    
	
  

    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-0f98d3cb672b7952fbdcbdf0b4f456a8">2 - MySQL</h1>
    <div class="lead">Integration Clickhouse with MySQL</div>
	<h3 id="replication-using-materializemysql">Replication using MaterializeMySQL.</h3>
<ul>
<li><a href="https://clickhouse.tech/docs/en/engines/database-engines/materialized-mysql/" target="_blank">https://clickhouse.tech/docs/en/engines/database-engines/materialized-mysql/</a></li>
<li><a href="https://translate.google.com/translate?sl=auto&amp;tl=en&amp;u=https://www.jianshu.com/p/d0d4306411b3" target="_blank">https://translate.google.com/translate?sl=auto&amp;tl=en&amp;u=https://www.jianshu.com/p/d0d4306411b3</a></li>
<li><a href="https://raw.githubusercontent.com/ClickHouse/clickhouse-presentations/master/meetup47/materialize_mysql.pdf" target="_blank">https://raw.githubusercontent.com/ClickHouse/clickhouse-presentations/master/meetup47/materialize_mysql.pdf</a></li>
</ul>
<p>It reads mysql binlog directly and transform queries into something which clickhouse can support. Supports updates and deletes (under the hood implemented via something like ReplacingMergeTree with enforced FINAL and &lsquo;deleted&rsquo; flag). Status is &rsquo;experimental&rsquo;, there are quite a lot of known limitations and issues, but some people use it. The original author of that went to another project, and the main team don&rsquo;t have a lot of resource to improve that for now (more important thing in the backlog)</p>
<p>The replication happens on the mysql database level.</p>
<h3 id="replication-using-debezium--kafka">Replication using debezium + Kafka</h3>
<p>Debezium can read the binlog and transform it to Kafka messages. You can later capture the stream of message on ClickHouse side and process it as you like.
Please remeber that currently Kafka engine supports only at-least-once delivery guarantees.</p>
<p>It&rsquo;s used by several companies, quite nice &amp; flexible. But initial setup may require some efforts.</p>
<h4 id="same-as-above-but-using-httpsmaxwells-daemonio-instead-of-debezium">Same as above but using <a href="https://maxwells-daemon.io/" target="_blank">https://maxwells-daemon.io/</a> instead of debezium.</h4>
<p>Have no experience / feedback there, but should be very similar to debezium.</p>
<h3 id="replication-using-clickhouse-mysql">Replication using clickhouse-mysql</h3>
<p>See <a href="https://altinity.com/blog/2018/6/30/realtime-mysql-clickhouse-replication-in-practice" target="_blank">https://altinity.com/blog/2018/6/30/realtime-mysql-clickhouse-replication-in-practice</a></p>
<p>That was done long time ago in altinity for one use-case, and it seem like it was never used outside of that.
It&rsquo;s a python application with lot of switches which can copy a schema or read binlog from mysql and put it to clickhouse.
Not supported currently. But it&rsquo;s just a python, so maybe can be adjusted to different needs.</p>
<h3 id="accessing-mysql-data-via-integration-engines-from-inside-clickhouse">Accessing MySQL data via integration engines from inside clickhouse.</h3>
<p>MySQL <a href="https://clickhouse.com/docs/en/engines/table-engines/integrations/mysql/" target="_blank">table engine</a> / <a href="https://clickhouse.com/docs/en/sql-reference/table-functions/mysql/" target="_blank">table function</a>, or <a href="https://clickhouse.com/docs/en/engines/database-engines/mysql/" target="_blank">MySQL database engine</a> - clickhouse just connects to mysql server as a client, and can do normal selects.</p>
<p>We had webinar about that a year ago: <a href="https://www.youtube.com/watch?v=44kO3UzIDLI" target="_blank">https://www.youtube.com/watch?v=44kO3UzIDLI</a></p>
<p>Using that you can easily create some ETL script which will copy the data from mysql to clickhouse regularly, i.e. something like</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">INSERT</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">INTO</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">clickhouse_table</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">SELECT</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">*</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">FROM</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">mysql_table</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">WHERE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">id</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">&gt;</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">...</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span></code></pre></div><p>Works great if you have append only table in MySQL.</p>
<p>In newer clickhouse versions you can query this was also sharded / replicated MySQL cluster - see <a href="https://clickhouse.com/docs/en/engines/table-engines/integrations/ExternalDistributed/" target="_blank">ExternalDistributed</a></p>
<h3 id="mysql-dictionaries">MySQL dictionaries</h3>
<p>There are also MySQL dictionaries, which can be very nice alternative for storing some dimensions information in star schema.</p>
<ul>
<li><a href="https://clickhouse.com/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts-dict-sources/#dicts-external_dicts_dict_sources-mysql" target="_blank">https://clickhouse.com/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts-dict-sources/#dicts-external_dicts_dict_sources-mysql</a></li>
<li><a href="https://github.com/ClickHouse/ClickHouse/blob/9f5cd35a6963cc556a51218b46b0754dcac7306a/tests/testflows/aes_encryption/tests/compatibility/mysql/dictionary.py#L35-L51" target="_blank">https://github.com/ClickHouse/ClickHouse/blob/9f5cd35a6963cc556a51218b46b0754dcac7306a/tests/testflows/aes_encryption/tests/compatibility/mysql/dictionary.py#L35-L51</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-eb3d7cbed2a5c568b2bb9a98bbc492ee">3 - ODBC Driver for ClickHouse</h1>
    <div class="lead">ODBC Driver for ClickHouse</div>
	<h1 id="odbc-driver-for-clickhouse">ODBC Driver for ClickHouse.</h1>
<p><a href="https://docs.microsoft.com/en-us/sql/odbc/reference/odbc-overview" target="_blank">ODBC</a> interface for <a href="https://clickhouse.yandex" target="_blank">ClickHouse</a> RDBMS.</p>
<p>Licensed under the <a href="LICENSE">Apache 2.0</a>.</p>
<h2 id="installation-and-usage">Installation and usage</h2>
<h3 id="windows">Windows</h3>
<ol>
<li>Download the latest <a href="https://github.com/ClickHouse/clickhouse-odbc/releases" target="_blank">release</a>. On 64bit system you usually need both 32 bit and 64 bit drivers.</li>
<li>Install (usually you will need ANSI driver, but better to install both versions, see below).</li>
<li>Configure ClickHouse DSN.</li>
</ol>
<p>Note: that install driver linked against MDAC (which is default for Windows), some non-windows native
applications (cygwin / msys64 based) may require driver linked agains unixodbc. Build section below.</p>
<h3 id="macos">MacOS</h3>
<ol>
<li>Install <a href="https://brew.sh/" target="_blank">homebrew</a>.</li>
<li>Install driver</li>
</ol>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>brew install https://raw.githubusercontent.com/proller/homebrew-core/chodbc/Formula/clickhouse-odbc.rb
</span></span></code></pre></div><ol start="3">
<li>Add clickhouse DSN configuration into ~/.odbc.ini file. (<a href="">sample</a>)</li>
</ol>
<p>Note: that install driver linked against iodbc (which is default for Mac), some homebrew applications
(like python) may require unixodbc driver to work properly. In that case see Build section below.</p>
<h3 id="linux">Linux</h3>
<ol>
<li>DEB/RPM packaging is not provided yet, please build &amp; install the driver from sources.</li>
<li>Add clickhouse DSN configuration into ~/.odbc.ini file. (<a href="">sample</a>)</li>
</ol>
<h2 id="configuration">Configuration</h2>
<p>On Linux / Max you configure DSN by adding new desctions in ~/.odbc.ini
(See sample file: <a href="https://github.com/ClickHouse/clickhouse-odbc/blob/fd74398b50201ab13b535cdfab57bca86e588b37/packaging/odbc.ini.sample" target="_blank">https://github.com/ClickHouse/clickhouse-odbc/blob/fd74398b50201ab13b535cdfab57bca86e588b37/packaging/odbc.ini.sample</a> )</p>
<p>On Windows you can create/edit DSN using GUI tool through Control Panel.</p>
<p>The list of DSN parameters recognized by the driver is as follows:</p>
<table>
<thead>
<tr>
<th style="text-align:center">Parameter</th>
<th style="text-align:center">Default value</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>Url</code></td>
<td style="text-align:center">empty</td>
<td style="text-align:left">URL that points to a running ClickHouse instance, may include username, password, port, database, etc.</td>
</tr>
<tr>
<td style="text-align:center"><code>Proto</code></td>
<td style="text-align:center">deduced from <code>Url</code>, or from <code>Port</code> and <code>SSLMode</code>: <code>https</code> if <code>443</code> or <code>8443</code> or <code>SSLMode</code> is not empty, <code>http</code> otherwise</td>
<td style="text-align:left">Protocol, one of: <code>http</code>, <code>https</code></td>
</tr>
<tr>
<td style="text-align:center"><code>Server</code> or <code>Host</code></td>
<td style="text-align:center">deduced from <code>Url</code></td>
<td style="text-align:left">IP or hostname of a server with a running ClickHouse instance on it</td>
</tr>
<tr>
<td style="text-align:center"><code>Port</code></td>
<td style="text-align:center">deduced from <code>Url</code>, or from <code>Proto</code>: <code>8443</code> if <code>https</code>, <code>8123</code> otherwise</td>
<td style="text-align:left">Port on which the ClickHouse instance is listening</td>
</tr>
<tr>
<td style="text-align:center"><code>Path</code></td>
<td style="text-align:center"><code>/query</code></td>
<td style="text-align:left">Path portion of the URL</td>
</tr>
<tr>
<td style="text-align:center"><code>UID</code> or <code>Username</code></td>
<td style="text-align:center"><code>default</code></td>
<td style="text-align:left">User name</td>
</tr>
<tr>
<td style="text-align:center"><code>PWD</code> or <code>Password</code></td>
<td style="text-align:center">empty</td>
<td style="text-align:left">Password</td>
</tr>
<tr>
<td style="text-align:center"><code>Database</code></td>
<td style="text-align:center"><code>default</code></td>
<td style="text-align:left">Database name to connect to</td>
</tr>
<tr>
<td style="text-align:center"><code>Timeout</code></td>
<td style="text-align:center"><code>30</code></td>
<td style="text-align:left">Connection timeout</td>
</tr>
<tr>
<td style="text-align:center"><code>SSLMode</code></td>
<td style="text-align:center">empty</td>
<td style="text-align:left">Certificate verification method (used by TLS/SSL connections, ignored in Windows), one of: <code>allow</code>, <code>prefer</code>, <code>require</code>, use <code>allow</code> to enable <a href="https://www.openssl.org/docs/manmaster/man3/SSL_CTX_set_verify.html" target="_blank">&lt;code&gt;SSL_VERIFY_PEER&lt;/code&gt;</a> TLS/SSL certificate verification mode, <a href="https://www.openssl.org/docs/manmaster/man3/SSL_CTX_set_verify.html" target="_blank">&lt;code&gt;SSL_VERIFY_PEER | SSL_VERIFY_FAIL_IF_NO_PEER_CERT&lt;/code&gt;</a> is used otherwise</td>
</tr>
<tr>
<td style="text-align:center"><code>PrivateKeyFile</code></td>
<td style="text-align:center">empty</td>
<td style="text-align:left">Path to private key file (used by TLS/SSL connections), can be empty if no private key file is used</td>
</tr>
<tr>
<td style="text-align:center"><code>CertificateFile</code></td>
<td style="text-align:center">empty</td>
<td style="text-align:left">Path to certificate file (used by TLS/SSL connections, ignored in Windows), if the private key and the certificate are stored in the same file, this can be empty if <code>PrivateKeyFile</code> is specified</td>
</tr>
<tr>
<td style="text-align:center"><code>CALocation</code></td>
<td style="text-align:center">empty</td>
<td style="text-align:left">Path to the file or directory containing the CA/root certificates (used by TLS/SSL connections, ignored in Windows)</td>
</tr>
<tr>
<td style="text-align:center"><code>DriverLog</code></td>
<td style="text-align:center"><code>on</code> if <code>CMAKE_BUILD_TYPE</code> is <code>Debug</code>, <code>off</code> otherwise</td>
<td style="text-align:left">Enable or disable the extended driver logging</td>
</tr>
<tr>
<td style="text-align:center"><code>DriverLogFile</code></td>
<td style="text-align:center"><code>\temp\clickhouse-odbc-driver.log</code>  on Windows, <code>/tmp/clickhouse-odbc-driver.log</code> otherwise</td>
<td style="text-align:left">Path to the extended driver log file (used when <code>DriverLog</code> is <code>on</code>)</td>
</tr>
</tbody>
</table>
<h2 id="troubleshooting--bug-reporting">Troubleshooting &amp; bug reporting</h2>
<p>If some software doesn&rsquo;t work properly with that driver, but works good with other drivers - we will be appritiate if you will be able to collect debug info.</p>
<p>To debug issues with the driver, first things that need to be done are:</p>
<ul>
<li>enabling driver manager tracing. Links may contain some irrelevant vendor-specific details.
<ul>
<li>on Windows/MDAC: <a href="https://dev.mysql.com/doc/connector-odbc/en/connector-odbc-configuration-trace-windows.html" target="_blank">1</a>, <a href="https://www.simba.com/blog/odbc-troubleshooting-tracing/" target="_blank">2</a>, <a href="https://docs.microsoft.com/en-us/sql/odbc/reference/develop-app/enabling-tracing" target="_blank">3</a></li>
<li>on Mac/iODBC: <a href="https://www.simba.com/blog/odbc-troubleshooting-tracing/" target="_blank">1</a>, <a href="http://www.iodbc.org/dataspace/doc/iodbc/wiki/iodbcWiki/FAQ#Tracing%20Application%20Behavior" target="_blank">2</a></li>
<li>on Linux/unixODBC: <a href="https://www.simba.com/blog/odbc-troubleshooting-tracing/" target="_blank">1</a>, <a href="https://www.easysoft.com/support/kb/kb00945.html" target="_blank">2</a></li>
</ul>
</li>
<li>enabling driver logging, see <code>DriverLog</code> and <code>DriverLogFile</code> DSN parameters above</li>
<li>making sure that the application is allowed to create and write these driver log and driver manager trace files</li>
<li>follow the steps leading to the issue.</li>
</ul>
<p>Collected log files will help to diagnose &amp; solve the issue.</p>
<h2 id="driver-managers">Driver Managers</h2>
<p>Note, that since ODBC drivers are not used directly by a user, but rather accessed through applications, which in their turn access the driver through ODBC driver manager, user have to install the driver for the <strong>same architecture</strong> (32- or 64-bit) as the application that is going to access the driver. Moreover, both the driver and the application must be compiled for (and actually use during run-time) the <strong>same ODBC driver manager implementation</strong> (we call them &ldquo;ODBC providers&rdquo; here). There are three supported ODBC providers:</p>
<ul>
<li>ODBC driver manager associated with <strong>MDAC</strong> (Microsoft Data Access Components, sometimes referenced as WDAC, Windows Data Access Components) - the standard ODBC provider of Windows</li>
<li><strong>UnixODBC</strong> - the most common ODBC provider in Unix-like systems. Theoretically, could be used in Cygwin or MSYS/MinGW environments in Windows too.</li>
<li><strong>iODBC</strong> - less common ODBC provider, mainly used in Unix-like systems, however, it is the standard ODBC provider in macOS. Theoretically, could be used in Cygwin or MSYS/MinGW environments in Windows too.</li>
</ul>
<p>If you don&rsquo;t see a package that matches your platforms, or the version of your system is significantly different than those of the available packages, or maybe you want to try a bleeding edge version of the code that hasn&rsquo;t been released yet, you can always build the driver manually from sources.</p>
<p>Note, that it is always a good idea to install the driver from the corresponding <strong>native</strong> package (<!-- `.deb`, `.rpm`, --><code>.msi</code>, etc., which you can also easily create if you are building from sources), than use the binaries that were manually copied to some folder.</p>
<h2 id="building-from-sources">Building from sources</h2>
<p>The general requirements for building the driver from sources are as follows:</p>
<ul>
<li>CMake 3.12 and later</li>
<li>C++17 and C11 capable compiler toolchain:
<ul>
<li>Clang 4 and later</li>
<li>GCC 7 and later</li>
<li>Xcode 10 and later</li>
<li>Microsoft Visual Studio 2017 and later</li>
</ul>
</li>
<li>ODBC Driver manager (MDAC / unixodbc / iODBC)</li>
<li>SSL library (openssl)</li>
</ul>
<p>Generic build scenario:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>git clone --recursive git@github.com:ClickHouse/clickhouse-odbc.git
</span></span><span style="display:flex;"><span><span style="color:#204a87">cd</span> clickhouse-odbc
</span></span><span style="display:flex;"><span>mkdir build
</span></span><span style="display:flex;"><span><span style="color:#204a87">cd</span> build
</span></span><span style="display:flex;"><span>cmake -DCMAKE_BUILD_TYPE<span style="color:#ce5c00;font-weight:bold">=</span>RelWithDebInfo ..
</span></span><span style="display:flex;"><span>cmake --build . -C RelWithDebInfo
</span></span></code></pre></div><p>Additional requirements exist for each platform, which also depend on whether packaging and/or testing is performed.</p>
<h3 id="linuxmacos">Linux/macOS</h3>
<p>Execute the following in the terminal to install needed dependencies:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># on Red Hat/CentOS (tested on CentOS 7)</span>
</span></span><span style="display:flex;"><span>sudo yum groupinstall <span style="color:#4e9a06">&#34;Development Tools&#34;</span>
</span></span><span style="display:flex;"><span>sudo yum install centos-release-scl
</span></span><span style="display:flex;"><span>sudo yum install devtoolset-8
</span></span><span style="display:flex;"><span>sudo yum install git cmake openssl-devel unixODBC-devel <span style="color:#8f5902;font-style:italic"># You may use libiodbc-devel INSTEAD of unixODBC-devel</span>
</span></span><span style="display:flex;"><span>scl <span style="color:#204a87">enable</span> devtoolset-8 -- bash <span style="color:#8f5902;font-style:italic"># Enable Software collections for that terminal session, to use newer versions of complilers</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># on Ubuntu (tested on Ubuntu 18.10, for older versions you may need to install newer c++ compiler and cmake versions)</span>
</span></span><span style="display:flex;"><span>sudo apt install build-essential git cmake libpoco-dev libssl-dev unixodbc-dev <span style="color:#8f5902;font-style:italic"># You may use libiodbc-devel INSEAD of unixODBC-devel</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># MacOS: </span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># You will need Xcode 10 or later and Command Line Tools to be installed, as well as [Homebrew](https://brew.sh/).</span>
</span></span><span style="display:flex;"><span>brew install git cmake make poco openssl libiodbc <span style="color:#8f5902;font-style:italic"># You may use unixodbc INSTEAD of libiodbc </span>
</span></span></code></pre></div><p><strong>Note:</strong> usually on Linux you use unixODBC driver manager, and on Mac - iODBC.
In some (rare) cases you may need use other driver manager, please do it only
if you clearly understand the differencies. Driver should be used with the driver
manager it was linked to.</p>
<p>Clone the repo with submodules:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>git clone --recursive git@github.com:ClickHouse/clickhouse-odbc.git
</span></span></code></pre></div><p>Enter the cloned source tree, create a temporary build folder, and generate a Makefile for the project in it:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#204a87">cd</span> clickhouse-odbc
</span></span><span style="display:flex;"><span>mkdir build
</span></span><span style="display:flex;"><span><span style="color:#204a87">cd</span> build
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Configuration options for the project can be specified in the next command in a form of &#39;-Dopt=val&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># For MacOS: you may also add &#39;-G Xcode&#39; to the next command, in order to use Xcode as a build system or IDE, and generate the solution and project files instead of Makefile.</span>
</span></span><span style="display:flex;"><span>cmake -DCMAKE_BUILD_TYPE<span style="color:#ce5c00;font-weight:bold">=</span>RelWithDebInfo ..
</span></span></code></pre></div><p>Build the generated solution in-place:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cmake --build . -C RelWithDebInfo
</span></span><span style="display:flex;"><span>cmake --build . -C RelWithDebInfo --target package
</span></span></code></pre></div><p>&hellip;and, optionally, run tests (note, that for non-unit tests, preconfigured driver and DSN entries must exist, that point to the binaries generated in this build folder):</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cmake --build . -C RelWithDebInfo --target <span style="color:#204a87">test</span>
</span></span></code></pre></div><p>For MacOS: if you configured the project with &lsquo;-G Xcode&rsquo; initially, open the IDE and build <code>all</code>, <code>package</code>, and <code>test</code> targets manually from there</p>
<pre tabindex="0"><code>cmake --open .
</code></pre><h3 id="windows-1">Windows</h3>
<p>CMake bundled with the recent versions of Visual Studio can be used.</p>
<p>An SDK required for building the ODBC driver is included in Windows SDK, which in its turn is also bundled with Visual Studio.</p>
<p>You will need to install WiX toolset to be able to generate <code>.msi</code> packages. You can download and install it from <a href="https://wixtoolset.org/" target="_blank">WiX toolset home page</a>.</p>
<p>All of the following commands have to be issued in Visual Studio Command Prompt:</p>
<ul>
<li>use <code>x86 Native Tools Command Prompt for VS 2019</code> or equivalent for 32-bit builds</li>
<li>use <code>x64 Native Tools Command Prompt for VS 2019</code> or equivalent for 64-bit builds</li>
</ul>
<p>Clone the repo with submodules:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>git clone --recursive git@github.com:ClickHouse/clickhouse-odbc.git
</span></span></code></pre></div><p>Enter the cloned source tree, create a temporary build folder, and generate the solution and project files in it:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#204a87">cd</span> clickhouse-odbc
</span></span><span style="display:flex;"><span>mkdir build
</span></span><span style="display:flex;"><span><span style="color:#204a87">cd</span> build
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Configuration options for the project can be specified in the next command in a form of &#39;-Dopt=val&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Use the following command for 32-bit build only.</span>
</span></span><span style="display:flex;"><span>cmake -A Win32 -DCMAKE_BUILD_TYPE<span style="color:#ce5c00;font-weight:bold">=</span>RelWithDebInfo ..
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Use the following command for 64-bit build only.</span>
</span></span><span style="display:flex;"><span>cmake -A x64 -DCMAKE_BUILD_TYPE<span style="color:#ce5c00;font-weight:bold">=</span>RelWithDebInfo ..
</span></span></code></pre></div><p>Build the generated solution in-place:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cmake --build . -C RelWithDebInfo
</span></span><span style="display:flex;"><span>cmake --build . -C RelWithDebInfo --target package
</span></span></code></pre></div><p>&hellip;and, optionally, run tests (note, that for non-unit tests, preconfigured driver and DSN entries must exist, that point to the binaries generated in this build folder):</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cmake --build . -C RelWithDebInfo --target <span style="color:#204a87">test</span>
</span></span></code></pre></div><p>&hellip;or open the IDE and build <code>all</code>, <code>package</code>, and <code>test</code> targets manually from there:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cmake --open .
</span></span></code></pre></div><h3 id="cmake-options">cmake options</h3>
<p>The list of configuration options recognized during the CMake generation step is as follows:</p>
<table>
<thead>
<tr>
<th style="text-align:center">Option</th>
<th style="text-align:center">Default value</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>CMAKE_BUILD_TYPE</code></td>
<td style="text-align:center"><code>RelWithDebInfo</code></td>
<td style="text-align:left">Build type, one of: <code>Debug</code>, <code>Release</code>, <code>RelWithDebInfo</code></td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_ENABLE_SSL</code></td>
<td style="text-align:center"><code>ON</code></td>
<td style="text-align:left">Enable TLS/SSL (required for utilizing <code>https://</code> interface, etc.)</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_ENABLE_INSTALL</code></td>
<td style="text-align:center"><code>ON</code></td>
<td style="text-align:left">Enable install targets (required for packaging)</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_ENABLE_TESTING</code></td>
<td style="text-align:center">inherits value of <code>BUILD_TESTING</code></td>
<td style="text-align:left">Enable test targets</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_PREFER_BUNDLED_THIRD_PARTIES</code></td>
<td style="text-align:center"><code>ON</code></td>
<td style="text-align:left">Prefer bundled over system variants of third party libraries</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_PREFER_BUNDLED_POCO</code></td>
<td style="text-align:center">inherits value of <code>CH_ODBC_PREFER_BUNDLED_THIRD_PARTIES</code></td>
<td style="text-align:left">Prefer bundled over system variants of Poco library</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_PREFER_BUNDLED_SSL</code></td>
<td style="text-align:center">inherits value of <code>CH_ODBC_PREFER_BUNDLED_POCO</code></td>
<td style="text-align:left">Prefer bundled over system variants of TLS/SSL library</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_PREFER_BUNDLED_GOOGLETEST</code></td>
<td style="text-align:center">inherits value of <code>CH_ODBC_PREFER_BUNDLED_THIRD_PARTIES</code></td>
<td style="text-align:left">Prefer bundled over system variants of Google Test library</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_PREFER_BUNDLED_NANODBC</code></td>
<td style="text-align:center">inherits value of <code>CH_ODBC_PREFER_BUNDLED_THIRD_PARTIES</code></td>
<td style="text-align:left">Prefer bundled over system variants of nanodbc library</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_RUNTIME_LINK_STATIC</code></td>
<td style="text-align:center"><code>OFF</code></td>
<td style="text-align:left">Link with compiler and language runtime statically</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_THIRD_PARTY_LINK_STATIC</code></td>
<td style="text-align:center"><code>ON</code></td>
<td style="text-align:left">Link with third party libraries statically</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_DEFAULT_DSN_ANSI</code></td>
<td style="text-align:center"><code>ClickHouse DSN (ANSI)</code></td>
<td style="text-align:left">Default ANSI DSN name</td>
</tr>
<tr>
<td style="text-align:center"><code>CH_ODBC_DEFAULT_DSN_UNICODE</code></td>
<td style="text-align:center"><code>ClickHouse DSN (Unicode)</code></td>
<td style="text-align:left">Default Unicode DSN name</td>
</tr>
<tr>
<td style="text-align:center"><code>TEST_DSN</code></td>
<td style="text-align:center">inherits value of <code>CH_ODBC_DEFAULT_DSN_ANSI</code></td>
<td style="text-align:left">ANSI DSN name to use in tests</td>
</tr>
<tr>
<td style="text-align:center"><code>TEST_DSN_W</code></td>
<td style="text-align:center">inherits value of <code>CH_ODBC_DEFAULT_DSN_UNICODE</code></td>
<td style="text-align:left">Unicode DSN name to use in tests</td>
</tr>
</tbody>
</table>
<h3 id="packaging--redistributing-the-driver">Packaging / redistributing the driver</h3>
<p>You can just copy the library to another computer, in that case you need to</p>
<ol>
<li>install run-time dependencies on target computer
<ul>
<li>Windows:
<ul>
<li>MDAC driver manager (preinstalled on all modern Windows systems)</li>
<li><code>C++ Redistributable for Visual Studio 2017</code> or same for <code>2019</code>, etc.</li>
</ul>
</li>
<li>Linux</li>
</ul>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># CentOS / RedHat</span>
</span></span><span style="display:flex;"><span>sudo yum install openssl unixODBC
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic"># Debian/Ubuntu</span>
</span></span><span style="display:flex;"><span>sudo apt install openssl unixodbc
</span></span></code></pre></div><ul>
<li>MacOS (assuming you have <a href="https://brew.sh/" target="_blank">Homebrew</a> installed):</li>
</ul>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>brew install poco openssl libiodbc
</span></span></code></pre></div><ol start="2">
<li>register the driver so that the corresponding ODBC provider is able to locate it.</li>
</ol>
<p>All this involves modifying a dedicated registry keys in case of MDAC, or editing <code>odbcinst.ini</code> (for driver registration) and <code>odbc.ini</code> (for DSN definition) files for UnixODBC or iODBC, directly or indirectly.</p>
<p>This will be done automatically using some default values if you are installing the driver using native installers.</p>
<p>Otherwise, if you are configuring manually, or need to modify the default configuration created by the installer, please see the exact locations of files (or registry keys) that need to be modified.</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-d2afec8f52450d3642df08e91fab21b4">4 - ClickHouse &#43; Spark</h1>
    <div class="lead">Spark</div>
	<h2 id="clickhouse--spark">ClickHouse + Spark</h2>
<h3 id="jdbc">jdbc</h3>
<p>The trivial &amp; natural way to talk to ClickHouse from Spark is using jdbc. There are 2 jdbc drivers:</p>
<ul>
<li><a href="https://github.com/ClickHouse/clickhouse-jdbc/" target="_blank">https://github.com/ClickHouse/clickhouse-jdbc/</a></li>
<li><a href="https://github.com/housepower/ClickHouse-Native-JDBC#integration-with-spark" target="_blank">https://github.com/housepower/ClickHouse-Native-JDBC#integration-with-spark</a></li>
</ul>
<p>ClickHouse-Native-JDBC has some hints about integration with Spark even in the main README file.</p>
<p>&lsquo;Official&rsquo; driver does support some conversion of complex data types (Roarring bitmaps) for Spark-Clickhouse integration: <a href="https://github.com/ClickHouse/clickhouse-jdbc/pull/596" target="_blank">https://github.com/ClickHouse/clickhouse-jdbc/pull/596</a></p>
<p>But proper partitioning of the data (to spark partitions) may be tricky with jdbc.</p>
<p>Some example snippets:</p>
<ul>
<li><a href="https://markelic.de/how-to-access-your-clickhouse-database-with-spark-in-python/" target="_blank">https://markelic.de/how-to-access-your-clickhouse-database-with-spark-in-python/</a></li>
<li><a href="https://stackoverflow.com/questions/60448877/how-can-i-write-spark-dataframe-to-clickhouse" target="_blank">https://stackoverflow.com/questions/60448877/how-can-i-write-spark-dataframe-to-clickhouse</a></li>
</ul>
<h3 id="connectors">Connectors</h3>
<ul>
<li><a href="https://github.com/DmitryBe/spark-clickhouse" target="_blank">https://github.com/DmitryBe/spark-clickhouse</a> (looks dead)</li>
<li><a href="https://github.com/VaBezruchko/spark-clickhouse-connector" target="_blank">https://github.com/VaBezruchko/spark-clickhouse-connector</a> (is not actively maintained).</li>
<li><a href="https://github.com/housepower/spark-clickhouse-connector" target="_blank">https://github.com/housepower/spark-clickhouse-connector</a>  (actively developing connector from housepower - same guys as authors of ClickHouse-Native-JDBC)</li>
</ul>
<h3 id="via-kafka">via Kafka</h3>
<p>ClickHouse can produce / consume data from/to Kafka to exchange data with Spark.</p>
<h3 id="via-hdfs">via hdfs</h3>
<p>You can load data into hadoop/hdfs using sequence of statements like <code>INSERT INTO FUNCTION hdfs(...) SELECT ... FROM clickhouse_table</code>
later process the data from hdfs by spark and do the same in reverse direction.</p>
<h3 id="via-s3">via s3</h3>
<p>Similar to above but using s3.</p>
<h3 id="via-shell-calls">via shell calls</h3>
<p>You can call other commands from Spark. Those commands can be <code>clickhouse-client</code> and/or <code>clickhouse-local</code>.</p>
<h3 id="do-you-really-need-spark-">do you really need Spark? :)</h3>
<p>In many cases you can do everything inside ClickHouse without Spark help :)
Arrays, Higher-order functions, machine learning, integration with lot of different things including the possibility to run some external code using executable dictionaries or UDF.</p>
<h2 id="more-info--some-unordered-links-mostly-in-chinese--russian">More info + some unordered links (mostly in Chinese / Russian)</h2>
<ul>
<li>Spark + ClickHouse: not a fight, but a symbiosis <a href="https://github.com/ClickHouse/clickhouse-presentations/blob/master/meetup28/spark_and_clickhouse.pdf" target="_blank">https://github.com/ClickHouse/clickhouse-presentations/blob/master/meetup28/spark_and_clickhouse.pdf</a> (russian)</li>
<li>Using a bunch of ClickHouse and Spark in MFI Soft <a href="https://www.youtube.com/watch?v=ID8eTnmag0s" target="_blank">https://www.youtube.com/watch?v=ID8eTnmag0s</a> (russian)</li>
<li>Spark read and write ClickHouse <a href="https://yerias.github.io/2020/12/08/clickhouse/9/#Jdbc%E6%93%8D%E4%BD%9Cclickhouse" target="_blank">https://yerias.github.io/2020/12/08/clickhouse/9/#Jdbc%E6%93%8D%E4%BD%9Cclickhouse</a></li>
<li>Spark reads and writes ClickHouse through jdbc <a href="https://blog.katastros.com/a?ID=01800-e40e1b3c-5fa4-4ea0-a3a8-f5e89ef0ce14" target="_blank">https://blog.katastros.com/a?ID=01800-e40e1b3c-5fa4-4ea0-a3a8-f5e89ef0ce14</a></li>
<li>Spark JDBC write clickhouse operation summary <a href="https://www.jianshu.com/p/43f78c8a025b?hmsr=toutiao.io&amp;utm_campaign=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target="_blank">https://www.jianshu.com/p/43f78c8a025b?hmsr=toutiao.io&amp;utm_campaign=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io</a>  <a href="https://toutiao.io/posts/m63yw89/preview" target="_blank">https://toutiao.io/posts/m63yw89/preview</a></li>
<li>Spark-sql is based on Clickhouse&rsquo;s DataSourceV2 data source extension (russian)
<a href="https://www.cnblogs.com/mengyao/p/4689866.html" target="_blank">https://www.cnblogs.com/mengyao/p/4689866.html</a></li>
<li>Alibaba integration instructions <a href="https://www.alibabacloud.com/help/doc-detail/191192.htm" target="_blank">https://www.alibabacloud.com/help/doc-detail/191192.htm</a></li>
<li>Tencent integration instructions <a href="https://intl.cloud.tencent.com/document/product/1026/35884" target="_blank">https://intl.cloud.tencent.com/document/product/1026/35884</a></li>
<li>Yandex DataProc demo: loading files from S3 to ClickHouse with Spark <a href="https://www.youtube.com/watch?v=N3bZW0_rRzI" target="_blank">https://www.youtube.com/watch?v=N3bZW0_rRzI</a></li>
<li>Clickhouse official documentation_Spark JDBC writes some pits of ClickHouse  <a href="https://blog.csdn.net/weixin_39615984/article/details/111206050" target="_blank">https://blog.csdn.net/weixin_39615984/article/details/111206050</a></li>
<li>ClickHouse data import (Flink, Spark, Kafka, MySQL, Hive) <a href="https://zhuanlan.zhihu.com/p/299094269" target="_blank">https://zhuanlan.zhihu.com/p/299094269</a></li>
<li>Baifendian Big Data Technical Team: Practice of ClickHouse data synchronization solutionbased on multiple Spark tasks. <a href="https://www.6aiq.com/article/1635461873075" target="_blank">https://www.6aiq.com/article/1635461873075</a></li>
<li>SPARK-CLICKHOUSE-ES REAL-TIME PROJECT EIGHTH DAY-PRECISE ONE-TIME CONSUMPTION SAVE OFFSET. <a href="https://www.freesion.com/article/71421322524/" target="_blank">https://www.freesion.com/article/71421322524/</a></li>
<li>Still struggling with real-time data warehouse selection, Spark + ClickHouse makes yoamazing! <a href="https://dbaplus.cn/news-73-3806-1.html" target="_blank">https://dbaplus.cn/news-73-3806-1.html</a></li>
<li>HDFS+ClickHouse+Spark: A lightweight big data analysis system from 0 to 1. <a href="https://juejin.cn/post/6850418114962653198" target="_blank">https://juejin.cn/post/6850418114962653198</a></li>
<li>ClickHouse Clustering for Spark Developer <a href="http://blog.madhukaraphatak.com/clickouse-clustering-spark-developer/" target="_blank">http://blog.madhukaraphatak.com/clickouse-clustering-spark-developer/</a></li>
<li>«Иногда приходится заглядывать в код Spark»: Александр Морозов (SEMrush) об использовании Scala, Spark и ClickHouse.  <a href="https://habr.com/ru/company/jugru/blog/341288/" target="_blank">https://habr.com/ru/company/jugru/blog/341288/</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-490f1eab7bb37421ddd14a8d6c58e9ab">5 - BI Tools</h1>
    <div class="lead">Business Intelligence Tools</div>
	<ul>
<li>Superset: <a href="https://superset.apache.org/docs/databases/clickhouse" target="_blank">https://superset.apache.org/docs/databases/clickhouse</a></li>
<li>Metabase: <a href="https://github.com/enqueue/metabase-clickhouse-driver" target="_blank">https://github.com/enqueue/metabase-clickhouse-driver</a></li>
<li>Querybook: <a href="https://www.querybook.org/docs/setup_guide/connect_to_query_engines/#all-query-engines" target="_blank">https://www.querybook.org/docs/setup_guide/connect_to_query_engines/#all-query-engines</a></li>
<li>Tableau: <a href="https://github.com/Altinity/clickhouse-tableau-connector-odbc" target="_blank">Clickhouse Tableau connector odbc</a></li>
<li>Looker: <a href="https://docs.looker.com/setup-and-management/database-config/clickhouse" target="_blank">https://docs.looker.com/setup-and-management/database-config/clickhouse</a></li>
<li>Apache Zeppelin</li>
<li>SeekTable</li>
<li>ReDash</li>
<li>Mondrian: <a href="https://altinity.com/blog/accessing-clickhouse-from-excel-using-mondrian-rolap-engine" target="_blank">https://altinity.com/blog/accessing-clickhouse-from-excel-using-mondrian-rolap-engine</a></li>
<li>Grafana: <a href="https://docs.altinity.com/integrations/clickhouse-and-grafana/" target="_blank">Integrating Grafana with ClickHouse</a></li>
<li>Cumul.io</li>
<li>Tablum: <a href="https://tablum.io" target="_blank">https://tablum.io</a></li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-7a1dc52ba21a64be26ec5780459eb575">6 - CatBoost / MindsDB /  Fast.ai</h1>
    <div class="lead">CatBoost / MindsDB /  Fast.ai</div>
	

<div class="alert alert-info" role="alert">
<h4 class="alert-heading">Info</h4>

    Article is based on feedback provided by one of Altinity clients.

</div>

<p>CatBoost:</p>
<ul>
<li>It uses gradient boosting - a hard to use technique which can outperform neural networks. Gradient boosting is powerful but it&rsquo;s easy to shoot yourself in the foot using it.</li>
<li>The documentation on how to use it is quite lacking. The only good source of information on how to properly configure a model to yield good results is this video: <a href="https://www.youtube.com/watch?v=usdEWSDisS0" target="_blank">https://www.youtube.com/watch?v=usdEWSDisS0</a> . We had to dig around GitHub issues to find out how to make it work with ClickHouse.</li>
<li>CatBoost is fast. Other libraries will take ~5X to ~10X as long to do what CatBoost does.</li>
<li>CatBoost will do preprocessing out of the box (fills nulls, apply standard scaling, encodes strings as numbers).</li>
<li>CatBoost has all functions you&rsquo;d need (metrics, plotters, feature importance)</li>
</ul>
<p>It makes sense to split what CatBoost does into 2 parts:</p>
<ul>
<li>preprocessing (fills nulls, apply standard scaling, encodes strings as numbers)</li>
<li>number crunching (convert preprocessed numbers to another number - ex: revenue of impression)</li>
</ul>
<p>Compared to <a href="http://fast.ai/" target="_blank">Fast.ai</a>, CatBoost pre-processing is as simple to use and produces results that can be as good as <a href="http://fast.ai/" target="_blank">Fast.ai</a>.</p>
<p>The number crunching part of <a href="http://fast.ai/" target="_blank">Fast.ai</a> is no-config. For CatBoost you need to configure it, a lot.</p>
<p>CatBoost won&rsquo;t simplify or hide any complexity of the process. So you need to know data science terms and what it does (ex: if your model is underfitting you can use a smaller l2_reg parameter in the model constructor).</p>
<p>In the end both <a href="http://fast.ai/" target="_blank">Fast.ai</a> and CatBoost can yield comparable results.</p>
<p>Regarding deploying models, CatBoost is really good. The model runs fast, it has a simple binary format which can be loaded in ClickHouse, C, or Python and it will encapsulate pre-processing with the binary file. Deploying <a href="http://fast.ai/" target="_blank">Fast.ai</a> models at scale/speed is impossible out of the box (we have our custom solution to do it which is not simple).</p>
<p>TLDR: CatBoost is fast, produces awesome models, is super easy to deploy and it&rsquo;s easy to use/train (after becoming familiar with it despite the bad documentation &amp; if you know data science terms).</p>
<h2 id="regarding-mindsdb">Regarding MindsDB</h2>
<p>The project seems to be a good idea but it&rsquo;s too young. I was using the GUI version and I&rsquo;ve encountered some bugs, and none of those bugs have a good error message.</p>
<ul>
<li>
<p>It won&rsquo;t show data in preview.</p>
</li>
<li>
<p>The &ldquo;download&rdquo; button won&rsquo;t work.</p>
</li>
<li>
<p>It&rsquo;s trying to create and drop tables in ClickHouse without me asking it to.</p>
</li>
<li>
<p>Other than bugs:</p>
<ul>
<li>It will only use 1 core to do everything (training, analysis, download).</li>
<li>Analysis will only run with a very small subset of data, if I use something like 1M rows it never finishes.</li>
</ul>
</li>
<li>
<p>Training a model on 100k rows took 25 minutes - (CatBoost takes 90s to train with 1M rows)</p>
</li>
<li>
<p>The model trained on MindsDB is way worse. It had r-squared of 0.46 (CatBoost=0.58)</p>
<p>To me it seems that they are a plugin which connects ClickHouse to MySQL to run the model in Pytorch.</p>
<p>It&rsquo;s too complex and hard to debug and understand. The resulting model is not good enough.</p>
<p>TLDR: Easy to use (if bugs are ignored), too slow to train &amp; produces a bad model.</p>
</li>
</ul>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-902c0f257a8ddd6f658f1246ef020032">7 - Google S3 (GCS)</h1>
    <div class="lead">&ldquo;Google S3 GCS&rdquo;</div>
	<p>GCS with the table function - seems to work correctly for simple scenarios.</p>
<p>Essentially you can follow the steps from the <a href="https://cloud.google.com/storage/docs/migrating#migration-simple" target="_blank">Migrating from Amazon S3 to Cloud Storage</a>.</p>
<ol>
<li>Set up a GCS bucket.</li>
<li>This bucket must be set as part of the default project for the account. This configuration can be found in settings -&gt; interoperability.</li>
<li>Generate a HMAC key for the account, can be done in settings -&gt; interoperability, in the section for user account access keys.</li>
<li>In ClickHouse, replace the S3 bucket endpoint with the GCS bucket endpoint This must be done with the path-style GCS endpoint: <code>https://storage.googleapis.com/BUCKET_NAME/OBJECT_NAME</code>.</li>
<li>Replace the aws access key id and aws secret access key with the corresponding parts of the HMAC key.</li>
</ol>
<p>s3 Disk on the top of GCS and writing to GSC may be NOT working because GCS don&rsquo;t support some of bulk S3 API calls, see <a href="https://github.com/ClickHouse/ClickHouse/issues/24246" target="_blank">https://github.com/ClickHouse/ClickHouse/issues/24246</a></p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-baebc0ff2257ac7906ebf1b6671d8990">8 - Kafka</h1>
    <div class="lead">Kafka</div>
	<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git log -- contrib/librdkafka <span style="color:#000;font-weight:bold">|</span> git name-rev --stdin
</span></span></code></pre></div><table>
<thead>
<tr>
<th style="text-align:left"><strong>ClickHouse version</strong></th>
<th style="text-align:left"><strong>librdkafka version</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">21.10+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/27883" target="_blank">#27883</a>)</td>
<td style="text-align:left"><a href="https://github.com/edenhill/librdkafka/blob/v1.6.1/CHANGELOG.md" target="_blank">1.6.1</a> + snappy fixes + boring ssl + illumos_build fixes + edenhill#3279 fix</td>
</tr>
<tr>
<td style="text-align:left">21.6+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/23874" target="_blank">#23874</a>)</td>
<td style="text-align:left"><a href="https://github.com/edenhill/librdkafka/blob/v1.6.1/CHANGELOG.md" target="_blank">1.6.1</a> + snappy fixes + boring ssl + illumos_build fixes</td>
</tr>
<tr>
<td style="text-align:left">21.1+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/18671" target="_blank">#18671</a>)</td>
<td style="text-align:left"><a href="https://github.com/edenhill/librdkafka/blob/v1.6.0-RC3/CHANGELOG.md" target="_blank">1.6.0-RC3</a> + snappy fixes + boring ssl</td>
</tr>
<tr>
<td style="text-align:left">20.13+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/18053" target="_blank">#18053</a>)</td>
<td style="text-align:left"><a href="https://github.com/edenhill/librdkafka/blob/v1.5.0/CHANGELOG.md" target="_blank">1.5.0</a> + msan fixes + snappy fixes + boring ssl</td>
</tr>
<tr>
<td style="text-align:left">20.7+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/12991" target="_blank">#12991</a>)</td>
<td style="text-align:left"><a href="https://github.com/edenhill/librdkafka/blob/v1.5.0/CHANGELOG.md" target="_blank">1.5.0</a> + msan fixes</td>
</tr>
<tr>
<td style="text-align:left">20.5+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/11256" target="_blank">#11256</a>)</td>
<td style="text-align:left"><a href="https://github.com/edenhill/librdkafka/blob/v1.4.2/CHANGELOG.md" target="_blank">1.4.2</a></td>
</tr>
<tr>
<td style="text-align:left">20.2+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/9000" target="_blank">#9000</a>)</td>
<td style="text-align:left"><a href="https://github.com/edenhill/librdkafka/releases?after=v1.4.0-PRE1" target="_blank">1.3.0</a></td>
</tr>
<tr>
<td style="text-align:left">19.11+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/5872" target="_blank">#5872</a>)</td>
<td style="text-align:left"><a href="https://github.com/edenhill/librdkafka/releases?after=v1.1.0-selfstatic-test12" target="_blank">1.1.0</a></td>
</tr>
<tr>
<td style="text-align:left">19.5+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/4799" target="_blank">#4799</a>)</td>
<td style="text-align:left"><a href="https://github.com/edenhill/librdkafka/releases?after=v1.0.1-RC1" target="_blank">1.0.0</a></td>
</tr>
<tr>
<td style="text-align:left">19.1+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/4025" target="_blank">#4025</a>)</td>
<td style="text-align:left">1.0.0-RC5</td>
</tr>
<tr>
<td style="text-align:left">v1.1.54382+ (<a href="https://github.com/ClickHouse/ClickHouse/pull/2276" target="_blank">#2276</a>)</td>
<td style="text-align:left"><a href="https://github.com/edenhill/librdkafka/releases?after=v0.11.4-adminapi-post1" target="_blank">0.11.4</a></td>
</tr>
</tbody>
</table>

</div>



    
      
  
  
  
  

  
  

  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-b11bb1875d00a2b0ff0e60950c5360ed">8.1 - Adjusting librdkafka settings</h1>
    <div class="lead">Adjusting librdkafka settings</div>
	<ul>
<li>To set rdkafka options - add to <code>&lt;kafka&gt;</code> section in <code>config.xml</code> or preferably use a separate file in <code>config.d/</code>:
<ul>
<li><a href="https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md" target="_blank">https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md</a></li>
</ul>
</li>
</ul>
<p>Some random example:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;kafka&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;max_poll_interval_ms&gt;</span>60000<span style="color:#204a87;font-weight:bold">&lt;/max_poll_interval_ms&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;session_timeout_ms&gt;</span>60000<span style="color:#204a87;font-weight:bold">&lt;/session_timeout_ms&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;heartbeat_interval_ms&gt;</span>10000<span style="color:#204a87;font-weight:bold">&lt;/heartbeat_interval_ms&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;reconnect_backoff_ms&gt;</span>5000<span style="color:#204a87;font-weight:bold">&lt;/reconnect_backoff_ms&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;reconnect_backoff_max_ms&gt;</span>60000<span style="color:#204a87;font-weight:bold">&lt;/reconnect_backoff_max_ms&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;request_timeout_ms&gt;</span>20000<span style="color:#204a87;font-weight:bold">&lt;/request_timeout_ms&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;retry_backoff_ms&gt;</span>500<span style="color:#204a87;font-weight:bold">&lt;/retry_backoff_ms&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;message_max_bytes&gt;</span>20971520<span style="color:#204a87;font-weight:bold">&lt;/message_max_bytes&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;debug&gt;</span>all<span style="color:#204a87;font-weight:bold">&lt;/debug&gt;</span><span style="color:#8f5902;font-style:italic">&lt;!-- only to get the errors --&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;security_protocol&gt;</span>SSL<span style="color:#204a87;font-weight:bold">&lt;/security_protocol&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;ssl_ca_location&gt;</span>/etc/clickhouse-server/ssl/kafka-ca-qa.crt<span style="color:#204a87;font-weight:bold">&lt;/ssl_ca_location&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;ssl_certificate_location&gt;</span>/etc/clickhouse-server/ssl/client_clickhouse_client.pem<span style="color:#204a87;font-weight:bold">&lt;/ssl_certificate_location&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;ssl_key_location&gt;</span>/etc/clickhouse-server/ssl/client_clickhouse_client.key<span style="color:#204a87;font-weight:bold">&lt;/ssl_key_location&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;ssl_key_password&gt;</span>pass<span style="color:#204a87;font-weight:bold">&lt;/ssl_key_password&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;/kafka&gt;</span>
</span></span></code></pre></div><h2 id="authentication--connectivity">Authentication / connectivity</h2>
<h3 id="amazon-msk">Amazon MSK</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;yandex&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#204a87;font-weight:bold">&lt;kafka&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;security_protocol&gt;</span>sasl_ssl<span style="color:#204a87;font-weight:bold">&lt;/security_protocol&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;sasl_username&gt;</span>root<span style="color:#204a87;font-weight:bold">&lt;/sasl_username&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;sasl_password&gt;</span>toor<span style="color:#204a87;font-weight:bold">&lt;/sasl_password&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#204a87;font-weight:bold">&lt;/kafka&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;/yandex&gt;</span>
</span></span></code></pre></div><h3 id="saslscram">SASL/SCRAM</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;yandex&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#204a87;font-weight:bold">&lt;kafka&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;security_protocol&gt;</span>sasl_ssl<span style="color:#204a87;font-weight:bold">&lt;/security_protocol&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;sasl_mechanism&gt;</span>SCRAM-SHA-512<span style="color:#204a87;font-weight:bold">&lt;/sasl_mechanism&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;sasl_username&gt;</span>root<span style="color:#204a87;font-weight:bold">&lt;/sasl_username&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;sasl_password&gt;</span>toor<span style="color:#204a87;font-weight:bold">&lt;/sasl_password&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#204a87;font-weight:bold">&lt;/kafka&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;/yandex&gt;</span>
</span></span></code></pre></div><p><a href="https://leftjoin.ru/all/clickhouse-as-a-consumer-to-amazon-msk/" target="_blank">https://leftjoin.ru/all/clickhouse-as-a-consumer-to-amazon-msk/</a></p>
<h3 id="inline-kafka-certs">Inline Kafka certs</h3>
<p>To connect to some Kafka cloud services you may need to use certificates.</p>
<p>If needed they can be converted to pem format and inlined into ClickHouse config.xml
Example:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;kafka&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;ssl_key_pem&gt;</span><span style="color:#8f5902;font-style:italic">&lt;![CDATA[
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">  RSA Private-Key: (3072 bit, 2 primes)
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">    ....
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">-----BEGIN RSA PRIVATE KEY-----
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">...
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">-----END RSA PRIVATE KEY-----
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">]]&gt;</span><span style="color:#204a87;font-weight:bold">&lt;/ssl_key_pem&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;ssl_certificate_pem&gt;</span><span style="color:#8f5902;font-style:italic">&lt;![CDATA[
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">-----BEGIN CERTIFICATE-----
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">...
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">-----END CERTIFICATE-----
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">]]&gt;</span><span style="color:#204a87;font-weight:bold">&lt;/ssl_certificate_pem&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;/kafka&gt;</span>
</span></span></code></pre></div><p>See xml</p>
<p><a href="https://help.aiven.io/en/articles/489572-getting-started-with-aiven-kafka" target="_blank">https://help.aiven.io/en/articles/489572-getting-started-with-aiven-kafka</a></p>
<p><a href="https://stackoverflow.com/questions/991758/how-to-get-pem-file-from-key-and-crt-files" target="_blank">https://stackoverflow.com/questions/991758/how-to-get-pem-file-from-key-and-crt-files</a></p>
<h3 id="azure-event-hub">Azure Event Hub</h3>
<p>See <a href="https://github.com/ClickHouse/ClickHouse/issues/12609" target="_blank">https://github.com/ClickHouse/ClickHouse/issues/12609</a></p>
<h3 id="kerberos">Kerberos</h3>
<ul>
<li><a href="https://clickhouse.tech/docs/en/engines/table-engines/integrations/kafka/#kafka-kerberos-support" target="_blank">https://clickhouse.tech/docs/en/engines/table-engines/integrations/kafka/#kafka-kerberos-support</a></li>
<li><a href="https://github.com/ClickHouse/ClickHouse/blob/master/tests/integration/test_storage_kerberized_kafka/configs/kafka.xml" target="_blank">https://github.com/ClickHouse/ClickHouse/blob/master/tests/integration/test_storage_kerberized_kafka/configs/kafka.xml</a></li>
</ul>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span>  <span style="color:#8f5902;font-style:italic">&lt;!-- Kerberos-aware Kafka --&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#204a87;font-weight:bold">&lt;kafka&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;security_protocol&gt;</span>SASL_PLAINTEXT<span style="color:#204a87;font-weight:bold">&lt;/security_protocol&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;sasl_kerberos_keytab&gt;</span>/home/kafkauser/kafkauser.keytab<span style="color:#204a87;font-weight:bold">&lt;/sasl_kerberos_keytab&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;sasl_kerberos_principal&gt;</span>kafkauser/kafkahost@EXAMPLE.COM<span style="color:#204a87;font-weight:bold">&lt;/sasl_kerberos_principal&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#204a87;font-weight:bold">&lt;/kafka&gt;</span>
</span></span></code></pre></div><h3 id="confluent-cloud">confluent cloud</h3>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;yandex&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;kafka&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;auto_offset_reset&gt;</span>smallest<span style="color:#204a87;font-weight:bold">&lt;/auto_offset_reset&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;security_protocol&gt;</span>SASL_SSL<span style="color:#204a87;font-weight:bold">&lt;/security_protocol&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;ssl_endpoint_identification_algorithm&gt;</span>https<span style="color:#204a87;font-weight:bold">&lt;/ssl_endpoint_identification_algorithm&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;sasl_mechanism&gt;</span>PLAIN<span style="color:#204a87;font-weight:bold">&lt;/sasl_mechanism&gt;</span>
</span></span><span style="display:flex;"><span>xml<span style="color:#204a87;font-weight:bold">&lt;sasl_username&gt;</span>username<span style="color:#204a87;font-weight:bold">&lt;/sasl_username&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;sasl_password&gt;</span>password<span style="color:#204a87;font-weight:bold">&lt;/sasl_password&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;ssl_ca_location&gt;</span>probe<span style="color:#204a87;font-weight:bold">&lt;/ssl_ca_location&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8f5902;font-style:italic">&lt;!--
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">          &lt;ssl_ca_location&gt;/path/to/cert.pem&lt;/ssl_ca_location&gt;      
</span></span></span><span style="display:flex;"><span><span style="color:#8f5902;font-style:italic">        --&gt;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#204a87;font-weight:bold">&lt;/kafka&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#204a87;font-weight:bold">&lt;/yandex&gt;</span>
</span></span></code></pre></div><p><a href="https://docs.confluent.io/cloud/current/client-apps/config-client.html" target="_blank">https://docs.confluent.io/cloud/current/client-apps/config-client.html</a></p>
<h2 id="how-to-test-connection-settings">How to test connection settings</h2>
<p>Use kafkacat utility - it internally uses same library to access Kafla as clickhouse itself and allows easily to test different settings.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kafkacat -b my_broker:9092 -C -o -10 -t my_topic <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06"></span>   -X security.protocol<span style="color:#ce5c00;font-weight:bold">=</span>SASL_SSL  <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06"></span>   -X sasl.mechanisms<span style="color:#ce5c00;font-weight:bold">=</span>PLAIN <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06"></span>   -X sasl.username<span style="color:#ce5c00;font-weight:bold">=</span>uerName <span style="color:#4e9a06">\
</span></span></span><span style="display:flex;"><span><span style="color:#4e9a06"></span>   -X sasl.password<span style="color:#ce5c00;font-weight:bold">=</span>Password
</span></span></code></pre></div><h1 id="different-configurations-for-different-tables">Different configurations for different tables?</h1>
<blockquote>
<p>Is there some more documentation how to use this multiconfiguration for Kafka ?</p>
</blockquote>
<p>The whole logic is here:
<a href="https://github.com/ClickHouse/ClickHouse/blob/da4856a2be035260708fe2ba3ffb9e437d9b7fef/src/Storages/Kafka/StorageKafka.cpp#L466-L475" target="_blank">https://github.com/ClickHouse/ClickHouse/blob/da4856a2be035260708fe2ba3ffb9e437d9b7fef/src/Storages/Kafka/StorageKafka.cpp#L466-L475</a></p>
<p>So it load the main config first, after that it load (with overwrites) the configs for all topics,  <strong>listed in <code>kafka_topic_list</code> of the table</strong>.</p>
<p>Also since v21.12 it&rsquo;s possible to use more straght-forward way using named_collections:
<a href="https://github.com/ClickHouse/ClickHouse/pull/31691" target="_blank">https://github.com/ClickHouse/ClickHouse/pull/31691</a></p>
<p>So you can say something like</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">CREATE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">TABLE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">test</span><span style="color:#000;font-weight:bold">.</span><span style="color:#000">kafka</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">(</span><span style="color:#204a87;font-weight:bold">key</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">UInt64</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">value</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">UInt64</span><span style="color:#000;font-weight:bold">)</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">ENGINE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">Kafka</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">kafka1</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">kafka_format</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">&#39;CSV&#39;</span><span style="color:#000;font-weight:bold">);</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span></code></pre></div><p>And after that in configuration:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;clickhouse&gt;</span>
</span></span><span style="display:flex;"><span> <span style="color:#204a87;font-weight:bold">&lt;named_collections&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#204a87;font-weight:bold">&lt;kafka1&gt;</span>
</span></span><span style="display:flex;"><span>   <span style="color:#204a87;font-weight:bold">&lt;kafka_broker_list&gt;</span>kafka1:19092<span style="color:#204a87;font-weight:bold">&lt;/kafka_broker_list&gt;</span>
</span></span><span style="display:flex;"><span>   <span style="color:#204a87;font-weight:bold">&lt;kafka_topic_list&gt;</span>conf<span style="color:#204a87;font-weight:bold">&lt;/kafka_topic_list&gt;</span>
</span></span><span style="display:flex;"><span>   <span style="color:#204a87;font-weight:bold">&lt;kafka_group_name&gt;</span>conf<span style="color:#204a87;font-weight:bold">&lt;/kafka_group_name&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#204a87;font-weight:bold">&lt;/kafka1&gt;</span>
</span></span><span style="display:flex;"><span> <span style="color:#204a87;font-weight:bold">&lt;/named_collections&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">&lt;/clickhouse&gt;</span>
</span></span></code></pre></div><p>The same fragment of code in newer versions:
<a href="https://github.com/ClickHouse/ClickHouse/blob/d19e24f530c30f002488bc136da78f5fb55aedab/src/Storages/Kafka/StorageKafka.cpp#L474-L496" target="_blank">https://github.com/ClickHouse/ClickHouse/blob/d19e24f530c30f002488bc136da78f5fb55aedab/src/Storages/Kafka/StorageKafka.cpp#L474-L496</a></p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-d58f1474300f709dea11df04812ed578">8.2 - Error handling</h1>
    <div class="lead">Error handling</div>
	<h2 id="pre-216">Pre 21.6</h2>
<p>There are couple options:</p>
<p>Certain formats which has schema in built in them (like JSONEachRow) could silently skip any unexpected fields after enabling setting <code>input_format_skip_unknown_fields</code></p>
<p>It&rsquo;s also possible to skip up to N malformed messages for each block, with used setting <code>kafka_skip_broken_messages</code> but it&rsquo;s also does not support all possible formats.</p>
<h2 id="after-216">After 21.6</h2>
<p>It&rsquo;s possible to stream messages which could not be parsed, this behavior could be enabled via setting: <code>kafka_handle_error_mode='stream'</code> and clickhouse wil write error and message from Kafka itself to two new virtual columns: <code>_error, _raw_message</code>.</p>
<p>So you can create another Materialized View which would collect to a separate table all errors happening while parsing with all important information like offset and content of message.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#204a87;font-weight:bold">CREATE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">TABLE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">default</span><span style="color:#000;font-weight:bold">.</span><span style="color:#000">kafka_engine</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000;font-weight:bold">(</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#000">i</span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">Int64</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#000">s</span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">String</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000;font-weight:bold">)</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000">ENGINE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">Kafka</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000">SETTINGS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">kafka_broker_list</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#39;kafka:9092&#39;</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000">kafka_topic_list</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#39;topic&#39;</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000">kafka_group_name</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#39;clickhouse&#39;</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000">kafka_format</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#4e9a06">&#39;JSONEachRow&#39;</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000">kafka_handle_error_mode</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">&#39;stream&#39;</span><span style="color:#000;font-weight:bold">;</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">CREATE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">MATERIALIZED</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">VIEW</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">default</span><span style="color:#000;font-weight:bold">.</span><span style="color:#000">kafka_errors</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000;font-weight:bold">(</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#000">topic</span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">String</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#000">partition</span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">Int64</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#204a87;font-weight:bold">offset</span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">Int64</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#000">raw</span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">String</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#000">error</span><span style="color:#ce5c00;font-weight:bold">`</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">String</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000;font-weight:bold">)</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000">ENGINE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">MergeTree</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">ORDER</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">BY</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">topic</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">partition</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">offset</span><span style="color:#000;font-weight:bold">)</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#000">SETTINGS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">index_granularity</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#0000cf;font-weight:bold">8192</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">AS</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">SELECT</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#000">_topic</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">AS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">topic</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#000">_partition</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">AS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">partition</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#000">_offset</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">AS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">offset</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#000">_raw_message</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">AS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">raw</span><span style="color:#000;font-weight:bold">,</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline">    </span><span style="color:#000">_error</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">AS</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#000">error</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">FROM</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">default</span><span style="color:#000;font-weight:bold">.</span><span style="color:#000">kafka_engine</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span><span style="display:flex;"><span><span style="color:#f8f8f8;text-decoration:underline"></span><span style="color:#204a87;font-weight:bold">WHERE</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#204a87;font-weight:bold">length</span><span style="color:#000;font-weight:bold">(</span><span style="color:#000">_error</span><span style="color:#000;font-weight:bold">)</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#ce5c00;font-weight:bold">&gt;</span><span style="color:#f8f8f8;text-decoration:underline"> </span><span style="color:#0000cf;font-weight:bold">0</span><span style="color:#f8f8f8;text-decoration:underline">
</span></span></span></code></pre></div><p><img src="/assets/Untitled-2021-08-05-1027.png" alt="Table connections"></p>
<p><a href="https://github.com/ClickHouse/ClickHouse/pull/20249%5c#issuecomment-779054737" target="_blank">https://github.com/ClickHouse/ClickHouse/pull/20249#issuecomment-779054737</a></p>
<p><a href="https://github.com/ClickHouse/ClickHouse/pull/21850" target="_blank">https://github.com/ClickHouse/ClickHouse/pull/21850</a></p>
<p><a href="https://altinity.com/blog/clickhouse-kafka-engine-faq" target="_blank">https://altinity.com/blog/clickhouse-kafka-engine-faq</a></p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-d8f2388a49c064f3f21643937cbfcedc">8.3 - Exactly once semantics</h1>
    <div class="lead">Exactly once semantics</div>
	<p>EOS consumer (isolation.level=read_committed) is enabled by default since librdkafka 1.2.0, so for ClickHouse - since 20.2</p>
<p>See:</p>
<ul>
<li><a href="https://github.com/edenhill/librdkafka/commit/6b2a1552ac2a4ea09d915015183f268dd2df96e6" target="_blank">edenhill/librdkafka@6b2a155</a></li>
<li><a href="https://github.com/ClickHouse/ClickHouse/commit/9de5dffb5c97eb93545ae25eaf87ec195a590148" target="_blank">9de5dff</a></li>
</ul>
<p>BUT: while EOS semantics will guarantee you that no duplicates will happen on the Kafka side (i.e. even if you produce the same messages few times it will be consumed once), but ClickHouse as a Kafka client can currently guarantee only at-least-once. And in some corner cases (connection lost etc) you can get duplicates.</p>
<p>We need to have something like transactions on ClickHouse side to be able to avoid that. Adding something like simple transactions is in plans for Y2022.</p>
<h2 id="block-aggregator-by-ebay">block-aggregator by eBay</h2>
<p>Block Aggregator is a data loader that subscribes to Kafka topics, aggregates the Kafka messages into blocks that follow the Clickhouse’s table schemas, and then inserts the blocks into ClickHouse. Block Aggregator provides exactly-once delivery guarantee to load data from Kafka to ClickHouse. Block Aggregator utilizes Kafka’s metadata to keep track of blocks that are intended to send to ClickHouse, and later uses this metadata information to deterministically re-produce ClickHouse blocks for re-tries in case of failures. The identical blocks are guaranteed to be deduplicated by ClickHouse.</p>
<p><a href="https://github.com/eBay/block-aggregator" target="_blank">eBay/block-aggregator</a></p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-7b4e8063954e9a7aaa7e048590c82f0d">8.4 - Kafka main parsing loop</h1>
    <div class="lead">Kafka main parsing loop</div>
	<p>One of the threads from scheduled_pool (pre 20.9) / <code>background_message_broker_schedule_pool</code> (after 20.9) do that in infinite loop:</p>
<ol>
<li>Batch poll (time limit: <code>kafka_poll_timeout_ms</code> 500ms, messages limit: <code>kafka_poll_max_batch_size</code> 65536)</li>
<li>Parse messages.</li>
<li>If we don&rsquo;t have enough data (rows limit: <code>kafka_max_block_size</code> 1048576) or time limit reached (<code>kafka_flush_interval_ms</code> 7500ms) - continue polling (goto p.1)</li>
<li>Write a collected block of data to MV</li>
<li>Do commit (commit after write = at-least-once).</li>
</ol>
<p>On any error, during that process, Kafka client is restarted (leading to rebalancing - leave the group and get back in few seconds).</p>
<p><img src="/assets/128942286.png" alt="Kafka batching"></p>
<h2 id="important-settings">Important settings</h2>
<p>These usually should not be adjusted:</p>
<ul>
<li><code>kafka_poll_max_batch_size</code> = max_block_size (65536)</li>
<li><code>kafka_poll_timeout_ms</code> = stream_poll_timeout_ms (500ms)</li>
</ul>
<p>You may want to adjust those depending on your scenario:</p>
<ul>
<li><code>kafka_flush_interval_ms</code> = stream_poll_timeout_ms (7500ms)</li>
<li><code>kafka_max_block_size</code> = min_insert_block_size / kafka_num_consumers (for the single consumer: 1048576)</li>
</ul>
<h2 id="see-also">See also</h2>
<p><a href="https://github.com/ClickHouse/ClickHouse/pull/11388" target="_blank">https://github.com/ClickHouse/ClickHouse/pull/11388</a></p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-8de9ef71664f1495dde935e5d9c292a4">8.5 - Kafka parallel consuming</h1>
    <div class="lead">Kafka parallel consuming</div>
	<p>For very large topics when you need more parallelism (especially on the insert side) you may use several tables with the same pipeline (pre 20.9) or enable <code>kafka_thread_per_consumer</code> (after 20.9).</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ini" data-lang="ini"><span style="display:flex;"><span><span style="color:#c4a000">kafka_num_consumers</span> <span style="color:#ce5c00;font-weight:bold">=</span> <span style="color:#4e9a06">N,</span>
</span></span><span style="display:flex;"><span><span style="color:#c4a000">kafka_thread_per_consumer</span><span style="color:#ce5c00;font-weight:bold">=</span><span style="color:#4e9a06">1</span>
</span></span></code></pre></div><p>Notes:</p>
<ul>
<li>the inserts will happen in parallel (without that setting inserts happen linearly)</li>
<li>enough partitions are needed.</li>
</ul>
<p>Before increasing <code>kafka_num_consumers</code> with keeping <code>kafka_thread_per_consumer=0</code> may improve consumption &amp; parsing speed, but flushing &amp; committing still happens by a single thread there (so inserts are linear).</p>

</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-70048b9cd8c627a770ed4410dcd3a6d4">8.6 - Rewind / fast-forward / replay</h1>
    <div class="lead">Rewind / fast-forward / replay</div>
	<ul>
<li>Step 1: Detach Kafka tables in ClickHouse</li>
<li>Step 2: <code>kafka-consumer-groups.sh --bootstrap-server kafka:9092 --topic topic:0,1,2 --group id1 --reset-offsets --to-latest --execute</code>
<ul>
<li>More samples: <a href="https://gist.github.com/filimonov/1646259d18b911d7a1e8745d6411c0cc" target="_blank">https://gist.github.com/filimonov/1646259d18b911d7a1e8745d6411c0cc</a></li>
</ul>
</li>
<li>Step: Attach Kafka tables back</li>
</ul>
<p>See also these configuration settings:</p>
<pre tabindex="0"><code class="language-markup" data-lang="markup">&lt;kafka&gt;
  &lt;auto_offset_reset&gt;smallest&lt;/auto_offset_reset&gt;
&lt;/kafka&gt;
</code></pre>
</div>



    
	
  
    
    
	
    

<div class="td-content" style="page-break-before: always">
    
	<h1 id="pg-8441aefeee7f594b90b90afa09a25289">8.7 - SELECTs from engine=Kafka</h1>
    <div class="lead">SELECTs from engine=Kafka</div>
	<h2 id="question">Question</h2>
<p>What will happen, if we would run SELECT query from working Kafka table with MV attached? Would data showed in SELECT query appear later in MV destination table?</p>
<h2 id="answer">Answer</h2>
<ol>
<li>Most likely SELECT query would show nothing.</li>
<li>If you lucky enough and something would show up, those rows <strong>wouldn&rsquo;t appear</strong> in MV destination table.</li>
</ol>
<p>So it&rsquo;s not recommended to run SELECT queries on working Kafka tables.</p>
<p>In case of debug it&rsquo;s possible to use another Kafka table with different <code>consumer_group</code>, so it wouldn&rsquo;t affect your main pipeline.</p>

</div>



    
	
  

    
	
  



          </main>
        </div>
      </div>
      
<footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Twitter" aria-label="Twitter">
    <a class="text-white" target="_blank" rel="noopener noreferrer" href="https://twitter.com/AltinityDB">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="Youtube" aria-label="Youtube">
    <a class="text-white" target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/channel/UCE3Y2lDKl_ZfjaCrh62onYA">
      <i class="fab fa-youtube"></i>
    </a>
  </li>
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="LinkedIn" aria-label="LinkedIn">
    <a class="text-white" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/company/altinity/">
      <i class="fab fa-linkedin"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
        
        
        
<ul class="list-inline mb-0">
  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="GitHub" aria-label="GitHub">
    <a class="text-white" target="_blank" rel="noopener noreferrer" href="https://github.com/orgs/Altinity/">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
</ul>

        
        
      </div>
      <div class="col-12 col-sm-4 text-center py-2 order-sm-2">
        <small class="text-white">&copy; 2022  Altinity Inc. All Rights Reserved</small>
        <small class="ml-1"><a href="https://altinity.com/privacy-policy/" target="_blank">Privacy Policy</a></small>
	
		
	
      </div>
    </div>
  </div>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-101676615-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-101676615-2');
</script>
</footer>


    </div>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" integrity="sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF" crossorigin="anonymous"></script>






 













<script src="/js/main.min.7fa9e3e39f56ebd66798993ef3c080218d9696c971a28ef8872d750b7416a435.js" integrity="sha256-f6nj459W69ZnmJk&#43;88CAIY2Wlslxoo74hy11C3QWpDU=" crossorigin="anonymous"></script>



<script src='/js/prism.js'></script>



  </body>
</html>
