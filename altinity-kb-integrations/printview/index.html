<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical type=text/html href=http://kb.altinity.com/altinity-kb-integrations/><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=icon href=/favicons/favicon.ico><title>Integrations | Altinity® Knowledge Base for ClickHouse®</title>
<meta name=description content="Learn how you can integrate cloud services, BI tools, kafka, MySQL, Spark, MindsDB, and more with ClickHouse®
"><meta property="og:url" content="http://kb.altinity.com/altinity-kb-integrations/"><meta property="og:site_name" content="Altinity® Knowledge Base for ClickHouse®"><meta property="og:title" content="Integrations"><meta property="og:description" content="Learn how you can integrate cloud services, BI tools, kafka, MySQL, Spark, MindsDB, and more with ClickHouse®"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta itemprop=name content="Integrations"><meta itemprop=description content="Learn how you can integrate cloud services, BI tools, kafka, MySQL, Spark, MindsDB, and more with ClickHouse®"><meta itemprop=dateModified content="2024-07-30T22:09:50-04:00"><meta itemprop=keywords content="clickhouse integration,clickhouse bi,clickhouse kafka"><meta name=twitter:card content="summary"><meta name=twitter:title content="Integrations"><meta name=twitter:description content="Learn how you can integrate cloud services, BI tools, kafka, MySQL, Spark, MindsDB, and more with ClickHouse®"><link rel=preload href=/scss/main.min.10f29ebcf80a650ac763f904f53e25ddad49c874d72279a3e2123ef3e2c93426.css as=style><link href=/scss/main.min.10f29ebcf80a650ac763f904f53e25ddad49c874d72279a3e2123ef3e2c93426.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script><link rel=stylesheet href=/css/prism.css><meta name=keywords content="clickhouse integration,clickhouse bi,clickhouse kafka"><script type=text/javascript id=hs-script-loader async defer src=//js.hs-scripts.com/4536206.js></script><script type=text/javascript>(function(e,t,n,s,o,i,a){e[n]=e[n]||function(){(e[n].q=e[n].q||[]).push(arguments)},i=t.createElement(s),i.async=1,i.src="https://www.clarity.ms/tag/"+o,a=t.getElementsByTagName(s)[0],a.parentNode.insertBefore(i,a)})(window,document,"clarity","script","v7y63vmran")</script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand-xl navbar-dark"><a class=navbar-brand href=https://altinity.com target=_blank><span class=navbar-logo><img src=/images/general/altinity-logo_horizontal_blue_white.svg width=154 alt=Altinity.com></span>
</a><button class="navbar-toggler ml-auto" type=button data-bs-toggle=collapse data-bs-target=#mobile_navbar aria-controls=mobile_navbar aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="td-navbar-nav-scroll w-100 d-none d-xl-block" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item dropdown position-static"><a class="nav-link dropdown-toggle" href=# id=productsDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Products</a><ul class="dropdown-menu list-unstyled w-100 mega-menu" aria-labelledby=navbarDropdown><li><div class=grid-row style="grid-template-columns:35% 35% 30%"><div><h5 style=margin-bottom:15px>PRODUCTS</h5><div><div class=sub-section-header>Altinity.Cloud</div><div class=sub_links style="display:grid;grid-template-columns:50% 50%;margin-bottom:15px"><div><a href=https://altinity.com/managed-clickhouse/ id=nav_products_cloud class=med-link>Managed cloud</a><div class=desc>Deploy on Altinity’s cloud</div></div><div><a href=https://altinity.com/managed-clickhouse/bring-your-own-cloud/ id=nav_products_byoc class=med-link>Bring your own cloud</a><div class=desc>Any region, any environment</div></div></div><div class=sub_links style="display:grid;grid-template-columns:50% 50%;margin-bottom:20px"><div><a href=https://altinity.com/altinity-cloud-vs-clickhouse-cloud-faq id=nav_products_comparison><i class="fas fa-table text-primary"></i> Vendor comparison </a></div><div><a href=https://altinity.com/clickhouse-pricing/ id=nav_products_pricing><i class="fas fa-dollar-sign text-primary"></i> Pricing </a></div></div></div><div><div class=sub-section-header>Support for ClickHouse<sup>®</sup></div><a href=https://altinity.com/clickhouse-support/ id=nav_products_support class=med-link style=margin-bottom:10px>24/7 Support</a><br><a href=https://altinity.com/poc-evaluation-support/ id=nav_products_poc_evaluative_support class=med-link style=margin-bottom:10px>POC and Evaluative Support</a><br><a href=https://altinity.com/clickhouse-training/ id=nav_products_training class=med-link style=margin-bottom:10px>Training for ClickHouse<sup>®</sup></a><br></div></div><div style="border-left:1px solid rgba(255,255,255,.3);padding-left:30px"><h5 style=margin-bottom:15px>OPEN SOURCE SOFTWARE</h5><div style="margin-left:-10px;padding:5px 5px 5px 10px;margin-bottom:5px;background:rgba(24,157,208,.5);border-radius:8px"><a href=https://altinity.com/project-antalya-real-time-data-lakes/ id=nav_products_antalya_builds>NEW Project Antalya Builds </a><br><div class=desc style=margin-bottom:0>Scale ClickHouse queries infinitely with 10X cheaper data lakes</div></div><a href=https://altinity.com/altinity-stable/ id=nav_products_stable_builds>Altinity Stable Builds for ClickHouse<sup>®</sup> </a><br><div class=desc style=margin-bottom:15px>LTS-certified binaries with 3 years’ support</div><a href=https://altinity.com/kubernetes-operator/ id=nav_products_kubernetes>Altinity Kubernetes Operator for ClickHouse<sup>®</sup> </a><br><div class=desc style=margin-bottom:15px>Manage ClickHouse clusters on Kubernetes effortlessly</div><a href=https://altinity.com/altinity-backup-for-clickhouse/ id=nav_products_backup>Altinity Backup for ClickHouse<sup>®</sup> </a><br><div class=desc style=margin-bottom:15px>Simple backup and restore tool for ClickHouse</div><a href=https://altinity.com/ecosystem/>See more > </a></div><div style="border-left:1px solid rgba(255,255,255,.3);padding-left:30px"><h5 style=margin-bottom:15px>CLICKHOUSE<sup>®</sup> SOLUTIONS</h5><a href=https://altinity.com/observability-and-logging/ id=nav_observability>Observability & Logging </a><br><div class=desc style=margin-bottom:15px>Manage high-volume observability data efficiently</div><a href=https://altinity.com/security-information-and-event-management/ id=nav_siem>Security Information and Event Management (SIEM) </a><br><div class=desc style=margin-bottom:15px>Efficiently process and analyze high-volume security events</div><a href=https://altinity.com/trading-systems/ id=nav_trading_systems>Trading Analytics </a><br><div class=desc style=margin-bottom:15px>Make faster market decisions</div></div></div><div class=grid-row style="grid-template-columns:33% 60%;border-top:1px solid rgba(255,255,255,.3)"><div><a href=https://altinity.com/customer-stories/ id=nav_products_customer_stories>Customer stories </a><br><div class=desc>See why our customers love us</div></div><div><a href=https://altinity.com/plans-and-features-clickhouse/ id=nav_products_plans_features>Altinity Plans and Features </a><br><div class=desc>Managed service or support? Compare plans and features</div></div></div></li></ul></li><li class="nav-item dropdown position-static"><a class="nav-link dropdown-toggle" href=# id=resourceDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Resources</a><ul class="dropdown-menu list-unstyled w-100 mega-menu" aria-labelledby=navbarDropdown><li><div class=grid-row><div><p class=col-header>Developer Center</p><div><a href=https://docs.altinity.com/ target=_blank id=nav_resources_docs>Documentation </a><div class=desc>Product guides and tutorials</div><br></div><div><a href=https://kb.altinity.com/ target=_blank id=nav_resources_knowledgebase>Knowledge Base </a><div class=desc>Answers to common questions and issues</div><br></div><div><a href="https://altinity.com/blog/?cat=webinarspage" target=_blank id=nav_resources_webinars>Past Webinars </a><div class=desc>Watch anytime, on demand.</div><br></div><div><a href=https://altinity.com/developer-resources/ id=nav_resources_dev_resources>More Technical Content </a><div class=desc>How-to guides and videos</div><br></div></div><div><p class=col-header>Learning</p><div><a href=https://altinity.com/clickhouse-database/ id=nav_resources_what_is_ch>What is ClickHouse? </a><div class=desc>New to ClickHouse? Start here</div><br></div><div><a href=https://altinity.com/kubernetes-operator/ id=nav_resources_k8s_operator>Kubernetes Operator </a><div class=desc>Learn how it works and who uses it</div><br></div><div><a href=https://altinity.com/unevenly-distributed/ id=nav_unevenlydistributed>Unevenly Distributed </a><div class=desc>A Thought Leadership Series on Real-Time Data Lakes</div><br></div><div><a href=https://altinity.com/altinity-stable/ id=nav_resources_stable>Altinity Stable Builds </a><div class=desc>Learn why you should be using them in your prod environments</div><br></div></div><div><p class=col-header>Community</p><div><a href=https://altinity.com/ecosystem/ id=nav_resources_open_source>Open Source at Altinity </a><div class=desc>Explore our open source projects and contributions</div><br></div><div><a href=https://altinity.com/events/ id=nav_resources_events>Events </a><div class=desc>Upcoming conferences, events, and webinars</div><br></div><div><a href=https://altinity.com/slack/ target=_blank id=nav_resources_slack>Slack Community </a><div class=desc>Get help for any ClickHouse issue from experts</div><br></div><div><a href=https://altinity.com/office-hours-for-clickhouse/ id=nav_resources_office_hours>Monthly Office Hours </a><div class=desc>Meet our engineers live and ask your questions</div><br></div></div></div></li></ul></li><li class=nav-item><a class=nav-link href=https://altinity.com/blog target=_blank>Blog</a></li><li class="nav-item dropdown position-static"><a class="nav-link dropdown-toggle" href=# id=companyDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Company</a><ul class="dropdown-menu list-unstyled w-100 mega-menu" aria-labelledby=navbarDropdown><li><div class=grid-row><div><div><a href=https://altinity.com/about-us/ id=nav_company_about>About the company  </a></div><div><a href=https://altinity.com/about-us/#leadership id=nav_company_leadership>Leadership </a></div></div><div><div><a href=https://altinity.com/about-us/press-releases/ id=nav_company_press>Press Releases </a></div><div><a href=https://altinity.com/partners/ id=nav_company_partners>Partners </a></div></div><div><div><a href=https://altinity.com/customer-stories/ id=nav_company_customer_stories>Customer Stories </a></div><div><a href=https://altinity.com/careers/ id=nav_company_careers>Careers </a></div></div><div class=mega-bg-blue><div><h5>Get in touch with ClickHouse experts.</h5><a href=https://altinity.com/contact class="btn btn-primary button">Contact Us </a></div></div></div></li></ul></li><li class=nav-item><a class=nav-link href=https://altinity.com/contact target=_blank>Contact</a></li><li class="header-social-wrap ml-md-auto"><a class=navbar-button href=https://altinity.com/free-clickhouse-consultation/ target=_blank>Tech Support</a>
<a class=navbar-button href=https://acm.altinity.cloud/signup target=_blank style=margin-right:15px>ClickHouse® in Cloud</a>
<a href=https://www.youtube.com/@Altinity aria-label=Slack target=_blank rel="noopener noreferrer" class="social-button header-social-item"><span class=social-icon-custom-svg style=max-width:34px><svg fill="currentcolor" xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 28 28"><title>YouTube</title><path d="M11.109 17.625l7.562-3.906-7.562-3.953v7.859zM14 4.156c5.891.0 9.797.281 9.797.281.547.063 1.75.063 2.812 1.188.0.0.859.844 1.109 2.781.297 2.266.281 4.531.281 4.531v2.125s.016 2.266-.281 4.531c-.25 1.922-1.109 2.781-1.109 2.781-1.062 1.109-2.266 1.109-2.812 1.172.0.0-3.906.297-9.797.297v0c-7.281-.063-9.516-.281-9.516-.281-.625-.109-2.031-.078-3.094-1.188.0.0-.859-.859-1.109-2.781-.297-2.266-.281-4.531-.281-4.531v-2.125s-.016-2.266.281-4.531C.531 6.469 1.39 5.625 1.39 5.625 2.452 4.5 3.656 4.5 4.202 4.437c0 0 3.906-.281 9.797-.281v0z"/></svg>
</span></a><a href=https://altinity.com/slack/ aria-label=Slack target=_blank rel="noopener noreferrer" class="social-button header-social-item"><span class=social-icon-custom-svg style=max-width:34px><svg viewBox="0 0 36 36" height="24" width="24" xmlns="http://www.w3.org/2000/svg"><path fill="currentcolor" d="M7.563 22.747a3.782 3.782.0 11-3.78-3.78h3.78v3.78zm1.906.0a3.782 3.782.0 017.563.0v9.469a3.782 3.782.0 11-7.563.0V22.747zM13.251 7.563a3.782 3.782.0 113.782-3.78v3.78H13.251zm0 1.906a3.781 3.781.0 110 7.563H3.783a3.782 3.782.0 110-7.563h9.468zm15.183 3.782a3.783 3.783.0 113.783 3.782H28.434V13.251zm-1.9.0a3.782 3.782.0 01-7.565.0V3.783a3.782 3.782.0 117.564.0zM22.747 28.434a3.783 3.783.0 11-3.78 3.783V28.434h3.78zm0-1.9a3.782 3.782.0 010-7.565h9.469a3.782 3.782.0 110 7.564z" data-name="Icon simple-slack" id="Icon_simple-slack"/></svg>
</span></a><a href=https://github.com/altinity/ aria-label=GitHub target=_blank rel="noopener noreferrer" class="social-button header-social-item"><svg fill="currentcolor" xmlns="http://www.w3.org/2000/svg" width="24" height="28" viewBox="0 0 24 28"><title>Github</title><path d="M12 2c6.625.0 12 5.375 12 12 0 5.297-3.437 9.797-8.203 11.391-.609.109-.828-.266-.828-.578.0-.391.016-1.687.016-3.297.0-1.125-.375-1.844-.812-2.219 2.672-.297 5.484-1.313 5.484-5.922.0-1.313-.469-2.375-1.234-3.219.125-.313.531-1.531-.125-3.187-1-.313-3.297 1.234-3.297 1.234-.953-.266-1.984-.406-3-.406s-2.047.141-3 .406c0 0-2.297-1.547-3.297-1.234-.656 1.656-.25 2.875-.125 3.187-.766.844-1.234 1.906-1.234 3.219.0 4.594 2.797 5.625 5.469 5.922-.344.313-.656.844-.766 1.609-.688.313-2.438.844-3.484-1-.656-1.141-1.844-1.234-1.844-1.234-1.172-.016-.078.734-.078.734.781.359 1.328 1.75 1.328 1.75.703 2.141 4.047 1.422 4.047 1.422.0 1 .016 1.937.016 2.234.0.313-.219.688-.828.578-4.766-1.594-8.203-6.094-8.203-11.391.0-6.625 5.375-12 12-12zM4.547 19.234c.031-.063-.016-.141-.109-.187-.094-.031-.172-.016-.203.031-.031.063.016.141.109.187.078.047.172.031.203-.031zM5.031 19.766c.063-.047.047-.156-.031-.25-.078-.078-.187-.109-.25-.047-.063.047-.047.156.031.25.078.078.187.109.25.047zM5.5 20.469c.078-.063.078-.187.0-.297-.063-.109-.187-.156-.266-.094-.078.047-.078.172.0.281s.203.156.266.109zM6.156 21.125c.063-.063.031-.203-.063-.297-.109-.109-.25-.125-.313-.047-.078.063-.047.203.063.297.109.109.25.125.313.047zM7.047 21.516c.031-.094-.063-.203-.203-.25-.125-.031-.266.016-.297.109s.063.203.203.234c.125.047.266.0.297-.094zM8.031 21.594c0-.109-.125-.187-.266-.172-.141.0-.25.078-.25.172.0.109.109.187.266.172.141.0.25-.078.25-.172zM8.937 21.438c-.016-.094-.141-.156-.281-.141-.141.031-.234.125-.219.234.016.094.141.156.281.125s.234-.125.219-.219z"/></svg></a></li></ul></div></nav><div id=mobile_navbar class="collapse js-navbar-scroll navbar-collapse d-xl-none"><ul class="menu has-collapse-sub-nav"><li class="nav-item nav-item-has-children active"><div class=drawer-nav-drop-wrap><a>Products</a><span class=mobile-drop-toggle></span></div><ul class=sub-menu><li class="nav-item nav-item-has-children"><div class=drawer-nav-drop-wrap><a href=https://altinity.com/managed-clickhouse/>Altinity.Cloud</a><span class=mobile-drop-toggle></span></div><ul class=sub-menu><li class=nav-item><a href=https://altinity.com/clickhouse-pricing/>Pricing for ClickHouse</a></li><li class=nav-item><a href=https://altinity.com/altinity-cloud-vs-clickhouse-cloud-faq/>Altinity.Cloud vs ClickHouse Cloud FAQ</a></li><li class=nav-item><a href=https://altinity.com/clickhouse-support/>Support for ClickHouse</a></li><li class=nav-item><a href=https://altinity.com/clickhouse-training/>Training for ClickHouse</a></li></ul></li><li class="nav-item nav-item-has-children"><div class=drawer-nav-drop-wrap><a href=https://altinity.com/ecosystem/>Open Source Software</a></div><ul class=sub-menu><li class=nav-item><a href=https://altinity.com/project-antalya-real-time-data-lakes/>Project Antalya</a></li><li class=nav-item><a href=https://altinity.com/altinity-stable/>Altinity Stable Builds</a></li><li class=nav-item><a href=https://altinity.com/kubernetes-operator/>Kubernetes Operator</a></li><li class=nav-item><a href=https://altinity.com/altinity-backup-for-clickhouse/>Altinity Backup for ClickHouse</a></li></ul></li><li class="nav-item nav-item-has-children"><div class=drawer-nav-drop-wrap><a>ClickHouse™ Solutions</a><span class=mobile-drop-toggle></span></div><ul class=sub-menu><li class=nav-item><a href=https://altinity.com/observability-and-logging/>Observability & Logging with ClickHouse®</a></li><li class=nav-item><a href=https://altinity.com/security-information-and-event-management/>Security Information and Event Management (SIEM) with ClickHouse®</a></li><li class=nav-item><a href=https://altinity.com/trading-systems/>Trading analytics with ClickHouse®</a></li></ul></li></ul></li><li class="nav-item nav-item-has-children"><div class=drawer-nav-drop-wrap><a>Resources</a></div><ul class=sub-menu><li class="nav-item nav-item-has-children"><div class=drawer-nav-drop-wrap><a href=#>Developer Center</a><span class=mobile-drop-toggle></span></div><ul class=sub-menu><li class=nav-item><a target=_blank href=https://docs.altinity.com/>Documentation</a></li><li class=nav-item><a target=_blank href=https://kb.altinity.com/>Knowledge Base</a></li><li class=nav-item><a href="https://altinity.com/blog/?cat=webinarspage">Past Webinars</a></li><li class=nav-item><a href=https://altinity.com/developer-resources/>Guides and eBooks</a></li></ul></li><li class="nav-item nav-item-has-children"><div class=drawer-nav-drop-wrap><a href=#>Learning</a><span class=mobile-drop-toggle></span></div><ul class=sub-menu><li class=nav-item><a href=https://altinity.com/clickhouse-database/>What is ClickHouse?</a></li><li class=nav-item><a href=https://altinity.com/what-is-kubernetes/>What is Kubernetes?</a></li><li class=nav-item><a href=https://altinity.com/unevenly-distributed/>Unevenly Distributed</a></li><li class=nav-item><a href=https://altinity.com/altinity-stable/>Altinity Stable Builds</a></li></ul></li><li class="nav-item nav-item-has-children"><div class=drawer-nav-drop-wrap><a href=#>Community</a><span class=mobile-drop-toggle></span></div><ul class=sub-menu><li class=nav-item><a href=https://altinity.com/events>Events</a></li><li class="nav-slack nav-item"><a target=_blank href=http://www.localhost:10008/slack>Slack Community</a></li><li class=nav-item><a href=https://altinity.com/office-hours-for-clickhouse/>Office Hours for ClickHouse®</a></li></ul></li></ul></li><li class=nav-item><a href=https://altinity.com/blog>Blog</a></li><li class="nav-item nav-item-has-children"><div class=drawer-nav-drop-wrap><a>Company</a><span class=mobile-drop-toggle></span></div><ul class=sub-menu><li class=nav-item><a href=https://altinity.com/about-us/>About Altinity</a></li><li class=nav-item><a href=https://altinity.com/about-us/#leadership>Leadership</a></li><li class=nav-item><a href=https://altinity.com/about-us/press-releases/>Press Releases</a></li><li class=nav-item><a href=https://altinity.com/partners/>Partners</a></li><li class=nav-item><a href=https://altinity.com/customer-stories/>Customer Stories</a></li><li class=nav-item><a href=https://altinity.com/careers/>Careers</a></li></ul></li><li class=nav-item><a href=https://altinity.com/contact>Contact</a></li><li class="header-nav-button nav-item"><a href=https://altinity.com/free-clickhouse-consultation>Tech Support</a></li><li class="header-nav-button nav-item"><a href="https://acm.altinity.cloud/signup?__hstc=173202428.421802398cbec3b5d6457748d00d825f.1702395478849.1769622795179.1769630357065.395&__hssc=173202428.9.1769630357065&__hsfp=e5063c5ad56e06035f046e27f2ea897a">ClickHouse® in Cloud</a></li></ul></div></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/altinity-kb-integrations/>Return to the regular view of this page</a>.</p></div><h1 class=title>Integrations</h1><div class=lead>Learn how you can integrate cloud services, BI tools, kafka, MySQL, Spark, MindsDB, and more with ClickHouse®</div><ul><li>1: <a href=#pg-1df7bcbc597684541fc9783932543752>Altinity Cloud Access Management</a></li><ul></ul><li>2: <a href=#pg-2aaddc1e239f9e7d2ccf12529e8f816f>ClickHouse® python drivers</a></li><li>3: <a href=#pg-0f98d3cb672b7952fbdcbdf0b4f456a8>MySQL</a></li><li>4: <a href=#pg-eb3d7cbed2a5c568b2bb9a98bbc492ee>ODBC Driver for ClickHouse®</a></li><li>5: <a href=#pg-d2afec8f52450d3642df08e91fab21b4>ClickHouse® + Spark</a></li><li>6: <a href=#pg-490f1eab7bb37421ddd14a8d6c58e9ab>BI Tools</a></li><li>7: <a href=#pg-7a1dc52ba21a64be26ec5780459eb575>CatBoost / MindsDB / Fast.ai</a></li><li>8: <a href=#pg-902c0f257a8ddd6f658f1246ef020032>Google S3 (GCS)</a></li><li>9: <a href=#pg-baebc0ff2257ac7906ebf1b6671d8990>Kafka</a></li><ul><li>9.1: <a href=#pg-899d8da901ecc94da3c79954ddb7871b>Kafka engine Virtual columns</a></li><li>9.2: <a href=#pg-46af47e683866727c612b8efc5556565>Inferring Schema from AvroConfluent Messages in Kafka for ClickHouse®</a></li><li>9.3: <a href=#pg-b782f7dceeb8f45296efecc0559e5d5a>Setting the background message broker schedule pool size</a></li><li>9.4: <a href=#pg-b11bb1875d00a2b0ff0e60950c5360ed>Adjusting librdkafka settings</a></li><li>9.5: <a href=#pg-d58f1474300f709dea11df04812ed578>Error handling</a></li><li>9.6: <a href=#pg-d8f2388a49c064f3f21643937cbfcedc>Exactly once semantics</a></li><li>9.7: <a href=#pg-7b4e8063954e9a7aaa7e048590c82f0d>Kafka main parsing loop</a></li><li>9.8: <a href=#pg-8de9ef71664f1495dde935e5d9c292a4>Kafka parallel consuming</a></li><li>9.9: <a href=#pg-73c78c87d15e6e8b2e49b347c708ad83>Multiple MVs attached to Kafka table</a></li><li>9.10: <a href=#pg-70048b9cd8c627a770ed4410dcd3a6d4>Rewind / fast-forward / replay</a></li><li>9.11: <a href=#pg-8441aefeee7f594b90b90afa09a25289>SELECTs from engine=Kafka</a></li></ul><li>10: <a href=#pg-633ba7dbb22cf28081101da0fcc2c511>RabbitMQ</a></li><ul><li>10.1: <a href=#pg-98ba8cfef289db7021da328f13e65d9e>RabbitMQ Error handling</a></li></ul></ul><div class=content></div></div><div class=td-content><h1 id=pg-1df7bcbc597684541fc9783932543752>1 - Altinity Cloud Access Management</h1><div class=lead>Enabling access_management for Altinity.Cloud databases.</div><p>Organizations that want to enable administrative users in their Altinity.Cloud ClickHouse® servers can do so by enabling <code>access_management</code> manually. This allows for administrative users to be created on the specific ClickHouse Cluster.</p><div class="alert alert-warning" role=alert><h4 class=alert-heading>WARNING</h4>Modifying the ClickHouse cluster settings manually can lead to the cluster not loading or other issues. Change settings only with full consultation with an Altinity.Cloud support team member, and be ready to remove settings if they cause any disruption of service.</div><p>To add the <code>access_management</code> setting to an Altinity.Cloud ClickHouse Cluster:</p><ol><li><p>Log into your Altinity.Cloud account.</p></li><li><p>For the cluster to modify, select <strong>Configure -> Settings</strong>.</p><figure><img src=/assets/altinity-cloud-cluster-settings-configure.png width=400><figcaption><h4>Cluster setting configure</h4></figcaption></figure></li><li><p>From the Settings page, select <strong>+ADD SETTING</strong>.</p><figure><img src=/assets/altinity-cloud-cluster-add-setting.png><figcaption><h4>Add cluster setting</h4></figcaption></figure></li><li><p>Set the following options:</p></li><li><p><strong>Setting Type</strong>: Select <strong>users.d file</strong>.</p></li><li><p><strong>Filename</strong>: <code>access_management.xml</code></p></li><li><p><strong>Contents</strong>: Enter the following to allow the <code>clickhouse_operator</code> that controls the cluster through the <code>clickhouse-operator</code> the ability to set administrative options:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;clickhouse&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;users&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;admin&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#204a87;font-weight:700>&lt;access_management&gt;</span>1<span style=color:#204a87;font-weight:700>&lt;/access_management&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;/admin&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;clickhouse_operator&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#204a87;font-weight:700>&lt;access_management&gt;</span>1<span style=color:#204a87;font-weight:700>&lt;/access_management&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;/clickhouse_operator&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;/users&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/clickhouse&gt;</span>
</span></span></code></pre></div></li></ol><p>access_management=1 means that users <code>admin</code>, <code>clickhouse_operator</code> are able to create users and grant them privileges using SQL.</p><ol><li><p>Select <strong>OK</strong>. The cluster will restart, and users can now be created in the cluster that can be granted administrative access.</p></li><li><p>If you are running ClickHouse 21.9 and above you can enable storing access management in ZooKeeper. in this case it will be automatically propagated to the cluster. This requires yet another configuration file:</p></li><li><p><strong>Setting Type</strong>: Select <strong>config.d file</strong></p></li><li><p><strong>Filename</strong>: <code>user_directories.xml</code></p></li><li><p><strong>Contents</strong>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;clickhouse&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;user_directories</span> <span style=color:#c4a000>replace=</span><span style=color:#4e9a06>&#34;replace&#34;</span><span style=color:#204a87;font-weight:700>&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;users_xml&gt;</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&lt;path&gt;</span>/etc/clickhouse-server/users.xml<span style=color:#204a87;font-weight:700>&lt;/path&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;/users_xml&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;replicated&gt;</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>&lt;zookeeper_path&gt;</span>/clickhouse/access/<span style=color:#204a87;font-weight:700>&lt;/zookeeper_path&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;/replicated&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;local_directory&gt;</span>
</span></span><span style=display:flex><span>       <span style=color:#204a87;font-weight:700>&lt;path&gt;</span>/var/lib/clickhouse/access/<span style=color:#204a87;font-weight:700>&lt;/path&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;/local_directory&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;/user_directories&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/clickhouse&gt;</span>
</span></span></code></pre></div></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-2aaddc1e239f9e7d2ccf12529e8f816f>2 - ClickHouse® python drivers</h1><div class=lead>Python main drivers/clients for ClickHouse®</div><p>There are two main python drivers that can be used with ClickHouse. They all have their different set of features and use cases:</p><h3 id=clickhouse-driver-aka-clickhouse-driverhttpsclickhouse-driverreadthedocsioenlatest>ClickHouse driver AKA <a href=https://clickhouse-driver.readthedocs.io/en/latest/ target=_blank>clickhouse-driver</a></h3><p>The <strong><code>clickhouse-driver</code></strong> is a Python library used for interacting with ClickHouse. Here&rsquo;s a summary of its features:</p><ol><li><strong>Connectivity</strong>: <strong><code>clickhouse-driver</code></strong> allows Python applications to connect to ClickHouse servers over TCP/IP Native Interface (9000/9440 ports) and also HTTP interface but it is experimental.</li><li><strong>SQL Queries</strong>: It enables executing SQL queries against ClickHouse databases from Python scripts, including data manipulation (insertion, deletion, updating) and data retrieval (select queries).</li><li><strong>Query Parameters</strong>: Supports parameterized queries, which helps in preventing SQL injection attacks and allows for more efficient execution of repeated queries with different parameter values.</li><li><strong>Connection Pooling</strong>: Provides support for connection pooling, which helps manage connections efficiently, especially in high-concurrency applications, by reusing existing connections instead of creating new ones for each query.</li><li><strong>Data Types</strong>: Handles conversion between Python data types and ClickHouse data types, ensuring compatibility and consistency when passing data between Python and ClickHouse.</li><li><strong>Error Handling</strong>: Offers comprehensive error handling mechanisms, including exceptions and error codes, to facilitate graceful error recovery and handling in Python applications.</li><li><strong>Asynchronous Support</strong>: Supports asynchronous execution of queries using <code>asyncio</code>, allowing for non-blocking query execution in asynchronous Python applications.</li><li><strong>Customization</strong>: Provides options for customizing connection settings, query execution behavior, and other parameters to suit specific application requirements and performance considerations.</li><li><strong>Compatibility</strong>: Works with various versions of ClickHouse, ensuring compatibility and support for different ClickHouse features and functionalities.</li><li><strong>Documentation and Community</strong>: Offers comprehensive documentation and active community support, including examples, tutorials, and forums, to assist developers in effectively using the library and addressing any issues or questions they may have.</li><li><strong>Supports multiple host</strong> <strong>on connection string</strong> <a href=https://clickhouse-driver.readthedocs.io/en/latest/features.html#multiple-hosts target=_blank>https://clickhouse-driver.readthedocs.io/en/latest/features.html#multiple-hosts</a></li><li><strong>Connection pooling</strong> (aiohttp)</li></ol><p><strong>Python ecosystem libs/modules:</strong></p><ul><li>Good Pandas/Numpy support: <a href=https://clickhouse-driver.readthedocs.io/en/latest/features.html#numpy-pandas-support target=_blank>https://clickhouse-driver.readthedocs.io/en/latest/features.html#numpy-pandas-support</a></li><li>Good SQLALchemy support: <a href=https://pypi.org/project/clickhouse-sqlalchemy/ target=_blank>https://pypi.org/project/clickhouse-sqlalchemy/</a></li></ul><p>This was the first python driver for ClickHouse. It has a mature codebase. By default ClickHouse drivers uses <a href=https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#async-and-multithreading target=_blank>synchronous code</a>
. There is a wrapper to convert code to asynchronous, <a href=https://github.com/long2ice/asynch target=_blank>https://github.com/long2ice/asynch</a></p><p>Here you can get a basic working example from Altinity repo for ingestion/selection using clickhouse-driver:</p><p><a href=https://github.com/lesandie/clickhouse-tests/blob/main/scripts/test_ch_driver.py target=_blank>https://github.com/lesandie/clickhouse-tests/blob/main/scripts/test_ch_driver.py</a></p><h3 id=clickhouse-connect-aka-clickhouse-connecthttpsclickhousecomdocsenintegrationspython>ClickHouse-connect AKA <a href=https://clickhouse.com/docs/en/integrations/python target=_blank rel=nofollow>clickhouse-connect</a></h3><p>The ClickHouse Connect Python driver is the ClickHouse, Inc supported-official Python library. Here&rsquo;s a summary of its key features:</p><ol><li><strong>Connectivity</strong>: allows Python applications to connect to ClickHouse servers over HTTP Interface (8123/8443 ports).</li><li><strong>Compatibility</strong>: The driver is compatible with Python 3.x versions, ensuring that it can be used with modern Python applications without compatibility issues.</li><li><strong>Performance</strong>: The driver is optimized for performance, allowing for efficient communication with ClickHouse databases to execute queries and retrieve results quickly, which is crucial for applications requiring low latency and high throughput.</li><li><strong>Query Execution</strong>: Developers can use the driver to execute SQL queries against ClickHouse databases, including SELECT, INSERT, UPDATE, DELETE, and other SQL operations, enabling them to perform various data manipulation tasks from Python applications.</li><li><strong>Parameterized Queries</strong>: The driver supports parameterized queries, allowing developers to safely pass parameters to SQL queries to prevent SQL injection attacks and improve query performance by reusing query execution plans.</li><li><strong>Data Type Conversion</strong>: The driver automatically handles data type conversion between Python data types and ClickHouse data types, ensuring seamless integration between Python applications and ClickHouse databases without manual data type conversion.</li><li><strong>Error Handling</strong>: The driver provides robust error handling mechanisms, including exceptions and error codes, to help developers handle errors gracefully and take appropriate actions based on the type of error encountered during query execution.</li><li><strong>Limited Asynchronous Support</strong>: Some implementations of the driver offer asynchronous support, allowing developers to execute queries asynchronously to improve concurrency and scalability in asynchronous Python applications using asynchronous I/O frameworks like <code>asyncio</code>.</li><li><strong>Configuration Options</strong>: The driver offers various configuration options, such as connection parameters, authentication methods, and connection pooling settings, allowing developers to customize the driver&rsquo;s behavior to suit their specific requirements and environment.</li><li><strong>Documentation and Community</strong>: Offers comprehensive documentation and active community support, including examples, tutorials, and forums, to assist developers in effectively using the library and addressing any issues or questions they may have. <a href=https://clickhouse.com/docs/en/integrations/language-clients/python/intro/ target=_blank rel=nofollow>https://clickhouse.com/docs/en/integrations/language-clients/python/intro/</a></li><li><strong>Multiple host on connection string not supported</strong> <a href=https://github.com/ClickHouse/clickhouse-connect/issues/74 target=_blank>https://github.com/ClickHouse/clickhouse-connect/issues/74</a></li><li><strong>Connection pooling</strong> (urllib3)</li></ol><p><strong>Python ecosystem libs/modules:</strong></p><ul><li>Good Pandas/Numpy support: <a href=https://clickhouse.com/docs/en/integrations/python#consuming-query-results-with-numpy-pandas-or-arrow target=_blank rel=nofollow>https://clickhouse.com/docs/en/integrations/python#consuming-query-results-with-numpy-pandas-or-arrow</a></li><li>Decent SQLAlchemy 1.3 and 1.4 support (limited feature set)</li></ul><p>It is the most recent driver with the latest feature set (query context and query streaming …. ), and in recent release <a href=https://github.com/ClickHouse/clickhouse-connect/releases/tag/v0.7.16 target=_blank>asyncio wrapper</a></p><p>You can check multiple official examples here:</p><p><a href=https://github.com/ClickHouse/clickhouse-connect/tree/457533df05fa685b2a1424359bea5654240ef971/examples target=_blank>https://github.com/ClickHouse/clickhouse-connect/tree/457533df05fa685b2a1424359bea5654240ef971/examples</a></p><p>Also some Altinity examples from repo:</p><p><a href=https://github.com/lesandie/clickhouse-tests/blob/main/scripts/test_ch_connect_asyncio_insert.py target=_blank>https://github.com/lesandie/clickhouse-tests/blob/main/scripts/test_ch_connect_asyncio_insert.py</a></p><p>You can clone the repo and use the helper files like <code>DDL.sql</code> to setup some tests.</p><h3 id=most-common-use-cases>Most common use cases:</h3><h4 id=connection-pooler>Connection pooler:</h4><ul><li>Clickhouse-connect can use a connection pooler (based on urllib3) <a href=https://clickhouse.com/docs/en/integrations/python#customizing-the-http-connection-pool target=_blank rel=nofollow>https://clickhouse.com/docs/en/integrations/python#customizing-the-http-connection-pool</a></li><li>Clickhouse-driver you can use <strong>aiohttp</strong> (<a href=https://docs.aiohttp.org/en/stable/client_advanced.html#limiting-connection-pool-size target=_blank>https://docs.aiohttp.org/en/stable/client_advanced.html#limiting-connection-pool-size</a>
)</li></ul><h4 id=managing-clickhouse-session_id>Managing ClickHouse <code>session_id</code>:</h4><ul><li><p>clickhouse-driver</p><ul><li>Because it is using the Native Interface <code>session_id</code> is managed internally by clickhouse, so it is very rare (unless using asyncio) to get:</li></ul><p><code>Code: 373. DB::Exception: Session is locked by a concurrent client. (SESSION_IS_LOCKED)</code> .</p></li><li><p>clickhouse-connect: How to use clickhouse-connect in a pythonic way and avoid getting <code>SESSION_IS_LOCKED</code> exceptions:</p><ul><li><a href=https://clickhouse.com/docs/en/integrations/python#managing-clickhouse-session-ids target=_blank rel=nofollow>https://clickhouse.com/docs/en/integrations/python#managing-clickhouse-session-ids</a></li><li>If you want to specify a session_id per query you should be able to use the setting dictionary to pass a <code>session_id</code> for each query (note that ClickHouse will automatically generate a <code>session_id</code> if none is provided).</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#000>SETTINGS</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000;font-weight:700>{</span><span style=color:#4e9a06>&#34;session_id&#34;</span><span style=color:#000;font-weight:700>:</span> <span style=color:#4e9a06>&#34;dagster-batch&#34;</span> <span style=color:#ce5c00;font-weight:700>+</span> <span style=color:#4e9a06>&#34;-&#34;</span> <span style=color:#ce5c00;font-weight:700>+</span> <span style=color:#4e9a06>f</span><span style=color:#4e9a06>&#34;</span><span style=color:#4e9a06>{</span><span style=color:#000>time</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>time</span><span style=color:#000;font-weight:700>()</span><span style=color:#4e9a06>}</span><span style=color:#4e9a06>&#34;</span><span style=color:#000;font-weight:700>}</span>
</span></span><span style=display:flex><span><span style=color:#000>client</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>query</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;INSERT INTO table ....&#34;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>settings</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>SETTINGS</span><span style=color:#000;font-weight:700>)</span>
</span></span></code></pre></div></li></ul><p>Also in clickhouse documentation some explanation how to set <code>session_id</code> with another approach: <a href=https://clickhouse.com/docs/en/integrations/python#managing-clickhouse-session-ids target=_blank rel=nofollow>https://clickhouse.com/docs/en/integrations/python#managing-clickhouse-session-ids</a></p><p><a href=https://clickhouse.com/docs/en/integrations/language-clients/python/driver-api#common-method-arguments target=_blank rel=nofollow>ClickHouse Connect Driver API | ClickHouse Docs</a></p><p><a href=https://github.com/ClickHouse/clickhouse-connect/issues/73#issuecomment-1325280242 target=_blank>Best practices with flask · Issue #73 · ClickHouse/clickhouse-connect</a></p><h4 id=asyncio-asynchronous-wrappers>Asyncio (asynchronous wrappers)</h4><h5 id=clickhouse-connect>clickhouse-connect</h5><p>New release with <a href=https://github.com/ClickHouse/clickhouse-connect/releases/tag/v0.7.16 target=_blank>asyncio wrapper for clickhouse-connect</a></p><p>How the wrapper works: <a href=https://clickhouse.com/docs/en/integrations/python#asyncclient-wrapper target=_blank rel=nofollow>https://clickhouse.com/docs/en/integrations/python#asyncclient-wrapper</a></p><p>Wrapper and connection pooler example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>clickhouse_connect</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>asyncio</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>clickhouse_connect.driver.httputil</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>get_pool_manager</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>async</span> <span style=color:#204a87;font-weight:700>def</span> <span style=color:#000>main</span><span style=color:#000;font-weight:700>():</span>
</span></span><span style=display:flex><span>    <span style=color:#000>client</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#204a87;font-weight:700>await</span> <span style=color:#000>clickhouse_connect</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>get_async_client</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>host</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;localhost&#39;</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>port</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>8123</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>pool_mgr</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>get_pool_manager</span><span style=color:#000;font-weight:700>())</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>for</span> <span style=color:#000>i</span> <span style=color:#204a87;font-weight:700>in</span> <span style=color:#204a87>range</span><span style=color:#000;font-weight:700>(</span><span style=color:#0000cf;font-weight:700>100</span><span style=color:#000;font-weight:700>):</span>
</span></span><span style=display:flex><span>        <span style=color:#000>result</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#204a87;font-weight:700>await</span> <span style=color:#000>client</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>query</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#34;SELECT name FROM system.databases&#34;</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87>print</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>result</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>result_rows</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#000>asyncio</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>run</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>main</span><span style=color:#000;font-weight:700>())</span>
</span></span></code></pre></div><p><code>clickhouse-connect</code> code is synchronous by default and running synchronous functions in an async application is a workaround and might not be as efficient as using a library/wrapper designed for asynchronous operations from the ground up.. So you can use the current wrapper or you can use another approach with <code>asyncio</code> and <code>concurrent.futures</code> and <code>ThreadpoolExecutor</code> or <code>ProcessPoolExecutor</code>. Python GIL has a mutex over Threads but not to Processes so if you need performance at the cost of using processes instead of threads (not much different for medium workloads) you can use <code>ProcesspoolExecutor</code> instead.</p><p>Some info about this from the tinybird guys <a href=https://www.tinybird.co/blog-posts/killing-the-processpoolexecutor target=_blank>https://www.tinybird.co/blog-posts/killing-the-processpoolexecutor</a></p><p>For clickhouse-connect :</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>asyncio</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>from</span> <span style=color:#000>concurrent.futures</span> <span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>ProcessPoolExecutor</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>import</span> <span style=color:#000>clickhouse_connect</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Function to execute a query using clickhouse-connect synchronously</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>def</span> <span style=color:#000>execute_query_sync</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>query</span><span style=color:#000;font-weight:700>):</span>
</span></span><span style=display:flex><span>    <span style=color:#000>client</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>clickhouse_connect</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>get_client</span><span style=color:#000;font-weight:700>()</span>  <span style=color:#8f5902;font-style:italic># Adjust connection params as needed</span>
</span></span><span style=display:flex><span>    <span style=color:#000>result</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>client</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>query</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>query</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>return</span> <span style=color:#000>result</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Asynchronous wrapper function to run the synchronous function in a process pool</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>async</span> <span style=color:#204a87;font-weight:700>def</span> <span style=color:#000>execute_query_async</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>query</span><span style=color:#000;font-weight:700>):</span>
</span></span><span style=display:flex><span>    <span style=color:#000>loop</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>asyncio</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>get_running_loop</span><span style=color:#000;font-weight:700>()</span>
</span></span><span style=display:flex><span>    <span style=color:#8f5902;font-style:italic># Use ProcessPoolExecutor to execute the synchronous function</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>with</span> <span style=color:#000>ProcessPoolExecutor</span><span style=color:#000;font-weight:700>()</span> <span style=color:#204a87;font-weight:700>as</span> <span style=color:#000>pool</span><span style=color:#000;font-weight:700>:</span>
</span></span><span style=display:flex><span>        <span style=color:#000>result</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#204a87;font-weight:700>await</span> <span style=color:#000>loop</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>run_in_executor</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>pool</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>execute_query_sync</span><span style=color:#000;font-weight:700>,</span> <span style=color:#000>query</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>return</span> <span style=color:#000>result</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>async</span> <span style=color:#204a87;font-weight:700>def</span> <span style=color:#000>main</span><span style=color:#000;font-weight:700>():</span>
</span></span><span style=display:flex><span>    <span style=color:#000>query</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>&#34;SELECT * FROM your_table LIMIT 10&#34;</span>  <span style=color:#8f5902;font-style:italic># Example query</span>
</span></span><span style=display:flex><span>    <span style=color:#000>result</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#204a87;font-weight:700>await</span> <span style=color:#000>execute_query_async</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>query</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87>print</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>result</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Run the async main function</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>if</span> <span style=color:#000>__name__</span> <span style=color:#ce5c00;font-weight:700>==</span> <span style=color:#4e9a06>&#39;__main__&#39;</span><span style=color:#000;font-weight:700>:</span>
</span></span><span style=display:flex><span>    <span style=color:#000>asyncio</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#000>run</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>main</span><span style=color:#000;font-weight:700>())</span>
</span></span></code></pre></div><h5 id=clickhouse-driver>Clickhouse-driver</h5><p><code>clickhouse-driver</code> code is also synchronous and suffers the same problem as <code>clickhouse-connect</code> <a href=https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#async-and-multithreading target=_blank>https://clickhouse-driver.readthedocs.io/en/latest/quickstart.html#async-and-multithreading</a></p><p>So to use asynchronous approach it is recommended to use a connection pool and some asyncio wrapper that can hide the complexity of using the <code>ThreadPoolExecutor/ProcessPoolExecutor</code></p><ul><li><p>To begin testing such environment <a href=https://docs.aiohttp.org/ target=_blank>aiohttp</a>
is a good approach. Here an example: <a href=https://github.com/lesandie/clickhouse-tests/blob/main/scripts/test_aiohttp_inserts.py target=_blank>https://github.com/lesandie/clickhouse-tests/blob/main/scripts/test_aiohttp_inserts.py</a>
This will use simply requests module and aiohttp (you can tune the connection pooler <a href=https://docs.aiohttp.org/en/stable/client_advanced.html#limiting-connection-pool-size target=_blank>https://docs.aiohttp.org/en/stable/client_advanced.html#limiting-connection-pool-size</a>
)</p></li><li><p>Also <code>aiochclient</code> is another good wrapper <a href=https://github.com/maximdanilchenko/aiochclient target=_blank>https://github.com/maximdanilchenko/aiochclient</a>
for the HTTP interface</p></li><li><p>For the native interface you can try <a href=https://github.com/long2ice/asynch target=_blank>https://github.com/long2ice/asynch</a>
, <code>asynch</code> is an asyncio ClickHouse Python Driver with native (TCP) interface support, which reuse most of <a href=https://github.com/mymarilyn/clickhouse-driver target=_blank>clickhouse-driver</a>
 and comply with <a href=https://www.python.org/dev/peps/pep-0249/ target=_blank>PEP249</a>
.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-0f98d3cb672b7952fbdcbdf0b4f456a8>3 - MySQL</h1><h3 id=replication-using-materializemysql>Replication using MaterializeMySQL.</h3><ul><li><a href=https://clickhouse.com/docs/en/engines/database-engines/materialized-mysql target=_blank rel=nofollow>https://clickhouse.com/docs/en/engines/database-engines/materialized-mysql</a></li><li><a href="https://translate.google.com/translate?sl=auto&amp;tl=en&amp;u=https://www.jianshu.com/p/d0d4306411b3" target=_blank>https://translate.google.com/translate?sl=auto&amp;tl=en&amp;u=https://www.jianshu.com/p/d0d4306411b3</a></li><li><a href=https://raw.githubusercontent.com/ClickHouse/clickhouse-presentations/master/meetup47/materialize_mysql.pdf target=_blank>https://raw.githubusercontent.com/ClickHouse/clickhouse-presentations/master/meetup47/materialize_mysql.pdf</a></li></ul><p>It reads mysql binlog directly and transform queries into something which ClickHouse® can support. Supports updates and deletes (under the hood implemented via something like ReplacingMergeTree with enforced FINAL and &lsquo;deleted&rsquo; flag). Status is &rsquo;experimental&rsquo;, there are quite a lot of known limitations and issues, but some people use it. The original author of that went to another project, and the main team don&rsquo;t have a lot of resource to improve that for now (more important thing in the backlog)</p><p>The replication happens on the mysql database level.</p><h3 id=replication-using-debezium--kafka--altinity-sink-connector-for-clickhouse>Replication using debezium + Kafka (+ Altinity Sink Connector for ClickHouse)</h3><p>Debezium can read the binlog and transform it to Kafka messages.</p><p>You can later capture the stream of message on ClickHouse side and process it as you like.
Please remember that currently Kafka engine supports only at-least-once delivery guarantees.
It&rsquo;s used by several companies, quite nice & flexible. But initial setup may require some efforts.</p><h4 id=altinity-sink-connector-for-clickhouse>Altinity Sink Connector for ClickHouse</h4><p>Can handle transformation of debezium messages (with support for DELETEs and UPDATEs) and exactly-once delivery for you.</p><p>Links:</p><ul><li><a href=https://altinity.com/blog/fast-mysql-to-clickhouse-replication-announcing-the-altinity-sink-connector-for-clickhouse target=_blank>https://altinity.com/blog/fast-mysql-to-clickhouse-replication-announcing-the-altinity-sink-connector-for-clickhouse</a></li><li><a href=https://altinity.com/mysql-to-clickhouse/ target=_blank>https://altinity.com/mysql-to-clickhouse/</a></li><li><a href=https://github.com/Altinity/clickhouse-sink-connector target=_blank>https://github.com/Altinity/clickhouse-sink-connector</a></li></ul><h4 id=same-as-above-but-using-httpsmaxwells-daemonio-instead-of-debezium>Same as above but using <a href=https://maxwells-daemon.io/ target=_blank>https://maxwells-daemon.io/</a>
instead of debezium.</h4><p>Have no experience / feedback there, but should be very similar to debezium.</p><h3 id=replication-using-clickhouse-mysql>Replication using clickhouse-mysql</h3><p>See <a href=https://altinity.com/blog/2018/6/30/realtime-mysql-clickhouse-replication-in-practice target=_blank>https://altinity.com/blog/2018/6/30/realtime-mysql-clickhouse-replication-in-practice</a></p><p>That was done long time ago in altinity for one use-case, and it seem like it was never used outside of that.
It&rsquo;s a python application with lot of switches which can copy a schema or read binlog from mysql and put it to ClickHouse.
Not supported currently. But it&rsquo;s just a python, so maybe can be adjusted to different needs.</p><h3 id=accessing-mysql-data-via-integration-engines-from-inside-clickhouse>Accessing MySQL data via integration engines from inside ClickHouse.</h3><p>MySQL <a href=https://clickhouse.com/docs/en/engines/table-engines/integrations/mysql/ target=_blank rel=nofollow>table engine</a>
/ <a href=https://clickhouse.com/docs/en/sql-reference/table-functions/mysql/ target=_blank rel=nofollow>table function</a>
, or <a href=https://clickhouse.com/docs/en/engines/database-engines/mysql/ target=_blank rel=nofollow>MySQL database engine</a>
- ClickHouse just connects to mysql server as a client, and can do normal selects.</p><p>We had webinar about that a year ago: <a href="https://www.youtube.com/watch?v=44kO3UzIDLI" target=_blank>https://www.youtube.com/watch?v=44kO3UzIDLI</a></p><p>Using that you can easily create some ETL script which will copy the data from mysql to ClickHouse regularly, i.e. something like</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>INSERT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>INTO</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>clickhouse_table</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>SELECT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>*</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>FROM</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>mysql_table</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>WHERE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>id</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>&gt;</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>...</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>Works great if you have append only table in MySQL.</p><p>In newer ClickHouse versions you can query this was also sharded / replicated MySQL cluster - see <a href=https://clickhouse.com/docs/en/engines/table-engines/integrations/ExternalDistributed/ target=_blank rel=nofollow>ExternalDistributed</a></p><h3 id=mysql-dictionaries>MySQL dictionaries</h3><p>There are also MySQL dictionaries, which can be very nice alternative for storing some dimensions information in star schema.</p><ul><li><a href=https://clickhouse.com/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts-dict-sources/#dicts-external_dicts_dict_sources-mysql target=_blank rel=nofollow>https://clickhouse.com/docs/en/sql-reference/dictionaries/external-dictionaries/external-dicts-dict-sources/#dicts-external_dicts_dict_sources-mysql</a></li><li><a href=https://github.com/ClickHouse/ClickHouse/blob/9f5cd35a6963cc556a51218b46b0754dcac7306a/tests/testflows/aes_encryption/tests/compatibility/mysql/dictionary.py#L35-L51 target=_blank>https://github.com/ClickHouse/ClickHouse/blob/9f5cd35a6963cc556a51218b46b0754dcac7306a/tests/testflows/aes_encryption/tests/compatibility/mysql/dictionary.py#L35-L51</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-eb3d7cbed2a5c568b2bb9a98bbc492ee>4 - ODBC Driver for ClickHouse®</h1><div class=lead>ODBC Driver for ClickHouse®</div><p><a href=https://docs.microsoft.com/en-us/sql/odbc/reference/odbc-overview target=_blank>ODBC</a>
interface for ClickHouse® RDBMS.</p><p>Licensed under the <a href="https://github.com/ClickHouse/clickhouse-odbc?tab=Apache-2.0-1-ov-file#readme" target=_blank>Apache 2.0</a>
.</p><h2 id=installation-and-usage>Installation and usage</h2><h3 id=windows>Windows</h3><ol><li>Download the latest <a href=https://github.com/ClickHouse/clickhouse-odbc/releases target=_blank>release</a>
. On 64bit system you usually need both 32 bit and 64 bit drivers.</li><li>Install (usually you will need ANSI driver, but better to install both versions, see below).</li><li>Configure ClickHouse DSN.</li></ol><p>Note: that install driver linked against MDAC (which is default for Windows), some non-windows native
applications (cygwin / msys64 based) may require driver linked against unixodbc. Build section below.</p><h3 id=macos>MacOS</h3><ol><li>Install <a href=https://brew.sh/ target=_blank>homebrew</a>
.</li><li>Install driver</li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>brew install https://raw.githubusercontent.com/proller/homebrew-core/chodbc/Formula/clickhouse-odbc.rb
</span></span></code></pre></div><ol start=3><li>Add ClickHouse DSN configuration into ~/.odbc.ini file. (<a href>sample</a>
)</li></ol><p>Note: that install driver linked against iodbc (which is default for Mac), some homebrew applications
(like python) may require unixodbc driver to work properly. In that case see Build section below.</p><h3 id=linux>Linux</h3><ol><li>DEB/RPM packaging is not provided yet, please build & install the driver from sources.</li><li>Add ClickHouse DSN configuration into ~/.odbc.ini file. (<a href>sample</a>
)</li></ol><h2 id=configuration>Configuration</h2><p>On Linux / Max you configure DSN by adding new desctions in ~/.odbc.ini
(See sample file: <a href=https://github.com/ClickHouse/clickhouse-odbc/blob/fd74398b50201ab13b535cdfab57bca86e588b37/packaging/odbc.ini.sample target=_blank>https://github.com/ClickHouse/clickhouse-odbc/blob/fd74398b50201ab13b535cdfab57bca86e588b37/packaging/odbc.ini.sample</a>
)</p><p>On Windows you can create/edit DSN using GUI tool through Control Panel.</p><p>The list of DSN parameters recognized by the driver is as follows:</p><table><thead><tr><th style=text-align:center>Parameter</th><th style=text-align:center>Default value</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>Url</code></td><td style=text-align:center>empty</td><td style=text-align:left>URL that points to a running ClickHouse instance, may include username, password, port, database, etc.</td></tr><tr><td style=text-align:center><code>Proto</code></td><td style=text-align:center>deduced from <code>Url</code>, or from <code>Port</code> and <code>SSLMode</code>: <code>https</code> if <code>443</code> or <code>8443</code> or <code>SSLMode</code> is not empty, <code>http</code> otherwise</td><td style=text-align:left>Protocol, one of: <code>http</code>, <code>https</code></td></tr><tr><td style=text-align:center><code>Server</code> or <code>Host</code></td><td style=text-align:center>deduced from <code>Url</code></td><td style=text-align:left>IP or hostname of a server with a running ClickHouse instance on it</td></tr><tr><td style=text-align:center><code>Port</code></td><td style=text-align:center>deduced from <code>Url</code>, or from <code>Proto</code>: <code>8443</code> if <code>https</code>, <code>8123</code> otherwise</td><td style=text-align:left>Port on which the ClickHouse instance is listening</td></tr><tr><td style=text-align:center><code>Path</code></td><td style=text-align:center><code>/query</code></td><td style=text-align:left>Path portion of the URL</td></tr><tr><td style=text-align:center><code>UID</code> or <code>Username</code></td><td style=text-align:center><code>default</code></td><td style=text-align:left>User name</td></tr><tr><td style=text-align:center><code>PWD</code> or <code>Password</code></td><td style=text-align:center>empty</td><td style=text-align:left>Password</td></tr><tr><td style=text-align:center><code>Database</code></td><td style=text-align:center><code>default</code></td><td style=text-align:left>Database name to connect to</td></tr><tr><td style=text-align:center><code>Timeout</code></td><td style=text-align:center><code>30</code></td><td style=text-align:left>Connection timeout</td></tr><tr><td style=text-align:center><code>SSLMode</code></td><td style=text-align:center>empty</td><td style=text-align:left>Certificate verification method (used by TLS/SSL connections, ignored in Windows), one of: <code>allow</code>, <code>prefer</code>, <code>require</code>, use <code>allow</code> to enable <a href=https://www.openssl.org/docs/manmaster/man3/SSL_CTX_set_verify.html target=_blank>SSL_VERIFY_PEER</a>
TLS/SSL certificate verification mode, <a href=https://www.openssl.org/docs/manmaster/man3/SSL_CTX_set_verify.html target=_blank>SSL_VERIFY_PEER | SSL_VERIFY_FAIL_IF_NO_PEER_CERT</a>
is used otherwise</td></tr><tr><td style=text-align:center><code>PrivateKeyFile</code></td><td style=text-align:center>empty</td><td style=text-align:left>Path to private key file (used by TLS/SSL connections), can be empty if no private key file is used</td></tr><tr><td style=text-align:center><code>CertificateFile</code></td><td style=text-align:center>empty</td><td style=text-align:left>Path to certificate file (used by TLS/SSL connections, ignored in Windows), if the private key and the certificate are stored in the same file, this can be empty if <code>PrivateKeyFile</code> is specified</td></tr><tr><td style=text-align:center><code>CALocation</code></td><td style=text-align:center>empty</td><td style=text-align:left>Path to the file or directory containing the CA/root certificates (used by TLS/SSL connections, ignored in Windows)</td></tr><tr><td style=text-align:center><code>DriverLog</code></td><td style=text-align:center><code>on</code> if <code>CMAKE_BUILD_TYPE</code> is <code>Debug</code>, <code>off</code> otherwise</td><td style=text-align:left>Enable or disable the extended driver logging</td></tr><tr><td style=text-align:center><code>DriverLogFile</code></td><td style=text-align:center><code>\temp\clickhouse-odbc-driver.log</code> on Windows, <code>/tmp/clickhouse-odbc-driver.log</code> otherwise</td><td style=text-align:left>Path to the extended driver log file (used when <code>DriverLog</code> is <code>on</code>)</td></tr></tbody></table><h2 id=troubleshooting--bug-reporting>Troubleshooting & bug reporting</h2><p>If some software doesn&rsquo;t work properly with that driver, but works good with other drivers - we will be appropriate if you will be able to collect debug info.</p><p>To debug issues with the driver, first things that need to be done are:</p><ul><li>enabling driver manager tracing. Links may contain some irrelevant vendor-specific details.<ul><li>on Windows/MDAC: <a href=https://dev.mysql.com/doc/connector-odbc/en/connector-odbc-configuration-trace-windows.html target=_blank>1</a>
, <a href=https://www.simba.com/blog/odbc-troubleshooting-tracing/ target=_blank>2</a>
, <a href=https://docs.microsoft.com/en-us/sql/odbc/reference/develop-app/enabling-tracing target=_blank>3</a></li><li>on Mac/iODBC: <a href=https://www.simba.com/blog/odbc-troubleshooting-tracing/ target=_blank>1</a>
, <a href=http://www.iodbc.org/dataspace/doc/iodbc/wiki/iodbcWiki/FAQ#Tracing%20Application%20Behavior target=_blank>2</a></li><li>on Linux/unixODBC: <a href=https://www.simba.com/blog/odbc-troubleshooting-tracing/ target=_blank>1</a>
, <a href=https://www.easysoft.com/support/kb/kb00945.html target=_blank>2</a></li></ul></li><li>enabling driver logging, see <code>DriverLog</code> and <code>DriverLogFile</code> DSN parameters above</li><li>making sure that the application is allowed to create and write these driver log and driver manager trace files</li><li>follow the steps leading to the issue.</li></ul><p>Collected log files will help to diagnose & solve the issue.</p><h2 id=driver-managers>Driver Managers</h2><p>Note, that since ODBC drivers are not used directly by a user, but rather accessed through applications, which in their turn access the driver through ODBC driver manager, user have to install the driver for the <strong>same architecture</strong> (32- or 64-bit) as the application that is going to access the driver. Moreover, both the driver and the application must be compiled for (and actually use during run-time) the <strong>same ODBC driver manager implementation</strong> (we call them &ldquo;ODBC providers&rdquo; here). There are three supported ODBC providers:</p><ul><li>ODBC driver manager associated with <strong>MDAC</strong> (Microsoft Data Access Components, sometimes referenced as WDAC, Windows Data Access Components) - the standard ODBC provider of Windows</li><li><strong>UnixODBC</strong> - the most common ODBC provider in Unix-like systems. Theoretically, could be used in Cygwin or MSYS/MinGW environments in Windows too.</li><li><strong>iODBC</strong> - less common ODBC provider, mainly used in Unix-like systems, however, it is the standard ODBC provider in macOS. Theoretically, could be used in Cygwin or MSYS/MinGW environments in Windows too.</li></ul><p>If you don&rsquo;t see a package that matches your platforms, or the version of your system is significantly different than those of the available packages, or maybe you want to try a bleeding edge version of the code that hasn&rsquo;t been released yet, you can always build the driver manually from sources.</p><p>Note, that it is always a good idea to install the driver from the corresponding <strong>native</strong> package (<code>.msi</code>, etc., which you can also easily create if you are building from sources), than use the binaries that were manually copied to some folder.</p><h2 id=building-from-sources>Building from sources</h2><p>The general requirements for building the driver from sources are as follows:</p><ul><li>CMake 3.12 and later</li><li>C++17 and C11 capable compiler toolchain:<ul><li>Clang 4 and later</li><li>GCC 7 and later</li><li>Xcode 10 and later</li><li>Microsoft Visual Studio 2017 and later</li></ul></li><li>ODBC Driver manager (MDAC / unixodbc / iODBC)</li><li>SSL library (openssl)</li></ul><p>Generic build scenario:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>git clone --recursive git@github.com:ClickHouse/clickhouse-odbc.git
</span></span><span style=display:flex><span><span style=color:#204a87>cd</span> clickhouse-odbc
</span></span><span style=display:flex><span>mkdir build
</span></span><span style=display:flex><span><span style=color:#204a87>cd</span> build
</span></span><span style=display:flex><span>cmake -DCMAKE_BUILD_TYPE<span style=color:#ce5c00;font-weight:700>=</span>RelWithDebInfo ..
</span></span><span style=display:flex><span>cmake --build . -C RelWithDebInfo
</span></span></code></pre></div><p>Additional requirements exist for each platform, which also depend on whether packaging and/or testing is performed.</p><h3 id=linuxmacos>Linux/macOS</h3><p>Execute the following in the terminal to install needed dependencies:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#8f5902;font-style:italic># on Red Hat/CentOS (tested on CentOS 7)</span>
</span></span><span style=display:flex><span>sudo yum groupinstall <span style=color:#4e9a06>&#34;Development Tools&#34;</span>
</span></span><span style=display:flex><span>sudo yum install centos-release-scl
</span></span><span style=display:flex><span>sudo yum install devtoolset-8
</span></span><span style=display:flex><span>sudo yum install git cmake openssl-devel unixODBC-devel <span style=color:#8f5902;font-style:italic># You may use libiodbc-devel INSTEAD of unixODBC-devel</span>
</span></span><span style=display:flex><span>scl <span style=color:#204a87>enable</span> devtoolset-8 -- bash <span style=color:#8f5902;font-style:italic># Enable Software collections for that terminal session, to use newer versions of complilers</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># on Ubuntu (tested on Ubuntu 18.10, for older versions you may need to install newer c++ compiler and cmake versions)</span>
</span></span><span style=display:flex><span>sudo apt install build-essential git cmake libpoco-dev libssl-dev unixodbc-dev <span style=color:#8f5902;font-style:italic># You may use libiodbc-devel INSEAD of unixODBC-devel</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># MacOS: </span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># You will need Xcode 10 or later and Command Line Tools to be installed, as well as [Homebrew](https://brew.sh/).</span>
</span></span><span style=display:flex><span>brew install git cmake make poco openssl libiodbc <span style=color:#8f5902;font-style:italic># You may use unixodbc INSTEAD of libiodbc </span>
</span></span></code></pre></div><p><strong>Note:</strong> usually on Linux you use unixODBC driver manager, and on Mac - iODBC.
In some (rare) cases you may need use other driver manager, please do it only
if you clearly understand the differences. Driver should be used with the driver
manager it was linked to.</p><p>Clone the repo with submodules:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>git clone --recursive git@github.com:ClickHouse/clickhouse-odbc.git
</span></span></code></pre></div><p>Enter the cloned source tree, create a temporary build folder, and generate a Makefile for the project in it:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#204a87>cd</span> clickhouse-odbc
</span></span><span style=display:flex><span>mkdir build
</span></span><span style=display:flex><span><span style=color:#204a87>cd</span> build
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Configuration options for the project can be specified in the next command in a form of &#39;-Dopt=val&#39;</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># For MacOS: you may also add &#39;-G Xcode&#39; to the next command, in order to use Xcode as a build system or IDE, and generate the solution and project files instead of Makefile.</span>
</span></span><span style=display:flex><span>cmake -DCMAKE_BUILD_TYPE<span style=color:#ce5c00;font-weight:700>=</span>RelWithDebInfo ..
</span></span></code></pre></div><p>Build the generated solution in-place:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cmake --build . -C RelWithDebInfo
</span></span><span style=display:flex><span>cmake --build . -C RelWithDebInfo --target package
</span></span></code></pre></div><p>&mldr;and, optionally, run tests (note, that for non-unit tests, preconfigured driver and DSN entries must exist, that point to the binaries generated in this build folder):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cmake --build . -C RelWithDebInfo --target <span style=color:#204a87>test</span>
</span></span></code></pre></div><p>For MacOS: if you configured the project with &lsquo;-G Xcode&rsquo; initially, open the IDE and build <code>all</code>, <code>package</code>, and <code>test</code> targets manually from there</p><pre tabindex=0><code>cmake --open .
</code></pre><h3 id=windows-1>Windows</h3><p>CMake bundled with the recent versions of Visual Studio can be used.</p><p>An SDK required for building the ODBC driver is included in Windows SDK, which in its turn is also bundled with Visual Studio.</p><p>You will need to install WiX toolset to be able to generate <code>.msi</code> packages. You can download and install it from <a href=https://wixtoolset.org/ target=_blank>WiX toolset home page</a>
.</p><p>All of the following commands have to be issued in Visual Studio Command Prompt:</p><ul><li>use <code>x86 Native Tools Command Prompt for VS 2019</code> or equivalent for 32-bit builds</li><li>use <code>x64 Native Tools Command Prompt for VS 2019</code> or equivalent for 64-bit builds</li></ul><p>Clone the repo with submodules:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>git clone --recursive git@github.com:ClickHouse/clickhouse-odbc.git
</span></span></code></pre></div><p>Enter the cloned source tree, create a temporary build folder, and generate the solution and project files in it:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#204a87>cd</span> clickhouse-odbc
</span></span><span style=display:flex><span>mkdir build
</span></span><span style=display:flex><span><span style=color:#204a87>cd</span> build
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Configuration options for the project can be specified in the next command in a form of &#39;-Dopt=val&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Use the following command for 32-bit build only.</span>
</span></span><span style=display:flex><span>cmake -A Win32 -DCMAKE_BUILD_TYPE<span style=color:#ce5c00;font-weight:700>=</span>RelWithDebInfo ..
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Use the following command for 64-bit build only.</span>
</span></span><span style=display:flex><span>cmake -A x64 -DCMAKE_BUILD_TYPE<span style=color:#ce5c00;font-weight:700>=</span>RelWithDebInfo ..
</span></span></code></pre></div><p>Build the generated solution in-place:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cmake --build . -C RelWithDebInfo
</span></span><span style=display:flex><span>cmake --build . -C RelWithDebInfo --target package
</span></span></code></pre></div><p>&mldr;and, optionally, run tests (note, that for non-unit tests, preconfigured driver and DSN entries must exist, that point to the binaries generated in this build folder):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cmake --build . -C RelWithDebInfo --target <span style=color:#204a87>test</span>
</span></span></code></pre></div><p>&mldr;or open the IDE and build <code>all</code>, <code>package</code>, and <code>test</code> targets manually from there:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cmake --open .
</span></span></code></pre></div><h3 id=cmake-options>cmake options</h3><p>The list of configuration options recognized during the CMake generation step is as follows:</p><table><thead><tr><th style=text-align:center>Option</th><th style=text-align:center>Default value</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:center><code>CMAKE_BUILD_TYPE</code></td><td style=text-align:center><code>RelWithDebInfo</code></td><td style=text-align:left>Build type, one of: <code>Debug</code>, <code>Release</code>, <code>RelWithDebInfo</code></td></tr><tr><td style=text-align:center><code>CH_ODBC_ENABLE_SSL</code></td><td style=text-align:center><code>ON</code></td><td style=text-align:left>Enable TLS/SSL (required for utilizing <code>https://</code> interface, etc.)</td></tr><tr><td style=text-align:center><code>CH_ODBC_ENABLE_INSTALL</code></td><td style=text-align:center><code>ON</code></td><td style=text-align:left>Enable install targets (required for packaging)</td></tr><tr><td style=text-align:center><code>CH_ODBC_ENABLE_TESTING</code></td><td style=text-align:center>inherits value of <code>BUILD_TESTING</code></td><td style=text-align:left>Enable test targets</td></tr><tr><td style=text-align:center><code>CH_ODBC_PREFER_BUNDLED_THIRD_PARTIES</code></td><td style=text-align:center><code>ON</code></td><td style=text-align:left>Prefer bundled over system variants of third party libraries</td></tr><tr><td style=text-align:center><code>CH_ODBC_PREFER_BUNDLED_POCO</code></td><td style=text-align:center>inherits value of <code>CH_ODBC_PREFER_BUNDLED_THIRD_PARTIES</code></td><td style=text-align:left>Prefer bundled over system variants of Poco library</td></tr><tr><td style=text-align:center><code>CH_ODBC_PREFER_BUNDLED_SSL</code></td><td style=text-align:center>inherits value of <code>CH_ODBC_PREFER_BUNDLED_POCO</code></td><td style=text-align:left>Prefer bundled over system variants of TLS/SSL library</td></tr><tr><td style=text-align:center><code>CH_ODBC_PREFER_BUNDLED_GOOGLETEST</code></td><td style=text-align:center>inherits value of <code>CH_ODBC_PREFER_BUNDLED_THIRD_PARTIES</code></td><td style=text-align:left>Prefer bundled over system variants of Google Test library</td></tr><tr><td style=text-align:center><code>CH_ODBC_PREFER_BUNDLED_NANODBC</code></td><td style=text-align:center>inherits value of <code>CH_ODBC_PREFER_BUNDLED_THIRD_PARTIES</code></td><td style=text-align:left>Prefer bundled over system variants of nanodbc library</td></tr><tr><td style=text-align:center><code>CH_ODBC_RUNTIME_LINK_STATIC</code></td><td style=text-align:center><code>OFF</code></td><td style=text-align:left>Link with compiler and language runtime statically</td></tr><tr><td style=text-align:center><code>CH_ODBC_THIRD_PARTY_LINK_STATIC</code></td><td style=text-align:center><code>ON</code></td><td style=text-align:left>Link with third party libraries statically</td></tr><tr><td style=text-align:center><code>CH_ODBC_DEFAULT_DSN_ANSI</code></td><td style=text-align:center><code>ClickHouse DSN (ANSI)</code></td><td style=text-align:left>Default ANSI DSN name</td></tr><tr><td style=text-align:center><code>CH_ODBC_DEFAULT_DSN_UNICODE</code></td><td style=text-align:center><code>ClickHouse DSN (Unicode)</code></td><td style=text-align:left>Default Unicode DSN name</td></tr><tr><td style=text-align:center><code>TEST_DSN</code></td><td style=text-align:center>inherits value of <code>CH_ODBC_DEFAULT_DSN_ANSI</code></td><td style=text-align:left>ANSI DSN name to use in tests</td></tr><tr><td style=text-align:center><code>TEST_DSN_W</code></td><td style=text-align:center>inherits value of <code>CH_ODBC_DEFAULT_DSN_UNICODE</code></td><td style=text-align:left>Unicode DSN name to use in tests</td></tr></tbody></table><h3 id=packaging--redistributing-the-driver>Packaging / redistributing the driver</h3><p>You can just copy the library to another computer, in that case you need to</p><ol><li>install run-time dependencies on target computer<ul><li>Windows:<ul><li>MDAC driver manager (preinstalled on all modern Windows systems)</li><li><code>C++ Redistributable for Visual Studio 2017</code> or same for <code>2019</code>, etc.</li></ul></li><li>Linux</li></ul></li></ol><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#8f5902;font-style:italic># CentOS / RedHat</span>
</span></span><span style=display:flex><span>sudo yum install openssl unixODBC
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># Debian/Ubuntu</span>
</span></span><span style=display:flex><span>sudo apt install openssl unixodbc
</span></span></code></pre></div><ul><li>MacOS (assuming you have <a href=https://brew.sh/ target=_blank>Homebrew</a>
installed):</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>brew install poco openssl libiodbc
</span></span></code></pre></div><ol start=2><li>register the driver so that the corresponding ODBC provider is able to locate it.</li></ol><p>All this involves modifying a dedicated registry keys in case of MDAC, or editing <code>odbcinst.ini</code> (for driver registration) and <code>odbc.ini</code> (for DSN definition) files for UnixODBC or iODBC, directly or indirectly.</p><p>This will be done automatically using some default values if you are installing the driver using native installers.</p><p>Otherwise, if you are configuring manually, or need to modify the default configuration created by the installer, please see the exact locations of files (or registry keys) that need to be modified.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d2afec8f52450d3642df08e91fab21b4>5 - ClickHouse® + Spark</h1><h3 id=jdbc>jdbc</h3><p>The trivial & natural way to talk to ClickHouse from Spark is using jdbc. There are 2 jdbc drivers:</p><ul><li><a href=https://github.com/ClickHouse/clickhouse-jdbc/ target=_blank>https://github.com/ClickHouse/clickhouse-jdbc/</a></li><li><a href=https://github.com/housepower/ClickHouse-Native-JDBC#integration-with-spark target=_blank>https://github.com/housepower/ClickHouse-Native-JDBC#integration-with-spark</a></li></ul><p>ClickHouse-Native-JDBC has some hints about integration with Spark even in the main README file.</p><p>&lsquo;Official&rsquo; driver does support some conversion of complex data types (Roaring bitmaps) for Spark-ClickHouse integration: <a href=https://github.com/ClickHouse/clickhouse-jdbc/pull/596 target=_blank>https://github.com/ClickHouse/clickhouse-jdbc/pull/596</a></p><p>But proper partitioning of the data (to spark partitions) may be tricky with jdbc.</p><p>Some example snippets:</p><ul><li><a href=https://markelic.de/how-to-access-your-clickhouse-database-with-spark-in-python/ target=_blank>https://markelic.de/how-to-access-your-clickhouse-database-with-spark-in-python/</a></li><li><a href=https://stackoverflow.com/questions/60448877/how-can-i-write-spark-dataframe-to-clickhouse target=_blank>https://stackoverflow.com/questions/60448877/how-can-i-write-spark-dataframe-to-clickhouse</a></li></ul><h3 id=connectors>Connectors</h3><ul><li><a href=https://github.com/DmitryBe/spark-clickhouse target=_blank>https://github.com/DmitryBe/spark-clickhouse</a>
(looks dead)</li><li><a href=https://github.com/VaBezruchko/spark-clickhouse-connector target=_blank>https://github.com/VaBezruchko/spark-clickhouse-connector</a>
(is not actively maintained).</li><li><a href=https://github.com/housepower/spark-clickhouse-connector target=_blank>https://github.com/housepower/spark-clickhouse-connector</a>
(actively developing connector from housepower - same guys as authors of ClickHouse-Native-JDBC)</li></ul><h3 id=via-kafka>via Kafka</h3><p>ClickHouse can produce / consume data from/to Kafka to exchange data with Spark.</p><h3 id=via-hdfs>via hdfs</h3><p>You can load data into hadoop/hdfs using sequence of statements like <code>INSERT INTO FUNCTION hdfs(...) SELECT ... FROM clickhouse_table</code>
later process the data from hdfs by spark and do the same in reverse direction.</p><h3 id=via-s3>via s3</h3><p>Similar to above but using s3.</p><h3 id=via-shell-calls>via shell calls</h3><p>You can call other commands from Spark. Those commands can be <code>clickhouse-client</code> and/or <code>clickhouse-local</code>.</p><h3 id=do-you-really-need-spark->do you really need Spark? :)</h3><p>In many cases you can do everything inside ClickHouse without Spark help :)
Arrays, Higher-order functions, machine learning, integration with lot of different things including the possibility to run some external code using executable dictionaries or UDF.</p><h2 id=more-info--some-unordered-links-mostly-in-chinese--russian>More info + some unordered links (mostly in Chinese / Russian)</h2><ul><li>Spark + ClickHouse: not a fight, but a symbiosis (Russian) <a href=https://github.com/ClickHouse/clickhouse-presentations/blob/master/meetup28/spark_and_clickhouse.pdf target=_blank>https://github.com/ClickHouse/clickhouse-presentations/blob/master/meetup28/spark_and_clickhouse.pdf</a>
(russian)</li><li>Using a bunch of ClickHouse and Spark in MFI Soft (Russian) <a href="https://www.youtube.com/watch?v=ID8eTnmag0s" target=_blank>https://www.youtube.com/watch?v=ID8eTnmag0s</a>
(russian)</li><li>Spark read and write ClickHouse (Chinese: Spark读写ClickHouse) <a href=https://yerias.github.io/2020/12/08/clickhouse/9/#Jdbc%E6%93%8D%E4%BD%9Cclickhouse target=_blank>https://yerias.github.io/2020/12/08/clickhouse/9/#Jdbc%E6%93%8D%E4%BD%9Cclickhouse</a></li><li>Spark JDBC write ClickHouse operation summary (Chinese: Spark JDBC 写 ClickHouse 操作总结) <a href="https://www.jianshu.com/p/43f78c8a025b?hmsr=toutiao.io&amp;utm_campaign=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io" target=_blank>https://www.jianshu.com/p/43f78c8a025b?hmsr=toutiao.io&amp;utm_campaign=toutiao.io&amp;utm_medium=toutiao.io&amp;utm_source=toutiao.io</a></li><li>Spark-sql is based on ClickHouse&rsquo;s DataSourceV2 data source extension (Chinese: spark-sql基于ClickHouse的DataSourceV2数据源扩展)
<a href=https://www.cnblogs.com/mengyao/p/4689866.html target=_blank>https://www.cnblogs.com/mengyao/p/4689866.html</a></li><li>Alibaba integration instructions (English) <a href=https://www.alibabacloud.com/help/doc-detail/191192.htm target=_blank>https://www.alibabacloud.com/help/doc-detail/191192.htm</a></li><li>Tencent integration instructions (English) <a href=https://intl.cloud.tencent.com/document/product/1026/35884 target=_blank>https://intl.cloud.tencent.com/document/product/1026/35884</a></li><li>Yandex DataProc demo: loading files from S3 to ClickHouse with Spark (Russian) <a href="https://www.youtube.com/watch?v=N3bZW0_rRzI" target=_blank>https://www.youtube.com/watch?v=N3bZW0_rRzI</a></li><li>ClickHouse official documentation_Spark JDBC writes some pits of ClickHouse (Chinese: ClickHouse官方文档_Spark JDBC写ClickHouse的一些坑) <a href=https://blog.csdn.net/weixin_39615984/article/details/111206050 target=_blank>https://blog.csdn.net/weixin_39615984/article/details/111206050</a></li><li>ClickHouse data import: Flink, Spark, Kafka, MySQL, Hive (Chinese: 篇五|ClickHouse数据导入 Flink、Spark、Kafka、MySQL、Hive) <a href=https://zhuanlan.zhihu.com/p/299094269 target=_blank>https://zhuanlan.zhihu.com/p/299094269</a></li><li>SPARK-CLICKHOUSE-ES REAL-TIME PROJECT EIGHTH DAY-PRECISE ONE-TIME CONSUMPTION SAVE OFFSET. (Chinese: SPARK-CLICKHOUSE-ES实时项目第八天-精确一次性消费保存偏移量) <a href=https://www.freesion.com/article/71421322524/ target=_blank>https://www.freesion.com/article/71421322524/</a></li><li>HDFS+ClickHouse+Spark: A lightweight big data analysis system from 0 to 1. (Chinese: HDFS+ClickHouse+Spark：从0到1实现一款轻量级大数据分析系统) <a href=https://juejin.cn/post/6850418114962653198 target=_blank>https://juejin.cn/post/6850418114962653198</a></li><li>ClickHouse Clustering for Spark Developer (English) <a href=http://blog.madhukaraphatak.com/clickouse-clustering-spark-developer/ target=_blank>http://blog.madhukaraphatak.com/clickouse-clustering-spark-developer/</a></li><li>«Иногда приходится заглядывать в код Spark»: Александр Морозов (SEMrush) об использовании Scala, Spark и ClickHouse. (Russian) <a href=https://habr.com/ru/company/jugru/blog/341288/ target=_blank>https://habr.com/ru/company/jugru/blog/341288/</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-490f1eab7bb37421ddd14a8d6c58e9ab>6 - BI Tools</h1><div class=lead>Business Intelligence Tools</div><ul><li>Superset: <a href=https://superset.apache.org/docs/databases/clickhouse target=_blank>https://superset.apache.org/docs/databases/clickhouse</a></li><li>Metabase: <a href=https://github.com/enqueue/metabase-clickhouse-driver target=_blank>https://github.com/enqueue/metabase-clickhouse-driver</a></li><li>Querybook: <a href=https://www.querybook.org/docs/setup_guide/connect_to_query_engines/#all-query-engines target=_blank>https://www.querybook.org/docs/setup_guide/connect_to_query_engines/#all-query-engines</a></li><li>Tableau: <a href=https://github.com/Altinity/tableau-connector-for-clickhouse target=_blank>Altinity Tableau Connector for ClickHouse®</a>
support both JDBC & ODBC drivers</li><li>Looker: <a href=https://docs.looker.com/setup-and-management/database-config/clickhouse target=_blank>https://docs.looker.com/setup-and-management/database-config/clickhouse</a></li><li>Apache Zeppelin</li><li>SeekTable</li><li>ReDash</li><li>Mondrian: <a href=https://altinity.com/blog/accessing-clickhouse-from-excel-using-mondrian-rolap-engine target=_blank>https://altinity.com/blog/accessing-clickhouse-from-excel-using-mondrian-rolap-engine</a></li><li>Grafana: <a href=https://docs.altinity.com/integrations/clickhouse-and-grafana/ target=_blank>Integrating Grafana with ClickHouse</a></li><li>Cumul.io</li><li>Tablum: <a href=https://tablum.io target=_blank>https://tablum.io</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-7a1dc52ba21a64be26ec5780459eb575>7 - CatBoost / MindsDB / Fast.ai</h1><div class=lead>CatBoost / MindsDB / Fast.ai</div><div class="alert alert-info" role=alert><h4 class=alert-heading>Info</h4>Article is based on feedback provided by one of Altinity clients.</div><p>CatBoost:</p><ul><li>It uses gradient boosting - a hard to use technique which can outperform neural networks. Gradient boosting is powerful but it&rsquo;s easy to shoot yourself in the foot using it.</li><li>The documentation on how to use it is quite lacking. The only good source of information on how to properly configure a model to yield good results is this video: <a href="https://www.youtube.com/watch?v=usdEWSDisS0" target=_blank>https://www.youtube.com/watch?v=usdEWSDisS0</a>
. We had to dig around GitHub issues to find out how to make it work with ClickHouse®.</li><li>CatBoost is fast. Other libraries will take ~5X to ~10X as long to do what CatBoost does.</li><li>CatBoost will do preprocessing out of the box (fills nulls, apply standard scaling, encodes strings as numbers).</li><li>CatBoost has all functions you&rsquo;d need (metrics, plotters, feature importance)</li></ul><p>It makes sense to split what CatBoost does into 2 parts:</p><ul><li>preprocessing (fills nulls, apply standard scaling, encodes strings as numbers)</li><li>number crunching (convert preprocessed numbers to another number - ex: revenue of impression)</li></ul><p>Compared to <a href=http://fast.ai/ target=_blank>Fast.ai</a>
, CatBoost pre-processing is as simple to use and produces results that can be as good as <a href=http://fast.ai/ target=_blank>Fast.ai</a>
.</p><p>The number crunching part of <a href=http://fast.ai/ target=_blank>Fast.ai</a>
is no-config. For CatBoost you need to configure it, a lot.</p><p>CatBoost won&rsquo;t simplify or hide any complexity of the process. So you need to know data science terms and what it does (ex: if your model is underfitting you can use a smaller l2_reg parameter in the model constructor).</p><p>In the end both <a href=http://fast.ai/ target=_blank>Fast.ai</a>
and CatBoost can yield comparable results.</p><p>Regarding deploying models, CatBoost is really good. The model runs fast, it has a simple binary format which can be loaded in ClickHouse, C, or Python and it will encapsulate pre-processing with the binary file. Deploying <a href=http://fast.ai/ target=_blank>Fast.ai</a>
models at scale/speed is impossible out of the box (we have our custom solution to do it which is not simple).</p><p>TLDR: CatBoost is fast, produces awesome models, is super easy to deploy and it&rsquo;s easy to use/train (after becoming familiar with it despite the bad documentation & if you know data science terms).</p><h2 id=regarding-mindsdb>Regarding MindsDB</h2><p>The project seems to be a good idea but it&rsquo;s too young. I was using the GUI version and I&rsquo;ve encountered some bugs, and none of those bugs have a good error message.</p><ul><li><p>It won&rsquo;t show data in preview.</p></li><li><p>The &ldquo;download&rdquo; button won&rsquo;t work.</p></li><li><p>It&rsquo;s trying to create and drop tables in ClickHouse without me asking it to.</p></li><li><p>Other than bugs:</p><ul><li>It will only use 1 core to do everything (training, analysis, download).</li><li>Analysis will only run with a very small subset of data, if I use something like 1M rows it never finishes.</li></ul></li><li><p>Training a model on 100k rows took 25 minutes - (CatBoost takes 90s to train with 1M rows)</p></li><li><p>The model trained on MindsDB is way worse. It had r-squared of 0.46 (CatBoost=0.58)</p><p>To me it seems that they are a plugin which connects ClickHouse to MySQL to run the model in Pytorch.</p><p>It&rsquo;s too complex and hard to debug and understand. The resulting model is not good enough.</p><p>TLDR: Easy to use (if bugs are ignored), too slow to train & produces a bad model.</p></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-902c0f257a8ddd6f658f1246ef020032>8 - Google S3 (GCS)</h1><p>GCS with the table function - seems to work correctly for simple scenarios.</p><p>Essentially you can follow the steps from the <a href=https://cloud.google.com/storage/docs/aws-simple-migration target=_blank>Migrating from Amazon S3 to Cloud Storage</a>
.</p><ol><li>Set up a GCS bucket.</li><li>This bucket must be set as part of the default project for the account. This configuration can be found in settings -> interoperability.</li><li>Generate a HMAC key for the account, can be done in settings -> interoperability, in the section for user account access keys.</li><li>In ClickHouse®, replace the S3 bucket endpoint with the GCS bucket endpoint This must be done with the path-style GCS endpoint: <code>https://storage.googleapis.com/BUCKET_NAME/OBJECT_NAME</code>.</li><li>Replace the aws access key id and aws secret access key with the corresponding parts of the HMAC key.</li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-baebc0ff2257ac7906ebf1b6671d8990>9 - Kafka</h1><div class=lead>Kafka</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>git log -- contrib/librdkafka <span style=color:#000;font-weight:700>|</span> git name-rev --stdin
</span></span></code></pre></div><table><thead><tr><th style=text-align:left><strong>ClickHouse® version</strong></th><th style=text-align:left><strong>librdkafka version</strong></th></tr></thead><tbody><tr><td style=text-align:left>25.3+ (<a href=https://github.com/ClickHouse/ClickHouse/issues/63697 target=_blank>#63697</a>
)</td><td style=text-align:left><a href=https://github.com/confluentinc/librdkafka/blob/v2.8.0/CHANGELOG.md target=_blank>2.8.0</a>
+ few <a href=https://gist.github.com/filimonov/ad252aa601d4d99fb57d4d76f14aa2bf target=_blank>fixes</a></td></tr><tr><td style=text-align:left>21.10+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/27883 target=_blank>#27883</a>
)</td><td style=text-align:left><a href=https://github.com/edenhill/librdkafka/blob/v1.6.1/CHANGELOG.md target=_blank>1.6.1</a>
+ snappy fixes + boring ssl + illumos_build fixes + edenhill#3279 fix</td></tr><tr><td style=text-align:left>21.6+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/23874 target=_blank>#23874</a>
)</td><td style=text-align:left><a href=https://github.com/edenhill/librdkafka/blob/v1.6.1/CHANGELOG.md target=_blank>1.6.1</a>
+ snappy fixes + boring ssl + illumos_build fixes</td></tr><tr><td style=text-align:left>21.1+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/18671 target=_blank>#18671</a>
)</td><td style=text-align:left><a href=https://github.com/edenhill/librdkafka/blob/v1.6.0-RC3/CHANGELOG.md target=_blank>1.6.0-RC3</a>
+ snappy fixes + boring ssl</td></tr><tr><td style=text-align:left>20.13+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/18053 target=_blank>#18053</a>
)</td><td style=text-align:left><a href=https://github.com/edenhill/librdkafka/blob/v1.5.0/CHANGELOG.md target=_blank>1.5.0</a>
+ msan fixes + snappy fixes + boring ssl</td></tr><tr><td style=text-align:left>20.7+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/12991 target=_blank>#12991</a>
)</td><td style=text-align:left><a href=https://github.com/edenhill/librdkafka/blob/v1.5.0/CHANGELOG.md target=_blank>1.5.0</a>
+ msan fixes</td></tr><tr><td style=text-align:left>20.5+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/11256 target=_blank>#11256</a>
)</td><td style=text-align:left><a href=https://github.com/edenhill/librdkafka/blob/v1.4.2/CHANGELOG.md target=_blank>1.4.2</a></td></tr><tr><td style=text-align:left>20.2+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/9000 target=_blank>#9000</a>
)</td><td style=text-align:left><a href="https://github.com/edenhill/librdkafka/releases?after=v1.4.0-PRE1" target=_blank>1.3.0</a></td></tr><tr><td style=text-align:left>19.11+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/5872 target=_blank>#5872</a>
)</td><td style=text-align:left><a href="https://github.com/edenhill/librdkafka/releases?after=v1.1.0-selfstatic-test12" target=_blank>1.1.0</a></td></tr><tr><td style=text-align:left>19.5+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/4799 target=_blank>#4799</a>
)</td><td style=text-align:left><a href="https://github.com/edenhill/librdkafka/releases?after=v1.0.1-RC1" target=_blank>1.0.0</a></td></tr><tr><td style=text-align:left>19.1+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/4025 target=_blank>#4025</a>
)</td><td style=text-align:left>1.0.0-RC5</td></tr><tr><td style=text-align:left>v1.1.54382+ (<a href=https://github.com/ClickHouse/ClickHouse/pull/2276 target=_blank>#2276</a>
)</td><td style=text-align:left><a href="https://github.com/edenhill/librdkafka/releases?after=v0.11.4-adminapi-post1" target=_blank>0.11.4</a></td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-899d8da901ecc94da3c79954ddb7871b>9.1 - Kafka engine Virtual columns</h1><div class=lead>Kafka virtual columns</div><h2 id=kafka-engine-virtual-columns-built-in>Kafka engine virtual columns (built-in)</h2><p><a href="https://clickhouse.com/docs/engines/table-engines/integrations/kafka?utm_source=chatgpt.com#virtual-columns" target=_blank rel=nofollow>From the Kafka engine docs</a>
, the supported virtual columns are:</p><ul><li><p><code>_topic</code> — Kafka topic (LowCardinality(String))</p></li><li><p><code>_key</code> — message key (String)</p></li><li><p><code>_offset</code> — message offset (UInt64)</p></li><li><p><code>_timestamp</code> — message timestamp (Nullable(DateTime))</p></li><li><p><code>_timestamp_ms</code> — timestamp with millisecond precision (Nullable(DateTime64(3)))</p></li><li><p><code>_partition</code> — partition (UInt64)</p></li><li><p><code>_headers.name</code> — header keys (Array(String))</p></li><li><p><code>_headers.value</code> — header values (Array(String))</p></li></ul><p>Extra virtual columns when you enable parse-error streaming:</p><p>If you set <code>kafka_handle_error_mode='stream'</code>, ClickHouse adds:</p><ul><li><p><code>_raw_message</code> — the raw message that failed to parse (String)</p></li><li><p><code>_error</code> — the exception message from parsing failure (String)</p></li></ul><p>Note: <code>_raw_message</code> and <code>_error</code> are populated only when parsing fails; otherwise they’re empty.</p><p>We can use these columns in a materialized view like this for example:</p></div><div class=td-content style=page-break-before:always><h1 id=pg-46af47e683866727c612b8efc5556565>9.2 - Inferring Schema from AvroConfluent Messages in Kafka for ClickHouse®</h1><div class=lead>Learn how to define Kafka table structures in ClickHouse® by using Avro&rsquo;s schema registry & sample message.</div><p>To consume messages from Kafka within ClickHouse®, you need to define the <code>ENGINE=Kafka</code> table structure with all the column names and types.
This task can be particularly challenging when dealing with complex Avro messages, as manually determining the exact schema for
ClickHouse is both tricky and time-consuming. This complexity is particularly frustrating in the case of Avro formats,
where the column names and their types are already clearly defined in the schema registry.</p><p>Although ClickHouse supports schema inference for files, it does not natively support this for Kafka streams.</p><p>Here’s a workaround to infer the schema using AvroConfluent messages:</p><h2 id=step-1-capture-and-store-a-raw-kafka-message>Step 1: Capture and Store a Raw Kafka Message</h2><p>First, create a table in ClickHouse to consume a raw message from Kafka and store it as a file:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TABLE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>test_kafka</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>(</span><span style=color:#000>raw</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>ENGINE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Kafka</span><span style=color:#f8f8f8;text-decoration:underline> 
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>SETTINGS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>kafka_broker_list</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;localhost:29092&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> 
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>         </span><span style=color:#000>kafka_topic_list</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;movies-raw&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> 
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>         </span><span style=color:#000>kafka_format</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;RawBLOB&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#8f5902;font-style:italic>-- Don&#39;t try to parse the message, return it &#39;as is&#39;
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic></span><span style=color:#f8f8f8;text-decoration:underline>         </span><span style=color:#000>kafka_group_name</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;tmp_test&#39;</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#8f5902;font-style:italic>-- Using some dummy consumer group here.
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic></span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>INSERT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>INTO</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>FUNCTION</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>file</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#39;./avro_raw_sample.avro&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;RawBLOB&#39;</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> 
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>SELECT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>*</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>FROM</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>test_kafka</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>LIMIT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#f8f8f8;text-decoration:underline> 
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>SETTINGS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>max_block_size</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>stream_like_engine_allow_direct_select</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>DROP</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TABLE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>test_kafka</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><h2 id=step-2-infer-schema-using-the-stored-file>Step 2: Infer Schema Using the Stored File</h2><p>Using the stored raw message, let ClickHouse infer the schema based on the AvroConfluent format and a specified schema registry URL:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TEMPORARY</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TABLE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>test</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> 
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>SELECT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>*</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>FROM</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>file</span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#39;./avro_raw_sample.avro&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;AvroConfluent&#39;</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> 
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>SETTINGS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>format_avro_schema_registry_url</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;http://localhost:8085&#39;</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>SHOW</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TEMPORARY</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TABLE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>test</span><span style=color:#a40000>\</span><span style=color:#204a87;font-weight:700>G</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>The output from the <code>SHOW CREATE</code> command will display the inferred schema, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-plaintext data-lang=plaintext><span style=display:flex><span>Row 1:
</span></span><span style=display:flex><span>──────
</span></span><span style=display:flex><span>statement: CREATE TEMPORARY TABLE test
</span></span><span style=display:flex><span>(
</span></span><span style=display:flex><span>    `movie_id` Int64,
</span></span><span style=display:flex><span>    `title` String,
</span></span><span style=display:flex><span>    `release_year` Int64
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>ENGINE = Memory
</span></span></code></pre></div><h2 id=step-3-create-the-kafka-table-with-the-inferred-schema>Step 3: Create the Kafka Table with the Inferred Schema</h2><p>Now, use the inferred schema to create the Kafka table:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TABLE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>movies_kafka</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>(</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>movie_id</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Int64</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>title</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>release_year</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Int64</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>ENGINE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Kafka</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>SETTINGS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>kafka_broker_list</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;localhost:29092&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>         </span><span style=color:#000>kafka_topic_list</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;movies-raw&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>         </span><span style=color:#000>kafka_format</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;AvroConfluent&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>         </span><span style=color:#000>kafka_group_name</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;movies&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>         </span><span style=color:#000>kafka_schema_registry_url</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;http://localhost:8085&#39;</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>This approach reduces manual schema definition efforts and enhances data integration workflows by utilizing the schema inference capabilities of ClickHouse for AvroConfluent messages.</p><h2 id=appendix>Appendix</h2><p><strong>Avro</strong> is a binary serialization format used within Apache Kafka for efficiently serializing data with a compact binary format. It relies on schemas, which define the structure of the serialized data, to ensure robust data compatibility and type safety.</p><p><strong>Schema Registry</strong> is a service that provides a centralized repository for Avro schemas. It helps manage and enforce schemas across applications, ensuring that the data exchanged between producers and consumers adheres to a predefined format, and facilitates schema evolution in a safe manner.</p><p>In ClickHouse, the <strong>Avro</strong> format is used for data that contains the schema embedded directly within the file or message. This means the structure of the data is defined and included with the data itself, allowing for self-describing messages. However, embedding the schema within every message is not optimal for streaming large volumes of data, as it increases the workload and network overhead. Repeatedly passing the same schema with each message can be inefficient, particularly in high-throughput environments.</p><p>On the other hand, the <strong>AvroConfluent</strong> format in ClickHouse is specifically designed to work with the Confluent Schema Registry. This format expects the schema to be managed externally in a schema registry rather than being embedded within each message. It retrieves schema information from the Schema Registry, which allows for centralized schema management and versioning, facilitating easier schema evolution and enforcement across different applications using Kafka.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-b782f7dceeb8f45296efecc0559e5d5a>9.3 - Setting the background message broker schedule pool size</h1><div class=lead>Guide to managing the <code>background_message_broker_schedule_pool_size</code> setting for Kafka, RabbitMQ, and NATS table engines in your database.</div><h2 id=overview>Overview</h2><p>When using Kafka, RabbitMQ, or NATS table engines in ClickHouse®, you may encounter issues related to a saturated background thread pool. One common symptom is a warning similar to the following:</p><pre tabindex=0><code>2025.03.14 08:44:26.725868 [ 344 ] {} &lt;Warning&gt; StorageKafka (events_kafka): [rdk:MAXPOLL] [thrd:main]: Application maximum poll interval (60000ms) exceeded by 159ms (adjust max.poll.interval.ms for long-running message processing): leaving group
</code></pre><p>This warning typically appears <strong>not because ClickHouse fails to poll</strong>, but because <strong>there are no available threads</strong> in the background pool to handle the polling in time. In rare cases, the same error might also be caused by long flushing operations to Materialized Views (MVs), especially if their logic is complex or chained.</p><p>To resolve this, you should monitor and, if needed, increase the value of the <code>background_message_broker_schedule_pool_size</code> setting.</p><hr><h2 id=step-1-check-thread-pool-utilization>Step 1: Check Thread Pool Utilization</h2><p>Run the following SQL query to inspect the current status of your background message broker thread pool:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>SELECT</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000;font-weight:700>(</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>SELECT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>value</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>FROM</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>system</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>metrics</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>WHERE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>metric</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;BackgroundMessageBrokerSchedulePoolTask&#39;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>tasks</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000;font-weight:700>(</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>SELECT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>value</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>FROM</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>system</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>metrics</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>WHERE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>metric</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;BackgroundMessageBrokerSchedulePoolSize&#39;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>pool_size</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>pool_size</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>-</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>tasks</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>free_threads</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>If you have <code>metric_log</code> enabled, you can also monitor the <strong>minimum number of free threads over the day</strong>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>SELECT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>min</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>CurrentMetric_BackgroundMessageBrokerSchedulePoolSize</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>-</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>CurrentMetric_BackgroundMessageBrokerSchedulePoolTask</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>min_free_threads</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>FROM</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>system</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>metric_log</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>WHERE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>event_date</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>today</span><span style=color:#000;font-weight:700>()</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p><strong>If <code>free_threads</code> is close to zero or negative</strong>, it means your thread pool is saturated and should be increased.</p><hr><h2 id=step-2-estimate-required-pool-size>Step 2: Estimate Required Pool Size</h2><p>To estimate a reasonable value for <code>background_message_broker_schedule_pool_size</code>, run the following query:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>WITH</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>toUInt32OrDefault</span><span style=color:#000;font-weight:700>(</span><span style=color:#204a87;font-weight:700>extract</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>engine_full</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;kafka_num_consumers\s*=\s*(\d+)&#39;</span><span style=color:#000;font-weight:700>))</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>as</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>kafka_num_consumers</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>extract</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>engine_full</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;kafka_thread_per_consumer\s*=\s*(\d+|\&#39;</span><span style=color:#204a87;font-weight:700>true</span><span style=color:#a40000>\</span><span style=color:#4e9a06>&#39;)&#39;</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>not</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>in</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#39;&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;0&#39;</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>as</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>kafka_thread_per_consumer</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>multiIf</span><span style=color:#000;font-weight:700>(</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#000>engine</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;Kafka&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>  
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>            </span><span style=color:#204a87;font-weight:700>if</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>kafka_thread_per_consumer</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AND</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>kafka_num_consumers</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>&gt;</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>kafka_num_consumers</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>),</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#000>engine</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;RabbitMQ&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>            </span><span style=color:#0000cf;font-weight:700>3</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#000>engine</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;NATS&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>            </span><span style=color:#0000cf;font-weight:700>3</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#8f5902;font-style:italic>/* should not happen */</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>as</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>threads_needed</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>SELECT</span><span style=color:#f8f8f8;text-decoration:underline> 
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>ceil</span><span style=color:#000;font-weight:700>(</span><span style=color:#204a87;font-weight:700>sum</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>threads_needed</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>*</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#000;font-weight:700>.</span><span style=color:#0000cf;font-weight:700>25</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>FROM</span><span style=color:#f8f8f8;text-decoration:underline> 
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>system</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>tables</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>WHERE</span><span style=color:#f8f8f8;text-decoration:underline> 
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>engine</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>in</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>(</span><span style=color:#4e9a06>&#39;Kafka&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;RabbitMQ&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;NATS&#39;</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>This will return an estimate that includes a 25% buffer to accommodate spikes in load.</p><hr><h2 id=step-3-apply-the-new-setting>Step 3: Apply the New Setting</h2><ol><li><p><strong>Create or update</strong> the following configuration file:</p><p><strong>Path:</strong> <code>/etc/clickhouse-server/config.d/background_message_broker_schedule_pool_size.xml</code></p><p><strong>Content:</strong></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;yandex&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;background_message_broker_schedule_pool_size&gt;</span>120<span style=color:#204a87;font-weight:700>&lt;/background_message_broker_schedule_pool_size&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/yandex&gt;</span>
</span></span></code></pre></div><p>Replace <code>120</code> with the value recommended from Step 2 (rounded up if needed).</p></li><li><p><strong>(Only for ClickHouse versions 23.8 and older)</strong></p><p>Add the same setting to the default user profile:</p><p><strong>Path:</strong> <code>/etc/clickhouse-server/users.d/background_message_broker_schedule_pool_size.xml</code></p><p><strong>Content:</strong></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;yandex&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;profiles&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;default&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#204a87;font-weight:700>&lt;background_message_broker_schedule_pool_size&gt;</span>120<span style=color:#204a87;font-weight:700>&lt;/background_message_broker_schedule_pool_size&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;/default&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;/profiles&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/yandex&gt;</span>
</span></span></code></pre></div></li></ol><hr><h2 id=step-4-restart-clickhouse>Step 4: Restart ClickHouse</h2><p>After applying the configuration, restart ClickHouse to apply the changes:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo systemctl restart clickhouse-server
</span></span></code></pre></div><hr><h2 id=summary>Summary</h2><p>A saturated background message broker thread pool can lead to missed Kafka polls and consumer group dropouts. Monitoring your metrics and adjusting <code>background_message_broker_schedule_pool_size</code> accordingly ensures stable operation of Kafka, RabbitMQ, and NATS integrations.</p><p>If the problem persists even after increasing the pool size, consider investigating slow MV chains or flushing logic as a potential bottleneck.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-b11bb1875d00a2b0ff0e60950c5360ed>9.4 - Adjusting librdkafka settings</h1><div class=lead>Adjusting librdkafka settings</div><ul><li>To set rdkafka options - add to <code>&lt;kafka></code> section in <code>config.xml</code> or preferably use a separate file in <code>config.d/</code>:<ul><li><a href=https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md target=_blank>https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md</a></li></ul></li></ul><p>Some random example using SSL certificates to authenticate:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;yandex&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;kafka&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;max_poll_interval_ms&gt;</span>60000<span style=color:#204a87;font-weight:700>&lt;/max_poll_interval_ms&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;session_timeout_ms&gt;</span>60000<span style=color:#204a87;font-weight:700>&lt;/session_timeout_ms&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;heartbeat_interval_ms&gt;</span>10000<span style=color:#204a87;font-weight:700>&lt;/heartbeat_interval_ms&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;reconnect_backoff_ms&gt;</span>5000<span style=color:#204a87;font-weight:700>&lt;/reconnect_backoff_ms&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;reconnect_backoff_max_ms&gt;</span>60000<span style=color:#204a87;font-weight:700>&lt;/reconnect_backoff_max_ms&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;request_timeout_ms&gt;</span>20000<span style=color:#204a87;font-weight:700>&lt;/request_timeout_ms&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;retry_backoff_ms&gt;</span>500<span style=color:#204a87;font-weight:700>&lt;/retry_backoff_ms&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;message_max_bytes&gt;</span>20971520<span style=color:#204a87;font-weight:700>&lt;/message_max_bytes&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;debug&gt;</span>all<span style=color:#204a87;font-weight:700>&lt;/debug&gt;</span><span style=color:#8f5902;font-style:italic>&lt;!-- only to get the errors --&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;security_protocol&gt;</span>SSL<span style=color:#204a87;font-weight:700>&lt;/security_protocol&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;ssl_ca_location&gt;</span>/etc/clickhouse-server/ssl/kafka-ca-qa.crt<span style=color:#204a87;font-weight:700>&lt;/ssl_ca_location&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;ssl_certificate_location&gt;</span>/etc/clickhouse-server/ssl/client_clickhouse_client.pem<span style=color:#204a87;font-weight:700>&lt;/ssl_certificate_location&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;ssl_key_location&gt;</span>/etc/clickhouse-server/ssl/client_clickhouse_client.key<span style=color:#204a87;font-weight:700>&lt;/ssl_key_location&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;ssl_key_password&gt;</span>pass<span style=color:#204a87;font-weight:700>&lt;/ssl_key_password&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;/kafka&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/yandex&gt;</span>
</span></span></code></pre></div><h2 id=authentication--connectivity>Authentication / connectivity</h2><p>Sometimes the consumer group needs to be explicitly allowed in the broker UI config.</p><h3 id=amazon-msk--saslscram>Amazon MSK | SASL/SCRAM</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;yandex&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;kafka&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;security_protocol&gt;</span>sasl_ssl<span style=color:#204a87;font-weight:700>&lt;/security_protocol&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#8f5902;font-style:italic>&lt;!-- Depending on your broker config you may need to uncomment below sasl_mechanism --&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#8f5902;font-style:italic>&lt;!-- &lt;sasl_mechanism&gt;SCRAM-SHA-512&lt;/sasl_mechanism&gt; --&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;sasl_username&gt;</span>root<span style=color:#204a87;font-weight:700>&lt;/sasl_username&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;sasl_password&gt;</span>toor<span style=color:#204a87;font-weight:700>&lt;/sasl_password&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;/kafka&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/yandex&gt;</span>
</span></span></code></pre></div><ul><li><a href=https://docs.aws.amazon.com/msk/latest/developerguide/port-info.html target=_blank>Broker ports detail</a></li><li><a href=https://leftjoin.ru/blog/data-engineering/clickhouse-as-a-consumer-to-amazon-msk/ target=_blank>Read here more</a>
(Russian language)</li></ul><h3 id=on-prem--self-hosted-kafka-broker>on-prem / self-hosted Kafka broker</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;yandex&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;kafka&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;security_protocol&gt;</span>sasl_ssl<span style=color:#204a87;font-weight:700>&lt;/security_protocol&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;sasl_mechanism&gt;</span>SCRAM-SHA-512<span style=color:#204a87;font-weight:700>&lt;/sasl_mechanism&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;sasl_username&gt;</span>root<span style=color:#204a87;font-weight:700>&lt;/sasl_username&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;sasl_password&gt;</span>toor<span style=color:#204a87;font-weight:700>&lt;/sasl_password&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#8f5902;font-style:italic>&lt;!-- fullchain cert here --&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;ssl_ca_location&gt;</span>/path/to/cert/fullchain.pem<span style=color:#204a87;font-weight:700>&lt;/ssl_ca_location&gt;</span>   
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;/kafka&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/yandex&gt;</span>
</span></span></code></pre></div><h3 id=inline-kafka-certs>Inline Kafka certs</h3><p>To connect to some Kafka cloud services you may need to use certificates.</p><p>If needed they can be converted to pem format and inlined into ClickHouse® config.xml
Example:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;kafka&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;ssl_key_pem&gt;</span><span style=color:#8f5902;font-style:italic>&lt;![CDATA[
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>  RSA Private-Key: (3072 bit, 2 primes)
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>    ....
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>-----BEGIN RSA PRIVATE KEY-----
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>...
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>-----END RSA PRIVATE KEY-----
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>]]&gt;</span><span style=color:#204a87;font-weight:700>&lt;/ssl_key_pem&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;ssl_certificate_pem&gt;</span><span style=color:#8f5902;font-style:italic>&lt;![CDATA[
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>-----BEGIN CERTIFICATE-----
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>...
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>-----END CERTIFICATE-----
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic>]]&gt;</span><span style=color:#204a87;font-weight:700>&lt;/ssl_certificate_pem&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/kafka&gt;</span>
</span></span></code></pre></div><p>See</p><ul><li><p><a href=https://help.aiven.io/en/articles/489572-getting-started-with-aiven-kafka target=_blank>https://help.aiven.io/en/articles/489572-getting-started-with-aiven-kafka</a></p></li><li><p><a href=https://stackoverflow.com/questions/991758/how-to-get-pem-file-from-key-and-crt-files target=_blank>https://stackoverflow.com/questions/991758/how-to-get-pem-file-from-key-and-crt-files</a></p></li></ul><h3 id=azure-event-hub>Azure Event Hub</h3><p>See <a href=https://github.com/ClickHouse/ClickHouse/issues/12609 target=_blank>https://github.com/ClickHouse/ClickHouse/issues/12609</a></p><h3 id=kerberos>Kerberos</h3><ul><li><a href=https://clickhouse.tech/docs/en/engines/table-engines/integrations/kafka/#kafka-kerberos-support target=_blank rel=nofollow>https://clickhouse.tech/docs/en/engines/table-engines/integrations/kafka/#kafka-kerberos-support</a></li><li><a href=https://github.com/ClickHouse/ClickHouse/blob/master/tests/integration/test_storage_kerberized_kafka/configs/kafka.xml target=_blank>https://github.com/ClickHouse/ClickHouse/blob/master/tests/integration/test_storage_kerberized_kafka/configs/kafka.xml</a></li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span>  <span style=color:#8f5902;font-style:italic>&lt;!-- Kerberos-aware Kafka --&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;kafka&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;security_protocol&gt;</span>SASL_PLAINTEXT<span style=color:#204a87;font-weight:700>&lt;/security_protocol&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;sasl_kerberos_keytab&gt;</span>/home/kafkauser/kafkauser.keytab<span style=color:#204a87;font-weight:700>&lt;/sasl_kerberos_keytab&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;sasl_kerberos_principal&gt;</span>kafkauser/kafkahost@EXAMPLE.COM<span style=color:#204a87;font-weight:700>&lt;/sasl_kerberos_principal&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;/kafka&gt;</span>
</span></span></code></pre></div><h3 id=confluent-cloud--google-cloud>Confluent Cloud / Google Cloud</h3><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;yandex&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;kafka&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;auto_offset_reset&gt;</span>smallest<span style=color:#204a87;font-weight:700>&lt;/auto_offset_reset&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;security_protocol&gt;</span>SASL_SSL<span style=color:#204a87;font-weight:700>&lt;/security_protocol&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#8f5902;font-style:italic>&lt;!-- older broker versions may need this below, for newer versions ignore --&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#8f5902;font-style:italic>&lt;!-- &lt;ssl_endpoint_identification_algorithm&gt;https&lt;/ssl_endpoint_identification_algorithm&gt; --&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;sasl_mechanism&gt;</span>PLAIN<span style=color:#204a87;font-weight:700>&lt;/sasl_mechanism&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;sasl_username&gt;</span>username<span style=color:#204a87;font-weight:700>&lt;/sasl_username&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;sasl_password&gt;</span>password<span style=color:#204a87;font-weight:700>&lt;/sasl_password&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#8f5902;font-style:italic>&lt;!-- Same as above here ignore if newer broker version --&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#8f5902;font-style:italic>&lt;!-- &lt;ssl_ca_location&gt;probe&lt;/ssl_ca_location&gt; --&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;/kafka&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/yandex&gt;</span>
</span></span></code></pre></div><ul><li><a href=https://docs.confluent.io/cloud/current/client-apps/config-client.html target=_blank>https://docs.confluent.io/cloud/current/client-apps/config-client.html</a></li><li><a href=https://cloud.google.com/managed-service-for-apache-kafka/docs/authentication-kafka target=_blank>https://cloud.google.com/managed-service-for-apache-kafka/docs/authentication-kafka</a></li></ul><h2 id=how-to-test-connection-settings>How to test connection settings</h2><p>Use kafkacat utility - it internally uses same library to access Kafla as ClickHouse itself and allows easily to test different settings.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kafkacat -b my_broker:9092 -C -o -10 -t my_topic <span style=color:#4e9a06>\ </span><span style=color:#ce5c00;font-weight:700>(</span>Google cloud and on-prem use <span style=color:#0000cf;font-weight:700>9092</span> port<span style=color:#ce5c00;font-weight:700>)</span>
</span></span><span style=display:flex><span>   -X security.protocol<span style=color:#ce5c00;font-weight:700>=</span>SASL_SSL  <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>   -X sasl.mechanisms<span style=color:#ce5c00;font-weight:700>=</span>PLAIN <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>   -X sasl.username<span style=color:#ce5c00;font-weight:700>=</span>uerName <span style=color:#4e9a06>\
</span></span></span><span style=display:flex><span><span style=color:#4e9a06></span>   -X sasl.password<span style=color:#ce5c00;font-weight:700>=</span>Password
</span></span></code></pre></div><h2 id=different-configurations-for-different-tables>Different configurations for different tables?</h2><blockquote><p>Is there some more documentation how to use this multiconfiguration for Kafka ?</p></blockquote><p>The whole logic is here:
<a href=https://github.com/ClickHouse/ClickHouse/blob/da4856a2be035260708fe2ba3ffb9e437d9b7fef/src/Storages/Kafka/StorageKafka.cpp#L466-L475 target=_blank>https://github.com/ClickHouse/ClickHouse/blob/da4856a2be035260708fe2ba3ffb9e437d9b7fef/src/Storages/Kafka/StorageKafka.cpp#L466-L475</a></p><p>So it load the main config first, after that it load (with overwrites) the configs for all topics, <strong>listed in <code>kafka_topic_list</code> of the table</strong>.</p><p>Also since v21.12 it&rsquo;s possible to use more straightforward way using named_collections:
<a href=https://github.com/ClickHouse/ClickHouse/pull/31691 target=_blank>https://github.com/ClickHouse/ClickHouse/pull/31691</a></p><p>So you can say something like</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TABLE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>test</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>kafka</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>(</span><span style=color:#204a87;font-weight:700>key</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>UInt64</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>value</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>UInt64</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>ENGINE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Kafka</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>kafka1</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>kafka_format</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;CSV&#39;</span><span style=color:#000;font-weight:700>);</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>And after that in configuration:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;clickhouse&gt;</span>
</span></span><span style=display:flex><span> <span style=color:#204a87;font-weight:700>&lt;named_collections&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;kafka1&gt;</span>
</span></span><span style=display:flex><span>   <span style=color:#204a87;font-weight:700>&lt;kafka_broker_list&gt;</span>kafka1:19092<span style=color:#204a87;font-weight:700>&lt;/kafka_broker_list&gt;</span>
</span></span><span style=display:flex><span>   <span style=color:#204a87;font-weight:700>&lt;kafka_topic_list&gt;</span>conf<span style=color:#204a87;font-weight:700>&lt;/kafka_topic_list&gt;</span>
</span></span><span style=display:flex><span>   <span style=color:#204a87;font-weight:700>&lt;kafka_group_name&gt;</span>conf<span style=color:#204a87;font-weight:700>&lt;/kafka_group_name&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>&lt;/kafka1&gt;</span>
</span></span><span style=display:flex><span> <span style=color:#204a87;font-weight:700>&lt;/named_collections&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/clickhouse&gt;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;clickhouse&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;named_collections&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;kafka_preset1&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#204a87;font-weight:700>&lt;kafka_broker_list&gt;</span>...<span style=color:#204a87;font-weight:700>&lt;/kafka_broker_list&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#204a87;font-weight:700>&lt;kafka_topic_list&gt;</span>foo.bar<span style=color:#204a87;font-weight:700>&lt;/kafka_topic_list&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#204a87;font-weight:700>&lt;kafka_group_name&gt;</span>foo.bar.group<span style=color:#204a87;font-weight:700>&lt;/kafka_group_name&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#204a87;font-weight:700>&lt;kafka&gt;</span>
</span></span><span style=display:flex><span>                <span style=color:#204a87;font-weight:700>&lt;security_protocol&gt;</span>...<span style=color:#204a87;font-weight:700>&lt;/security_protocol&gt;</span>
</span></span><span style=display:flex><span>                <span style=color:#204a87;font-weight:700>&lt;sasl_mechanism&gt;</span>...<span style=color:#204a87;font-weight:700>&lt;/sasl_mechanism&gt;</span>
</span></span><span style=display:flex><span>                <span style=color:#204a87;font-weight:700>&lt;sasl_username&gt;</span>...<span style=color:#204a87;font-weight:700>&lt;/sasl_username&gt;</span>
</span></span><span style=display:flex><span>                <span style=color:#204a87;font-weight:700>&lt;sasl_password&gt;</span>...<span style=color:#204a87;font-weight:700>&lt;/sasl_password&gt;</span>
</span></span><span style=display:flex><span>                <span style=color:#204a87;font-weight:700>&lt;auto_offset_reset&gt;</span>smallest<span style=color:#204a87;font-weight:700>&lt;/auto_offset_reset&gt;</span>
</span></span><span style=display:flex><span>                <span style=color:#204a87;font-weight:700>&lt;ssl_endpoint_identification_algorithm&gt;</span>https<span style=color:#204a87;font-weight:700>&lt;/ssl_endpoint_identification_algorithm&gt;</span>
</span></span><span style=display:flex><span>                <span style=color:#204a87;font-weight:700>&lt;ssl_ca_location&gt;</span>probe<span style=color:#204a87;font-weight:700>&lt;/ssl_ca_location&gt;</span>
</span></span><span style=display:flex><span>            <span style=color:#204a87;font-weight:700>&lt;/kafka&gt;</span>
</span></span><span style=display:flex><span>        <span style=color:#204a87;font-weight:700>&lt;/kafka_preset1&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#204a87;font-weight:700>&lt;/named_collections&gt;</span>
</span></span><span style=display:flex><span><span style=color:#204a87;font-weight:700>&lt;/clickhouse&gt;</span>
</span></span></code></pre></div><p>We can also use named collections with SQL and include kafka subsettings like this:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>NAMED</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>COLLECTION</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>kafka_preset</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka_broker_list</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;xxxx&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka_format</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;JSONEachRow&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka_group_name</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;xxxxx&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka_handle_error_mode</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;stream&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka_topic_list</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;xxxxx&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>security_protocol</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;SASL_SSL&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>sasl_mechanism</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;PLAIN&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>sasl_username</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;xxxx&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>ssl_ca_location</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;/path/to/cert&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>ssl_certificate_location</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;ssl_certificate_location&#39;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>kafka</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>ssl_key_location</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;/path-key_location&#39;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>The same fragment of code in newer versions:</p><ul><li><a href=https://github.com/ClickHouse/ClickHouse/blob/d19e24f530c30f002488bc136da78f5fb55aedab/src/Storages/Kafka/StorageKafka.cpp#L474-L496 target=_blank>https://github.com/ClickHouse/ClickHouse/blob/d19e24f530c30f002488bc136da78f5fb55aedab/src/Storages/Kafka/StorageKafka.cpp#L474-L496</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-d58f1474300f709dea11df04812ed578>9.5 - Error handling</h1><div class=lead>Error handling</div><h2 id=pre-216>Pre 21.6</h2><p>There are couple options:</p><p>Certain formats which has schema in built in them (like JSONEachRow) could silently skip any unexpected fields after enabling setting <code>input_format_skip_unknown_fields</code></p><p>It&rsquo;s also possible to skip up to N malformed messages for each block, with used setting <code>kafka_skip_broken_messages</code> but it&rsquo;s also does not support all possible formats.</p><h2 id=after-216>After 21.6</h2><p>It&rsquo;s possible to stream messages which could not be parsed, this behavior could be enabled via setting: <code>kafka_handle_error_mode='stream'</code> and ClickHouse® wil write error and message from Kafka itself to two new virtual columns: <code>_error, _raw_message</code>.</p><p>So you can create another Materialized View which would collect to a separate table all errors happening while parsing with all important information like offset and content of message.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TABLE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>default</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>kafka_engine</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>(</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>i</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Int64</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>s</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>ENGINE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Kafka</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>SETTINGS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>kafka_broker_list</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;kafka:9092&#39;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>kafka_topic_list</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;topic&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>kafka_group_name</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;clickhouse&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>kafka_format</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;JSONEachRow&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>kafka_handle_error_mode</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;stream&#39;</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TABLE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>default</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>kafka_errors</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>(</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>topic</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>partition</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Int64</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#204a87;font-weight:700>offset</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Int64</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>raw</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>error</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>ENGINE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>MergeTree</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>ORDER</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>BY</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>(</span><span style=color:#000>topic</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>partition</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>offset</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>SETTINGS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>index_granularity</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>8192</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>MATERIALIZED</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>VIEW</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>default</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>kafka_errors_mv</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TO</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>default</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>kafka_errors</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>SELECT</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>_topic</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>topic</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>_partition</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>partition</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>_offset</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>offset</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>_raw_message</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>raw</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>_error</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>error</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>FROM</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>default</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>kafka_engine</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>WHERE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>length</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>_error</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>&gt;</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><h2 id=since-258>Since 25.8</h2><p>dead letter queue can be used via setting: <code>kafka_handle_error_mode='dead_letter'</code> <a href=https://github.com/ClickHouse/ClickHouse/pull/68873 target=_blank>https://github.com/ClickHouse/ClickHouse/pull/68873</a></p><p><img alt="Table connections" src=/assets/Untitled-2021-08-05-1027.png></p><p><a href=https://github.com/ClickHouse/ClickHouse/pull/20249 target=_blank>https://github.com/ClickHouse/ClickHouse/pull/20249</a></p><p><a href=https://github.com/ClickHouse/ClickHouse/pull/21850 target=_blank>https://github.com/ClickHouse/ClickHouse/pull/21850</a></p><p><a href=https://altinity.com/blog/clickhouse-kafka-engine-faq target=_blank>https://altinity.com/blog/clickhouse-kafka-engine-faq</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-d8f2388a49c064f3f21643937cbfcedc>9.6 - Exactly once semantics</h1><div class=lead>Exactly once semantics</div><p>EOS consumer (isolation.level=read_committed) is enabled by default since librdkafka 1.2.0, so for ClickHouse® - since 20.2</p><p>See:</p><ul><li><a href=https://github.com/edenhill/librdkafka/commit/6b2a1552ac2a4ea09d915015183f268dd2df96e6 target=_blank>edenhill/librdkafka@6b2a155</a></li><li><a href=https://github.com/ClickHouse/ClickHouse/commit/9de5dffb5c97eb93545ae25eaf87ec195a590148 target=_blank>9de5dff</a></li></ul><p>BUT: while EOS semantics will guarantee you that no duplicates will happen on the Kafka side (i.e. even if you produce the same messages few times it will be consumed once), but ClickHouse as a Kafka client can currently guarantee only at-least-once. And in some corner cases (connection lost etc) you can get duplicates.</p><p>We need to have something like transactions on ClickHouse side to be able to avoid that. Adding something like simple transactions is in plans for Y2022.</p><h2 id=block-aggregator-by-ebay>block-aggregator by eBay</h2><p>Block Aggregator is a data loader that subscribes to Kafka topics, aggregates the Kafka messages into blocks that follow the ClickHouse’s table schemas, and then inserts the blocks into ClickHouse. Block Aggregator provides exactly-once delivery guarantee to load data from Kafka to ClickHouse. Block Aggregator utilizes Kafka’s metadata to keep track of blocks that are intended to send to ClickHouse, and later uses this metadata information to deterministically re-produce ClickHouse blocks for re-tries in case of failures. The identical blocks are guaranteed to be deduplicated by ClickHouse.</p><p><a href=https://github.com/eBay/block-aggregator target=_blank>eBay/block-aggregator</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-7b4e8063954e9a7aaa7e048590c82f0d>9.7 - Kafka main parsing loop</h1><div class=lead>Kafka main parsing loop</div><p>One of the threads from scheduled_pool (pre ClickHouse® 20.9) / <code>background_message_broker_schedule_pool</code> (after 20.9) do that in infinite loop:</p><ol><li>Batch poll (time limit: <code>kafka_poll_timeout_ms</code> 500ms, messages limit: <code>kafka_poll_max_batch_size</code> 65536)</li><li>Parse messages.</li><li>If we don&rsquo;t have enough data (rows limit: <code>kafka_max_block_size</code> 1048576) or time limit reached (<code>kafka_flush_interval_ms</code> 7500ms) - continue polling (goto p.1)</li><li>Write a collected block of data to MV</li><li>Do commit (commit after write = at-least-once).</li></ol><p>On any error, during that process, Kafka client is restarted (leading to rebalancing - leave the group and get back in few seconds).</p><p><img alt="Kafka batching" src=/assets/128942286.png></p><h2 id=important-settings>Important settings</h2><p>These usually should not be adjusted:</p><ul><li><code>kafka_poll_max_batch_size</code> = max_block_size (65536)</li><li><code>kafka_poll_timeout_ms</code> = stream_poll_timeout_ms (500ms)</li></ul><p>You may want to adjust those depending on your scenario:</p><ul><li><code>kafka_flush_interval_ms</code> = stream_poll_timeout_ms (7500ms)</li><li><code>kafka_max_block_size</code> = max_insert_block_size / kafka_num_consumers (for the single consumer: 1048576)</li></ul><h2 id=see-also>See also</h2><p><a href=https://github.com/ClickHouse/ClickHouse/pull/11388 target=_blank>https://github.com/ClickHouse/ClickHouse/pull/11388</a></p><h2 id=disable-at-least-once-delivery>Disable at-least-once delivery</h2><p><code>kafka_commit_every_batch</code> = 1 will change the loop logic mentioned above. Consumed batch committed to the Kafka and the block of rows send to Materialized Views only after that. It could be resembled as at-most-once delivery mode as prevent duplicate creation but allow loss of data in case of failures.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-8de9ef71664f1495dde935e5d9c292a4>9.8 - Kafka parallel consuming</h1><div class=lead>Kafka parallel consuming</div><p>For very large topics when you need more parallelism (especially on the insert side) you may use several tables with the same pipeline (pre ClickHouse® 20.9) or enable <code>kafka_thread_per_consumer</code> (after 20.9).</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-ini data-lang=ini><span style=display:flex><span><span style=color:#c4a000>kafka_num_consumers</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#4e9a06>N,</span>
</span></span><span style=display:flex><span><span style=color:#c4a000>kafka_thread_per_consumer</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>1</span>
</span></span></code></pre></div><p>Notes:</p><ul><li>the inserts will happen in parallel (without that setting inserts happen linearly)</li><li>enough partitions are needed.</li><li><code>kafka_num_consumers</code> is limited by number of physical cores (half of vCPUs). <code>kafka_disable_num_consumers_limit</code> can be used to override the limit.</li><li><code>background_message_broker_schedule_pool_size</code> is 16 by default, you may need to increase if using more than 16 consumers</li></ul><p>Before increasing <code>kafka_num_consumers</code> with keeping <code>kafka_thread_per_consumer=0</code> may improve consumption & parsing speed, but flushing & committing still happens by a single thread there (so inserts are linear).</p></div><div class=td-content style=page-break-before:always><h1 id=pg-73c78c87d15e6e8b2e49b347c708ad83>9.9 - Multiple MVs attached to Kafka table</h1><div class=lead>How Multiple MVs attached to Kafka table consume and how they are affected by kafka_num_consumers/kafka_thread_per_consumer</div><p>Kafka Consumer is a thread inside the Kafka Engine table that is visible by Kafka monitoring tools like kafka-consumer-groups and in Clickhouse in system.kafka_consumers table.</p><p>Having multiple consumers increases ingesting parallelism and can significantly speed up event processing. However, it comes with a trade-off: it&rsquo;s a CPU-intensive task, especially under high event load and/or complicated parsing of incoming data. Therefore, it&rsquo;s crucial to create as many consumers as you really need and ensure you have enough CPU cores to handle them. We don’t recommend creating too many Kafka Engines per server because it could lead to uncontrolled CPU usage in situations like bulk data upload or catching up a huge kafka lag due to excessive parallelism of the ingesting process.</p><h2 id=kafka_thread_per_consumer-meaning>kafka_thread_per_consumer meaning</h2><p>Consider a basic pipeline depicted as a Kafka table with 2 MVs attached. The Kafka broker has 2 topics and 4 partitions.</p><h3 id=kafka_thread_per_consumer--0>kafka_thread_per_consumer = 0</h3><p>Kafka engine table will act as 2 consumers, but only 1 insert thread for both of them. It is important to note that the topic needs to have as many partitions as consumers. For this scenario, we use these settings:</p><pre tabindex=0><code>kafka_num_consumers = 2
kafka_thread_per_consumer = 0
</code></pre><p>The same Kafka engine will create 2 streams, 1 for each consumer, and will join them in a union stream. And it will use 1 thread for inserting <code>[ 2385 ]</code>
This is how we can see it in the logs:</p><pre tabindex=0><code class=language-log data-lang=log>2022.11.09 17:49:34.282077 [ 2385 ] {} &lt;Debug&gt; StorageKafka (kafka_table): Started streaming to 2 attached views
</code></pre><ul><li><p>How ClickHouse® calculates the number of threads depending on the <code>thread_per_consumer</code> setting:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span>  <span style=color:#204a87;font-weight:700>auto</span> <span style=color:#000>stream_count</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>thread_per_consumer</span> <span style=color:#ce5c00;font-weight:700>?</span> <span style=color:#0000cf;font-weight:700>1</span> <span style=color:#ce5c00;font-weight:700>:</span> <span style=color:#000>num_created_consumers</span><span style=color:#000;font-weight:700>;</span>
</span></span><span style=display:flex><span>      <span style=color:#000>sources</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>reserve</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>stream_count</span><span style=color:#000;font-weight:700>);</span>
</span></span><span style=display:flex><span>      <span style=color:#000>pipes</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>reserve</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>stream_count</span><span style=color:#000;font-weight:700>);</span>
</span></span><span style=display:flex><span>      <span style=color:#204a87;font-weight:700>for</span> <span style=color:#000;font-weight:700>(</span><span style=color:#000>size_t</span> <span style=color:#000>i</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#0000cf;font-weight:700>0</span><span style=color:#000;font-weight:700>;</span> <span style=color:#000>i</span> <span style=color:#ce5c00;font-weight:700>&lt;</span> <span style=color:#000>stream_count</span><span style=color:#000;font-weight:700>;</span> <span style=color:#ce5c00;font-weight:700>++</span><span style=color:#000>i</span><span style=color:#000;font-weight:700>)</span>
</span></span><span style=display:flex><span>      <span style=color:#000;font-weight:700>{</span>
</span></span><span style=display:flex><span>         <span style=color:#000;font-weight:700>......</span>
</span></span><span style=display:flex><span>      <span style=color:#000;font-weight:700>}</span>
</span></span></code></pre></div></li></ul><p>Details:</p><p><a href=https://github.com/ClickHouse/ClickHouse/blob/1b49463bd297ade7472abffbc931c4bb9bf213d0/src/Storages/Kafka/StorageKafka.cpp#L834 target=_blank>https://github.com/ClickHouse/ClickHouse/blob/1b49463bd297ade7472abffbc931c4bb9bf213d0/src/Storages/Kafka/StorageKafka.cpp#L834</a></p><p>Also, a detailed graph of the pipeline:</p><p><img alt=thread_per_consumer0 src=/assets/thread_per_consumer0.png></p><p>With this approach, even if the number of consumers increased, the Kafka engine will still use only 1 thread to flush. The consuming/processing rate will probably increase a bit, but not linearly. For example, 5 consumers will not consume 5 times faster. Also, a good property of this approach is the <code>linearization</code> of INSERTS, which means that the order of the inserts is preserved and sequential. This option is good for small/medium Kafka topics.</p><h3 id=kafka_thread_per_consumer--1>kafka_thread_per_consumer = 1</h3><p>Kafka engine table will act as 2 consumers and 1 thread per consumer. For this scenario, we use these settings:</p><pre tabindex=0><code>kafka_num_consumers = 2
kafka_thread_per_consumer = 1
</code></pre><p>Here, the pipeline works like this:</p><p><img alt=thread_per_consumer1 src=/assets/thread_per_consumer1.png></p><p>With this approach, the number of consumers remains the same, but each consumer will use their own insert/flush thread, and the consuming/processing rate should increase.</p><h2 id=background-pool>Background Pool</h2><p>In Clickhouse there is a special thread pool for background processes, such as streaming engines. Its size is controlled by the background_message_broker_schedule_pool_size setting and is 16 by default. If you exceed this limit across all tables on the server, you’ll likely encounter continuous Kafka rebalances, which will slow down processing considerably. For a server with a lot of CPU cores, you can increase that limit to a higher value, like 20 or even 40. <code>background_message_broker_schedule_pool_size</code> = 20 allows you to create 5 Kafka Engine tables with 4 consumers each of them has its own insert thread. This option is good for large Kafka topics with millions of messages per second.</p><h2 id=multiple-materialized-views>Multiple Materialized Views</h2><p>Attaching multiple Materialized Views (MVs) to a Kafka Engine table can be used when you need to apply different transformations to the same topic and store the resulting data in different tables.</p><p>(This approach also applies to the other streaming engines - RabbitMQ, s3queue, etc).</p><p>All streaming engines begin processing data (reading from the source and producing insert blocks) only after at least one Materialized View is attached to the engine. Multiple Materialized Views can be connected to distribute data across various tables with different transformations. But how does it work when the server starts?</p><p>Once the first Materialized View (MV) is loaded, started, and attached to the Kafka/s3queue table, data consumption begins immediately—data is read from the source, pushed to the destination, and the pointers advance to the next position. However, any other MVs that haven&rsquo;t started yet will miss the data consumed by the first MV, leading to some data loss.</p><p>This issue worsens with asynchronous table loading. Tables are only loaded upon first access, and the loading process takes time. When multiple MVs direct the data stream to different tables, some tables might be ready sooner than others. As soon as the first table becomes ready, data consumption starts, and any tables still loading will miss the data consumed during that interval, resulting in further data loss for those tables.</p><p>That means when you make a design with Multiple MVs <code>async_load_databases</code> should be switched off:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#ce5c00;font-weight:700>&lt;</span><span style=color:#000>async_load_databases</span><span style=color:#ce5c00;font-weight:700>&gt;</span><span style=color:#204a87;font-weight:700>false</span><span style=color:#ce5c00;font-weight:700>&lt;/</span><span style=color:#000>async_load_databases</span><span style=color:#ce5c00;font-weight:700>&gt;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>Also, you have to prevent starting to consume until all MVs are loaded and started. For that, you can add an additional Null table to the MV pipeline, so the Kafka table will pass the block to a single Null table first, and only then many MVs start their own transformations to many dest tables:</p><p>KafkaTable → dummy_MV -> NullTable -> [MV1, MV2, ….] → [Table1, Table2, …]</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>create</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>table</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>NullTable</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>Engine</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#204a87;font-weight:700>Null</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>as</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>KafkaTable</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>create</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>materialized</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>view</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>dummy_MV</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>to</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>NullTable</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>select</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>*</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>from</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>KafkaTable</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#8f5902;font-style:italic>--WHERE NOT ignore(throwIf(if((uptime() &lt; 120), 1 , 0)))
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic></span><span style=color:#204a87;font-weight:700>WHERE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NOT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>ignore</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>throwIf</span><span style=color:#000;font-weight:700>(</span><span style=color:#204a87;font-weight:700>if</span><span style=color:#000;font-weight:700>((</span><span style=color:#000>uptime</span><span style=color:#000;font-weight:700>()</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>&lt;</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>120</span><span style=color:#000;font-weight:700>),</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>+</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>sleep</span><span style=color:#000;font-weight:700>(</span><span style=color:#0000cf;font-weight:700>3</span><span style=color:#000;font-weight:700>),</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#000;font-weight:700>)))</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>120 seconds should be enough for loading all MVs.</p><p>Using an intermediate Null table is also preferable because it&rsquo;s easier to make any changes with MVs:</p><ul><li>drop the dummy_MV to stop consuming</li><li>make any changes to transforming MVs by drop/recreate</li><li>create dummy_MV again to resume consuming</li></ul><p>The fix for correctly starting multiple MVs will be available from 25.5 version - <a href=https://github.com/ClickHouse/ClickHouse/pull/72123 target=_blank>https://github.com/ClickHouse/ClickHouse/pull/72123</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-70048b9cd8c627a770ed4410dcd3a6d4>9.10 - Rewind / fast-forward / replay</h1><div class=lead>Rewind / fast-forward / replay</div><ul><li>Step 1: Detach Kafka tables in ClickHouse®<pre tabindex=0><code>DETACH TABLE db.kafka_table_name ON CLUSTER &#39;{cluster}&#39;;
</code></pre></li><li>Step 2: <code>kafka-consumer-groups.sh --bootstrap-server kafka:9092 --topic topic:0,1,2 --group id1 --reset-offsets --to-latest --execute</code><ul><li>More samples: <a href=https://gist.github.com/filimonov/1646259d18b911d7a1e8745d6411c0cc target=_blank>https://gist.github.com/filimonov/1646259d18b911d7a1e8745d6411c0cc</a></li></ul></li><li>Step 3: Attach Kafka tables back<pre tabindex=0><code>ATTACH TABLE db.kafka_table_name ON CLUSTER &#39;{cluster}&#39;;
</code></pre></li></ul><p>See also these configuration settings:</p><pre tabindex=0><code class=language-markup data-lang=markup>&lt;kafka&gt;
  &lt;auto_offset_reset&gt;smallest&lt;/auto_offset_reset&gt;
&lt;/kafka&gt;
</code></pre><h3 id=about-offset-consuming>About Offset Consuming</h3><p>When a consumer joins the consumer group, the broker will check if it has a committed offset. If that is the case, then it will start from the latest offset. Both ClickHouse and librdKafka documentation state that the default value for <code>auto_offset_reset</code> is largest (or <code>latest</code> in new Kafka versions) but it is not, if the consumer is new:</p><p><a href=https://github.com/ClickHouse/ClickHouse/blob/f171ad93bcb903e636c9f38812b6aaf0ab045b04/src/Storages/Kafka/StorageKafka.cpp#L506 target=_blank>https://github.com/ClickHouse/ClickHouse/blob/f171ad93bcb903e636c9f38812b6aaf0ab045b04/src/Storages/Kafka/StorageKafka.cpp#L506</a></p><p> <code>conf.set("auto.offset.reset", "earliest");     // If no offset stored for this group, read all messages from the start</code></p><p>If there is no offset stored or it is out of range, for that particular consumer group, the consumer will start consuming from the beginning (<code>earliest</code>), and if there is some offset stored then it should use the <code>latest</code>.
The log retention policy influences which offset values correspond to the <code>earliest</code> and <code>latest</code> configurations. Consider a scenario where a topic has a retention policy set to 1 hour. Initially, you produce 5 messages, and then, after an hour, you publish 5 more messages. In this case, the latest offset will remain unchanged from the previous example. However, due to Kafka removing the earlier messages, the earliest available offset will not be 0; instead, it will be 5.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-8441aefeee7f594b90b90afa09a25289>9.11 - SELECTs from engine=Kafka</h1><div class=lead>SELECTs from engine=Kafka</div><h2 id=question>Question</h2><p>What will happen, if we would run SELECT query from working Kafka table with MV attached? Would data showed in SELECT query appear later in MV destination table?</p><h2 id=answer>Answer</h2><ol><li>Most likely SELECT query would show nothing.</li><li>If you lucky enough and something would show up, those rows <strong>wouldn&rsquo;t appear</strong> in MV destination table.</li></ol><p>So it&rsquo;s not recommended to run SELECT queries on working Kafka tables.</p><p>In case of debug it&rsquo;s possible to use another Kafka table with different <code>consumer_group</code>, so it wouldn&rsquo;t affect your main pipeline.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-633ba7dbb22cf28081101da0fcc2c511>10 - RabbitMQ</h1><div class=lead>RabbitMQ engine in ClickHouse® 24.3+</div><h3 id=settings>Settings</h3><p>Basic RabbitMQ settings and use cases: <a href=https://clickhouse.com/docs/en/engines/table-engines/integrations/rabbitmq target=_blank rel=nofollow>https://clickhouse.com/docs/en/engines/table-engines/integrations/rabbitmq</a></p><h3 id=latest-improvementsfixes>Latest improvements/fixes</h3><h5 id=v2310>(v23.10+)</h5><ul><li><strong>Allow to save unparsed records and errors in RabbitMQ</strong>:
NATS and FileLog engines. Add virtual columns <code>_error</code> and <code>_raw_message</code> (for NATS and RabbitMQ), <code>_raw_record</code> (for FileLog) that are filled when ClickHouse fails to parse new record.
The behaviour is controlled under storage settings <code>nats_handle_error_mode</code> for NATS, <code>rabbitmq_handle_error_mode</code> for RabbitMQ, <code>handle_error_mode</code> for FileLog similar to <code>kafka_handle_error_mode</code>.
If it&rsquo;s set to <code>default</code>, en exception will be thrown when ClickHouse fails to parse a record, if it&rsquo;s set to <code>stream</code>, error and raw record will be saved into virtual columns.
Closes <a href=https://github.com/ClickHouse/ClickHouse/issues/36035 target=_blank>#36035</a>
and <a href=https://github.com/ClickHouse/ClickHouse/pull/55477 target=_blank>#55477</a></li></ul><h5 id=v24>(v24+)</h5><ul><li><a href=https://github.com/ClickHouse/ClickHouse/issues/45350 target=_blank>#45350 RabbitMq Storage Engine should NACK messages if exception is thrown during processing</a></li><li><a href=https://github.com/ClickHouse/ClickHouse/pull/59775 target=_blank>#59775 rabbitmq: fix having neither acked nor nacked messages</a></li><li><a href=https://github.com/ClickHouse/ClickHouse/pull/60312 target=_blank>#60312 Make rabbitmq nack broken messages</a></li><li><a href=https://github.com/ClickHouse/ClickHouse/pull/61320 target=_blank>#61320 Fix logical error in RabbitMQ storage with MATERIALIZED columns</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-98ba8cfef289db7021da328f13e65d9e>10.1 - RabbitMQ Error handling</h1><div class=lead>Error handling for RabbitMQ table engine</div><p>Same approach as in Kafka but virtual columns are different. Check <a href=https://clickhouse.com/docs/en/engines/table-engines/integrations/rabbitmq#virtual-columns target=_blank rel=nofollow>https://clickhouse.com/docs/en/engines/table-engines/integrations/rabbitmq#virtual-columns</a></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TABLE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>IF</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NOT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>EXISTS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>rabbitmq</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>broker_errors_queue</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>(</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>exchange_name</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>channel_id</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>delivery_tag</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>UInt64</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>redelivered</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>UInt8</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>message_id</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>timestamp</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>UInt64</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>engine</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>RabbitMQ</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>SETTINGS</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>rabbitmq_host_port</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;localhost:5672&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>rabbitmq_exchange_name</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;exchange-test&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#8f5902;font-style:italic>-- required parameter even though this is done via the rabbitmq config
</span></span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic></span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>rabbitmq_queue_consume</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>true</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>rabbitmq_queue_base</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;test-errors&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>rabbitmq_format</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;JSONEachRow&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>rabbitmq_username</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;guest&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>rabbitmq_password</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;guest&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#000>rabbitmq_handle_error_mode</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;stream&#39;</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>MATERIALIZED</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>VIEW</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>IF</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NOT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>EXISTS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>rabbitmq</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>broker_errors_mv</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>(</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>exchange_name</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>channel_id</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>delivery_tag</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>UInt64</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>redelivered</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>UInt8</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>message_id</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>timestamp</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>UInt64</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>raw_message</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>error</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>String</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>ENGINE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>MergeTree</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>ORDER</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>BY</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>(</span><span style=color:#000>error</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000>SETTINGS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>index_granularity</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>8192</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>SELECT</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>_exchange_name</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>exchange_name</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>_channel_id</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>channel_id</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>_delivery_tag</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>delivery_tag</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>_redelivered</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>redelivered</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>_message_id</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>message_id</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>_timestamp</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>timestamp</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>_raw_message</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>raw_message</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#000>_error</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>AS</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>error</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>FROM</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>rabbitmq</span><span style=color:#000;font-weight:700>.</span><span style=color:#000>broker_errors_queue</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>WHERE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>length</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>_error</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>&gt;</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>0</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class="row footer-inner pb-3"><div class=col-12><a href=https://altinity.com target=_blank><img src=/images/general/altinity-logo_horizontal_blue_white.svg width=154 alt=Altinity.com></a></div></div><div class="row footer-inner py-3"><div class="col-12 col-sm-6 col-md-3"><ul class="nav flex-column mb-3"><li class=nav-item><b>PRODUCT</b></li><li class=nav-item><a href=https://altinity.com/managed-clickhouse/ target=_blank>Altinity.Cloud</a></li><li class=nav-item><a href=https://altinity.com/clickhouse-support/ target=_blank>Support for ClickHouse</a></li><li class=nav-item><a href=https://altinity.com/clickhouse-training target=_blank>Training for ClickHouse</a></li><li class=nav-item><a href=https://altinity.com/clickhouse-pricing/ target=_blank>Altinity.Cloud Pricing</a></li><li class=nav-item><a href=https://altinity.com/plans-and-features-clickhouse/ target=_blank>Altinity Plans and Features</a></li></ul><div class="d-none d-md-block mb-3"><img decoding=async style="width:60px;display:inline-block;margin:0 10px 0 0" src=/images/general/soc.webp alt="SOC Certified"><img decoding=async style=width:60px;display:inline-block;margin:0 src=/images/general/soc2.webp alt="SOC2 TYPE II Certified"></div></div><div class="col-12 col-sm-6 col-md-3"><ul class="nav flex-column mb-3"><li class=nav-item><b>RESOURCES</b></li><li class=nav-item><a href=https://altinity.com/blog target=_blank>Blog</a></li><li class=nav-item><a href=https://docs.altinity.com/ target=_blank>Documentation</a></li><li class=nav-item><a href=https://kb.altinity.com/ target=_blank>Knowledge Base</a></li><li class=nav-item><a href=https://altinity.com/releases target=_blank>Altinity Stable Builds</a></li><li class=nav-item><a href=https://hubs.la/Q02pLTV20 target=_blank>Kubernetes Operator</a></li><li class=nav-item><a href=https://altinity.com/ecosystem/ target=_blank>Altinity Open Source Projects</a></li><li class=nav-item><a href=https://altinity.com/events/ target=_blank>Events</a></li></ul></div><div class="col-12 col-sm-6 col-md-3"><ul class="nav flex-column mb-3"><li class=nav-item><b>COMPANY</b></li><li class=nav-item><a href=https://altinity.com/about-us/ target=_blank>About Altinity</a></li><li class=nav-item><a href=https://altinity.com/about-us/press-releases target=_blank>Press Releases</a></li><li class=nav-item><a href=https://altinity.com/partners/ target=_blank>Partners</a></li><li class=nav-item><a href=https://altinity.com/customer-stories/ target=_blank>Customer Stories</a></li><li class=nav-item><a href=https://altinity.com/careers/ target=_blank>Careers</a></li><li class=nav-item><a href=https://altinity.com/contact/ target=_blank>Contact Us</a></li></ul></div><div class="col-12 col-sm-6 col-md-3">Get the latest ClickHouse news straight to your inbox every month.<br><a href=https://altinity.com/newsletter/ target=_blank class="btn btn-primary my-3" style=border-radius:1.5rem>Sign Up</a></div></div></div><div class="row footer-inner pb-3"><div class="col-12 col-sm-6 text-left text-xs-center py-2"><small class=text-white>&copy; 2026 Altinity Inc. Altinity®, Altinity.Cloud®, and Altinity Stable® are registered trademarks of Altinity, Inc. ClickHouse® is a registered trademark of ClickHouse, Inc.; Altinity is not affiliated with or associated with ClickHouse, Inc. Kafka, Kubernetes, MySQL, and PostgreSQL are trademarks and property of their respective owners. All Rights Reserved</small>
<small class=ml-1><a href=https://altinity.com/privacy-policy/ target=_blank>Privacy Policy</a></small></div><div class="col-12 col-sm-6 text-end text-xs-center"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack><a class=text-white target=_blank rel="noopener noreferrer" href=https://altinity.com/slack><i class="fab fa-slack"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=X aria-label=X><a class=text-white target=_blank rel="noopener noreferrer" href=https://twitter.com/AltinityDB><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=LinkedIn aria-label=LinkedIn><a class=text-white target=_blank rel="noopener noreferrer" href=https://www.linkedin.com/company/altinity/><i class="fab fa-linkedin"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube><a class=text-white target=_blank rel="noopener noreferrer" href=https://www.youtube.com/channel/UCE3Y2lDKl_ZfjaCrh62onYA><i class="fab fa-youtube"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel="noopener noreferrer" href=https://github.com/Altinity/altinityknowledgebase><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Reddit aria-label=Reddit><a class=text-white target=_blank rel="noopener noreferrer" href=https://www.reddit.com/r/Clickhouse/><i class="fab fa-reddit"></i></a></li></ul></div></div></div><script async src="https://www.googletagmanager.com/gtag/js?id=UA-101676615-2"></script><script type=text/javascript id=hs-script-loader async defer src=//js.hs-scripts.com/4536206.js></script><script type=text/javascript>!function(){var e,t="06536e793668baa",n=function(){Reo.init({clientID:"06536e793668baa"})};(e=document.createElement("script")).src="https://static.reo.dev/"+t+"/reo.js",e.defer=!0,e.onload=n,document.head.appendChild(e)}()</script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-101676615-2")</script><script>$(document).ready(function(){$(".mobile-drop-toggle").on("click",function(){$(this).parent().parent().toggleClass("active")})})</script></footer><script type=text/javascript>_linkedin_partner_id="1601132",window._linkedin_data_partner_ids=window._linkedin_data_partner_ids||[],window._linkedin_data_partner_ids.push(_linkedin_partner_id)</script><script type=text/javascript>(function(e){e||(window.lintrk=function(e,t){window.lintrk.q.push([e,t])},window.lintrk.q=[]);var n=document.getElementsByTagName("script")[0],t=document.createElement("script");t.type="text/javascript",t.async=!0,t.src="https://snap.licdn.com/li.lms-analytics/insight.min.js",n.parentNode.insertBefore(t,n)})(window.lintrk)</script><noscript><img height=1 width=1 style=display:none alt src="https://px.ads.linkedin.com/collect/?pid=1601132&fmt=gif"></noscript></div><script src=/js/main.min.69e2c1ae9320465ab10236d9ef752c6a4442c54b48b883b17c497b7c7d96a796.js integrity="sha256-aeLBrpMgRlqxAjbZ73UsakRCxUtIuIOxfEl7fH2Wp5Y=" crossorigin=anonymous></script><script src=/js/prism.js></script><script src=/js/tabpane-persist.js></script></body></html>