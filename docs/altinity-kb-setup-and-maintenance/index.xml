<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Setup &amp; maintenance on Altinity Beta Knowledgebase</title>
    <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/</link>
    <description>Recent content in Setup &amp; maintenance on Altinity Beta Knowledgebase</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/clickhouse-backup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/clickhouse-backup/</guid>
      <description>title: &amp;ldquo;clickhouse-backup&amp;rdquo; linkTitle: &amp;ldquo;clickhouse-backup&amp;rdquo; description: &amp;gt; clickhouse-backup Installation and configuration Download the latest clickhouse-backup.tar.gz from assets from https://github.com/AlexAkulov/clickhouse-backup/releases
This tar.gz contains a single binary of clickhouse-backup and an example of config file.
Backblaze has s3 compatible API but requires empty acl parameter acl: &amp;quot;&amp;quot;.
https://www.backblaze.com/ has 15 days and free 10Gb S3 trial.
$ mkdir clickhouse-backup$ cd clickhouse-backup$ wget https://github.com/AlexAkulov/clickhouse-backup/releases/download/1.0.0-beta2/clickhouse-backup.tar.gz$ tar zxf clickhouse-backup.tar.gz$ rm clickhouse-backup.tar.gz$ cat config.ymlgeneral:remote_storage:s3max_file_size:1099511627776disable_progress_bar:falsebackups_to_keep_local:0backups_to_keep_remote:0log_level:infoallow_empty_backups:falseclickhouse:username:defaultpassword:&amp;#34;&amp;#34;host:localhostport:9000disk_mapping:{}skip_tables:- system.*timeout:5mfreeze_by_part:falsesecure:falseskip_verify:falsesync_replicated_tables:truelog_sql_queries:falses3:access_key:0****1secret_key:K****1bucket:&amp;#34;mybucket&amp;#34;endpoint:s3.us-west-000.backblazeb2.comregion:us-west-000acl:&amp;#34;&amp;#34;force_path_style:falsepath:clickhouse-backupdisable_ssl:falsepart_size:536870912compression_level:1compression_format:tarsse:&amp;#34;&amp;#34;disable_cert_verification:falsestorage_class:STANDARDI have a database test with table test</description>
    </item>
    
    <item>
      <title></title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/logging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/logging/</guid>
      <description>Logging Q. I get errors:
File not found: /var/log/clickhouse-server/clickhouse-server.log.0. File not found: /var/log/clickhouse-server/clickhouse-server.log.8.gz. ... File not found: /var/log/clickhouse-server/clickhouse-server.err.log.0, Stack trace (when copying this message, always include the lines below): 0. Poco::FileImpl::handleLastErrorImpl(std::__1::basic_string&amp;lt;char, std::__1::char_traits&amp;lt;char&amp;gt;, std::__1::allocator&amp;lt;char&amp;gt; &amp;gt; const&amp;amp;) @ 0x11c2b345 in /usr/bin/clickhouse 1. Poco::PurgeOneFileStrategy::purge(std::__1::basic_string&amp;lt;char, std::__1::char_traits&amp;lt;char&amp;gt;, std::__1::allocator&amp;lt;char&amp;gt; &amp;gt; const&amp;amp;) @ 0x11c84618 in /usr/bin/clickhouse 2. Poco::FileChannel::log(Poco::Message const&amp;amp;) @ 0x11c314cc in /usr/bin/clickhouse 3. DB::OwnFormattingChannel::logExtended(DB::ExtendedLogMessage const&amp;amp;) @ 0x8681402 in /usr/bin/clickhouse 4. DB::OwnSplitChannel::logSplit(Poco::Message const&amp;amp;) @ 0x8682fa8 in /usr/bin/clickhouse 5.</description>
    </item>
    
    <item>
      <title>Altinity packaging compatibility &amp;gt;21.x and earlier</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-packaging-compatibility-greater-than-21.x-and-earlier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-packaging-compatibility-greater-than-21.x-and-earlier/</guid>
      <description>Working with Altinity &amp;amp; Yandex packaging together Since version 21.1 Altinity switches to the same packaging as used by Yandex. That is needed for syncing things and introduces several improvements (like adding systemd service file).
Unfortunately, that change leads to compatibility issues - automatic dependencies resolution gets confused by the conflicting package names: both when you update ClickHouse to the new version (the one which uses older packaging) and when you want to install older altinity packages (20.</description>
    </item>
    
    <item>
      <title>AWS EBS</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/aws-ebs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/aws-ebs/</guid>
      <description>Volume type  gp3 gp2     Max throughput per volume  1000 MiB/s 250 MiB/s   Price  $0.08/GB-month
3,000 IOPS free and
$0.005/provisioned IOPS-month over 3,000;
125 MB/s free and
$0.04/provisioned MB/s-month over 125
 $0.10/GB-month    GP2 In usual conditions ClickHouse being limited by throughput of volumes only and amount of provided IOPS doesn&amp;rsquo;t make any big difference for performance.</description>
    </item>
    
    <item>
      <title>ClickHouse in Docker</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-clickhouse-in-docker/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-clickhouse-in-docker/</guid>
      <description>Do you have documentation on Docker deployments?
 Check
 https://hub.docker.com/r/yandex/clickhouse-server/ https://docs.altinity.com/clickhouseonkubernetes/ sources of entry point - https://github.com/ClickHouse/ClickHouse/blob/master/docker/server/entrypoint.sh  Important things:
 use concrete version tag (avoid using latest) if possible use --network=host (due to performance reasons) you need to mount the folder /var/lib/clickhouse to have persistency. you MAY also mount the folder /var/log/clickhouse-server to have logs accessible outside of the container. Also, you may mount in some files or folders in the configuration folder:  /etc/clickhouse-server/config.</description>
    </item>
    
    <item>
      <title>ClickHouse versions</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/untitled/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/untitled/</guid>
      <description>ClickHouse versioning schema Example:
21.3.10.1-lts
 21 is the year of release. 3 indicates a Feature Release. This is an increment where features are delivered. 10 is the bugfix / maintenance version. When that version is incremented it means that some bugs was fixed comparing to 21.3.9. 1 - build number, means nothing for end users. lts - type of release. (long time support).  What is Altinity Stable version? It is one of general / public version of ClickHouse which has passed some extra testings, the upgrade path and changelog was analyzed, known issues are documented, and at least few big companies use it on production.</description>
    </item>
    
    <item>
      <title>Converting MergeTree to Replicated</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-converting-mergetree-to-replicated/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-converting-mergetree-to-replicated/</guid>
      <description>Options here are:
 UseINSERT INTO foo_replicated SELECT * FROM foo . Create table aside and attach all partition from the existing table then drop original table (uses hard links don&amp;rsquo;t require extra disk space). ALTER TABLE foo_replicated ATTACH PARTITION ID &#39;bar&#39; FROM &#39;foo&#39; You can easily auto generate those commands using a query like: SELECT DISTINCT &#39;ALTER TABLE foo_replicated ATTACH PARTITION ID &#39;&#39; || partition_id || &#39;&#39; FROM foo&#39; from system.</description>
    </item>
    
    <item>
      <title>High CPU usage</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/high-cpu-usage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/high-cpu-usage/</guid>
      <description>In general, it is a NORMAL situation for clickhouse that while processing a huge dataset it can use a lot of (or all of) the server resources. It is &amp;lsquo;by design&amp;rsquo; - just to make the answers faster.
The main directions to reduce the CPU usage is to review the schema / queries to limit the amount of the data which need to be processed, and to plan the resources in a way when single running query will not impact the others.</description>
    </item>
    
    <item>
      <title>Load balancers</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/load-balancers/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/load-balancers/</guid>
      <description>In general - one of the simplest option to do load balancing is to implement it on the client side.
I.e. list serveral endpoints for clickhouse connections and add some logic to pick one of the nodes.
Many client libraries support that.
ClickHouse native protocol (port 9000) Currently there are no protocol-aware proxies for clickhouse protocol, so the proxy / load balancer can work only on TCP level.
One of the best option for TCP load balancer is haproxy, also nginx can work in that mode.</description>
    </item>
    
    <item>
      <title>memory configuration settings</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-memory-configuration-settings/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-memory-configuration-settings/</guid>
      <description>max_memory_usage. Single query memory usage max_memory_usage - the maximum amount of memory allowed for a single query to take. By default, it&amp;rsquo;s 10Gb. The default value is good, don&amp;rsquo;t adjust it in advance.
There are scenarios when you need to relax the limit for particular queries (if you hit &amp;lsquo;Memory limit (for query) exceeded&amp;rsquo;), or use a lower limit if you need to discipline the users or increase the number of simultaneous queries.</description>
    </item>
    
    <item>
      <title>Monitoring</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-monitoring/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-monitoring/</guid>
      <description>Prometheus endpoint  Grafana dashboard (internal endpoint) https://grafana.com/grafana/dashboards/13500
Grafana dashboard (clickhouse-operator) https://github.com/Altinity/clickhouse-operator/tree/master/grafana-dashboard
Prometheus alerts (clickhouse-operator) https://github.com/Altinity/clickhouse-operator/blob/master/deploy/prometheus/prometheus-alert-rules.yaml
ClickHouse exporter  https://github.com/ClickHouse/clickhouse_exporter
Zabbix  https://github.com/Altinity/clickhouse-zabbix-template
ZooKeeper Monitoring {% page-ref page=&amp;ldquo;altinity-kb-zookeeper/zookeeper-monitoring.md&amp;rdquo; %}
© 2021 Altinity Inc. All rights reserved.</description>
    </item>
    
    <item>
      <title>Moving table to another device.</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-moving-table-to-another-device./</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-moving-table-to-another-device./</guid>
      <description>Suppose we mount a new device at path /mnt/disk_1 and want to move table_4 to it.
 Create directory on new device for ClickHouse data. /in shell mkdir /mnt/disk_1/clickhouse Change ownership of created directory to ClickHouse user. /in shell chown -R clickhouse:clickhouse /mnt/disk_1/clickhouse Create a special storage policy which should include both disks: old and new. /in shell  nano /etc/clickhouse-server/config.d/storage.xml ###################/etc/clickhouse-server/config.d/storage.xml########################### &amp;lt;yandex&amp;gt; &amp;lt;storage_configuration&amp;gt; &amp;lt;disks&amp;gt; &amp;lt;!-- default disk is special, it always exists even if not explicitly configured here, but you can&#39;t change it&#39;s path here (you should use &amp;lt;path&amp;gt; on top level config instead) --&amp;gt; &amp;lt;default&amp;gt; &amp;lt;!</description>
    </item>
    
    <item>
      <title>Object consistency in a cluster</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-object-consistency-in-a-cluster/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-object-consistency-in-a-cluster/</guid>
      <description>List of missing tables
WITH(SELECTgroupArray(FQDN())FROMclusterAllReplicas({cluster},system,one))AShostsSELECTdatabase,table,arrayFilter(i-&amp;gt;NOThas(groupArray(host),i),hosts)miss_tableFROM(SELECTFQDN()host,database,nametableFROMclusterAllReplicas({cluster},system,tables)WHEREengineNOTIN(&amp;#39;Log&amp;#39;,&amp;#39;Memory&amp;#39;,&amp;#39;TinyLog&amp;#39;))GROUPBYdatabase,tableHAVINGmiss_table&amp;lt;&amp;gt;[]SETTINGSskip_unavailable_shards=1;┌─database─┬─table─┬─miss_table────────────────┐│default│test│[&amp;#39;host366.mynetwork.net&amp;#39;]│└──────────┴───────┴───────────────────────────┘List of inconsistent tables
SELECTdatabase,name,engine,uniqExact(create_table_query)ASddlFROMclusterAllReplicas({cluster},system.tables)GROUPBYdatabase,name,engineHAVINGddl&amp;gt;1List of inconsistent columns
WITH(SELECTgroupArray(FQDN())FROMclusterAllReplicas({cluster},system,one))AShostsSELECTdatabase,table,column,arrayStringConcat(arrayMap(i-&amp;gt;i.2||&amp;#39;: &amp;#39;||i.1,(groupArray((type,host))ASg)),&amp;#39;, &amp;#39;)diffFROM(SELECTFQDN()host,database,table,namecolumn,typeFROMclusterAllReplicas({cluster},system,columns))GROUPBYdatabase,table,columnHAVINGlength(arrayDistinct(g.1))&amp;gt;1ORlength(g.1)&amp;lt;&amp;gt;length(hosts)SETTINGSskip_unavailable_shards=1;┌─database─┬─table───┬─column────┬─diff────────────────────────────────┐│default│z│A│ch-host22:Int64,ch-host21:String│└──────────┴─────────┴───────────┴─────────────────────────────────────┘List of inconsistent dictionaries
WITH(SELECTgroupArray(FQDN())FROMclusterAllReplicas({cluster},system,one))AShostsSELECTdatabase,dictionary,arrayFilter(i-&amp;gt;NOThas(groupArray(host),i),hosts)miss_dict,arrayReduce(&amp;#39;median&amp;#39;,(groupArray((element_count,host))ASec).1)FROM(SELECTFQDN()host,database,namedictionary,element_countFROMclusterAllReplicas({cluster},system,dictionaries))GROUPBYdatabase,dictionaryHAVINGmiss_dict&amp;lt;&amp;gt;[]SETTINGSskip_unavailable_shards=1;© 2021 Altinity Inc. All rights reserved.</description>
    </item>
    
    <item>
      <title>Replication queue</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-replication-queue/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-replication-queue/</guid>
      <description>SELECTdatabase,table,type,any(last_exception),any(postpone_reason),min(create_time),max(last_attempt_time),max(last_postpone_time),max(num_postponed)ASmax_postponed,max(num_tries)ASmax_tries,min(num_tries)ASmin_tries,countIf(last_exception!=&amp;#39;&amp;#39;)AScount_err,countIf(num_postponed&amp;gt;0)AScount_postponed,countIf(is_currently_executing)AScount_executing,count()AScount_allFROMsystem.replication_queueGROUPBYdatabase,table,typeORDERBYcount_allDESC© 2021 Altinity Inc. All rights reserved.</description>
    </item>
    
    <item>
      <title>Server config files</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-server-config-files/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-server-config-files/</guid>
      <description>Сonfig management (recommended structure) Settings &amp;amp;amp; restart Dictionaries incl attribute &amp;amp;amp; metrica.xml Multiple Clickhouse instances at one host preprocessed_configs  Сonfig management (recommended structure)  Clickhouse server config consists of two parts server settings (config.xml) and users settings (users.xml).
By default they are stored in the folder /etc/clickhouse-server/ in two files config.xml &amp;amp; users.xml.
We suggest never change vendor config files and place your changes into separate .xml files in sub-folders.</description>
    </item>
    
    <item>
      <title>Settings to adjust</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-settings-to-adjust/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-settings-to-adjust/</guid>
      <description>query_log and other _log tables - set up TTL, or some other cleanup procedures.
cat /etc/clickhouse-server/config.d/query_log.xml &amp;lt;yandex&amp;gt; &amp;lt;query_log replace=&amp;quot;1&amp;quot;&amp;gt; &amp;lt;database&amp;gt;system&amp;lt;/database&amp;gt; &amp;lt;table&amp;gt;query_log&amp;lt;/table&amp;gt; &amp;lt;flush_interval_milliseconds&amp;gt;7500&amp;lt;/flush_interval_milliseconds&amp;gt; &amp;lt;engine&amp;gt; ENGINE = MergeTree PARTITION BY event_date ORDER BY (event_time) TTL event_date + interval 90 day SETTINGS ttl_only_drop_parts=1 &amp;lt;/engine&amp;gt; &amp;lt;/query_log&amp;gt; &amp;lt;/yandex&amp;gt;   query_thread_log - typically is not useful, you can disable it (or set up TTL).
cat /etc/clickhouse-server/config.d/disable_query_thread_log.xml &amp;lt;yandex&amp;gt; &amp;lt;query_thread_log remove=&amp;quot;1&amp;quot; /&amp;gt; &amp;lt;metric_log remove=&amp;quot;1&amp;quot; /&amp;gt; &amp;lt;asynchronous_metric_log remove=&amp;quot;1&amp;quot; /&amp;gt; &amp;lt;!</description>
    </item>
    
    <item>
      <title>Shutting down a node</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-shutting-down-a-node/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-shutting-down-a-node/</guid>
      <description>It’s possible to shutdown server on fly, but that would lead to failure of some queries.
More safer way:
  Remove server (which is going to be disabled) from remote_server section of config.xml on all servers.
  Remove server from load balancer, so new queries wouldn’t hit it.
  Wait until all already running queries would finish execution on it.
It’s possible to check it via query:</description>
    </item>
    
    <item>
      <title>SSL connection unexpectedly closed</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/ssl-connection-unexpectedly-closed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/ssl-connection-unexpectedly-closed/</guid>
      <description>ClickHouse doesn&amp;rsquo;t probe CA path which is default on CentOS and Amazon Linux.
ClickHouse client: cat /etc/clickhouse-client/conf.d/openssl-ca.xml &amp;lt;config&amp;gt; &amp;lt;openSSL&amp;gt; &amp;lt;client&amp;gt; &amp;lt;!-- Used for connection to server&#39;s secure tcp port --&amp;gt; &amp;lt;caConfig&amp;gt;/etc/ssl/certs&amp;lt;/caConfig&amp;gt; &amp;lt;/client&amp;gt; &amp;lt;/openSSL&amp;gt; &amp;lt;/config&amp;gt; ClickHouse server: cat /etc/clickhouse-server/conf.d/openssl-ca.xml &amp;lt;config&amp;gt; &amp;lt;openSSL&amp;gt; &amp;lt;server&amp;gt; &amp;lt;!-- Used for https server AND secure tcp port --&amp;gt; &amp;lt;caConfig&amp;gt;/etc/ssl/certs&amp;lt;/caConfig&amp;gt; &amp;lt;/server&amp;gt; &amp;lt;client&amp;gt; &amp;lt;!-- Used for connecting to https dictionary source and secured Zookeeper communication --&amp;gt; &amp;lt;caConfig&amp;gt;/etc/ssl/certs&amp;lt;/caConfig&amp;gt; &amp;lt;/client&amp;gt; &amp;lt;/openSSL&amp;gt; &amp;lt;/config&amp;gt; {% embed url=&amp;ldquo;https://github.</description>
    </item>
    
    <item>
      <title>System tables eat my disk</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-system-tables-eat-my-disk/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-system-tables-eat-my-disk/</guid>
      <description>Note 1: System database stores virtual tables (parts, tables, columns, etc.) and *_log tables.
Virtual tables do not persist on disk. They reflect ClickHouse memory (c++ structures). They cannot be changed or removed.
Log tables are named with postfix *_log and have the MergeTree engine.
You can drop / rename / truncate *_log tables at any time. ClickHouse will recreate them in about 7 seconds (flush period).
  Note 2: Log tables with numeric postfixes (_1 / 2 / 3 &amp;hellip;) query_log_1 query_thread_log_3 are results of Clickhouse upgrades.</description>
    </item>
    
    <item>
      <title>Threads</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-threads/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-threads/</guid>
      <description>Collect thread names &amp;amp; counts using ps &amp;amp; clickhouse-local
ps H -o &amp;#39;tid comm&amp;#39; $(pidof -s clickhouse-server) | tail -n +2 | awk &amp;#39;{ printf(&amp;#34;%s\t%s\n&amp;#34;, $1, $2) }&amp;#39; | clickhouse-local -S &amp;#34;threadid UInt16, name String&amp;#34; -q &amp;#34;SELECT name, count() FROM table GROUP BY name WITH TOTALS ORDER BY count() DESC FORMAT PrettyCompact&amp;#34; Check threads used by running queries:
SELECTquery,length(thread_ids)ASthreads_countFROMsystem.processesORDERBYthreads_count;--- title: &amp;#34;cat /proc/$(pidof -s clickhouse-server)/status | grep Threads&amp;#34; linkTitle: &amp;#34;cat /proc/$(pidof -s clickhouse-server)/status | grep Threads&amp;#34; description: &amp;gt; cat /proc/$(pidof -s clickhouse-server)/status | grep Threads --- Threads: 103 --- title: &amp;#34;ps hH $(pidof -s clickhouse-server)| wc -l&amp;#34; linkTitle: &amp;#34;ps hH $(pidof -s clickhouse-server)| wc -l&amp;#34; description: &amp;gt; ps hH $(pidof -s clickhouse-server) | wc -l --- 103 --- title: &amp;#34;ps hH -AF | grep clickhouse | wc -l&amp;#34; linkTitle: &amp;#34;ps hH -AF | grep clickhouse | wc -l&amp;#34; description: &amp;gt; ps hH -AF | grep clickhouse | wc -l --- 116 Pools</description>
    </item>
    
    <item>
      <title>Who ate my memory</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-who-ate-my-memory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/altinity-kb-who-ate-my-memory/</guid>
      <description>SELECTformatReadableSize(sum(bytes_allocated))FROMsystem.dictionaries;SELECTdatabase,name,formatReadableSize(total_bytes)FROMsystem.tablesWHEREengineIN(&amp;#39;Memory&amp;#39;,&amp;#39;Set&amp;#39;,&amp;#39;Join&amp;#39;);SELECTformatReadableSize(sum(memory_usage))FROMsystem.merges;SELECTformatReadableSize(sum(memory_usage))FROMsystem.processes;SELECTinitial_query_id,formatReadableSize(memory_usage),formatReadableSize(peak_memory_usage),queryFROMsystem.processesORDERBYpeak_memory_usageDESCLIMIT10;SELECTmetric,formatReadableSize(value)FROMsystem.asynchronous_metricsWHEREmetricIN(&amp;#39;UncompressedCacheBytes&amp;#39;,&amp;#39;MarkCacheBytes&amp;#39;);SELECTformatReadableSize(sum(primary_key_bytes_in_memory))ASprimary_key_bytes_in_memory,formatReadableSize(sum(primary_key_bytes_in_memory_allocated))ASprimary_key_bytes_in_memory_allocatedFROMsystem.parts;SELECTinitial_query_id,formatReadableSize(memory_usage),queryFROMsystem.query_logWHERE(event_date&amp;gt;=today())AND(event_time&amp;gt;=(now()-7200))ORDERBYmemory_usageDESCLIMIT10;© 2021 Altinity Inc. All rights reserved.</description>
    </item>
    
    <item>
      <title>X rows of Y total rows in filesystem are suspicious</title>
      <link>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/x-rows-of-y-total-rows-in-filesystem-are-suspicious/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://beta.kb.altinity.com/altinity-kb-setup-and-maintenance/x-rows-of-y-total-rows-in-filesystem-are-suspicious/</guid>
      <description>{% hint style=&amp;ldquo;danger&amp;rdquo; %} The local set of parts of table doesn&amp;rsquo;t look like the set of parts in ZooKeeper. 100.00 rows of 150.00 total rows in filesystem are suspicious. There are 1 unexpected parts with 100 rows (1 of them is not just-written with 100 rows), 0 missing parts (with 0 blocks).: Cannot attach table. {% endhint %}
ClickHouse has a registry of parts in ZooKeeper.
And during the start ClickHouse compares that list of parts on a local disk is consistent with a list in ZooKeeper.</description>
    </item>
    
  </channel>
</rss>
